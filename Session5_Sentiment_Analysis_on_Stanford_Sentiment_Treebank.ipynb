{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session5_Sentiment Analysis on Stanford Sentiment Treebank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Sentiment classification\n",
        "\n",
        "We will be using Stanford Sentiment Treebank as the datasource and perform sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJp6-__LVf4d",
        "outputId": "0e72d261-3cfc-40c9-a39a-e6395519768b"
      },
      "source": [
        "!pip install google_trans_new\n",
        "\n",
        "import random\n",
        "import google_trans_new\n",
        "from google_trans_new import google_translator \n",
        "\n",
        "def random_insertion(sentence, n): \n",
        "    words = remove_stopwords(sentence) \n",
        "    for _ in range(n):\n",
        "        new_synonym = get_synonyms(random.choice(words))\n",
        "        sentence.insert(randrange(len(sentence)+1), new_synonym) \n",
        "    return sentence\n",
        "\n",
        "def random_swap(sentence, n=5): \n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return sentence\n",
        "\n",
        "def random_deletion(words, p=0.5): \n",
        "    if len(words) == 1: # return if single word\n",
        "        return words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
        "    if len(remaining) == 0: # if not left, sample a random word\n",
        "        return [random.choice(words)] \n",
        "    else:\n",
        "        return remaining"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google_trans_new in /usr/local/lib/python3.7/dist-packages (1.1.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pywng6FniiiY",
        "outputId": "8351be00-8304-4a73-dcc3-f8cfc03d0c1d"
      },
      "source": [
        "random_deletion('I am good boy'.split())"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['am', 'boy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXBkR84SOKKL",
        "outputId": "bf72fc77-7a59-44c1-f75e-7a83707f9bdd"
      },
      "source": [
        "!pip install pytreebank\n",
        "!pip install hyperopt"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytreebank in /usr/local/lib/python3.7/dist-packages (0.2.7)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.5.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.41.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (3.11.4)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ7cKlnUvu0e",
        "outputId": "837636c4-bc54-462a-d092-0ae1748de796"
      },
      "source": [
        "!pip install flair allennlp"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.8.0.post1)\n",
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.0.3)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.12)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n",
            "Requirement already satisfied: torch<=1.7.1,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.1)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.5)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.0.9)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair) (3.12.2)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.7.0)\n",
            "Requirement already satisfied: torchvision<0.10.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.9.1+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.0.12)\n",
            "Requirement already satisfied: boto3<2.0,>=1.14 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.17.86)\n",
            "Requirement already satisfied: wandb<0.11.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.10.31)\n",
            "Requirement already satisfied: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.17.0)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: overrides==3.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1,>=1.5.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.10.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.10.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.86 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (1.20.86)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (0.4.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (0.10.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (0.4.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (7.1.2)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (5.0.2)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (0.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (3.5.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (3.13)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (3.1.17)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (3.12.4)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (57.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (3.0.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp) (1.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2020.12.5)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (21.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.0.0->flair) (3.4.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb<0.11.0,>=0.10.0->allennlp) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.11.0,>=0.10.0->allennlp) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQzPH2nnv2--"
      },
      "source": [
        "from flair.datasets import ClassificationCorpus\n",
        "from flair.embeddings import FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.training_utils import EvaluationMetric\n",
        "from flair.visual.training_curves import Plotter\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.data import Sentence"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc"
      },
      "source": [
        "# import pytreebank\n",
        "# import sys\n",
        "# import os\n",
        "\n",
        "\n",
        "# out_path = os.path.join(sys.path[0], 'sst_{}.txt')\n",
        "# dataset = pytreebank.load_sst()\n",
        "\n",
        "# # Store train, dev and test in separate files\n",
        "# for category in ['train', 'test', 'dev']:\n",
        "#     with open(out_path.format(category), 'w') as outfile:\n",
        "#         for item in dataset[category]:\n",
        "#             outfile.write(\"__label__{}\\t{}\\n\".format(\n",
        "#                 item.to_labeled_lines()[0][0] + 1,\n",
        "#                 item.to_labeled_lines()[0][1]\n",
        "#             ))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_0C5DIq0AqY"
      },
      "source": [
        "# import pytreebank\n",
        "# # load the sentiment treebank corpus in the parenthesis format,\n",
        "# # e.g. \"(4 (2 very ) (3 good))\"\n",
        "# dataset = pytreebank.load_sst()\n",
        "# # add Javascript and CSS to the Ipython notebook\n",
        "# pytreebank.LabeledTree.inject_visualization_javascript()\n",
        "# # select and example to visualize\n",
        "# example = dataset[\"train\"][0]\n",
        "# # display it in the page\n",
        "# example.display()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rST73bBBxOQg",
        "outputId": "58757658-f112-49be-c888-57358b571860"
      },
      "source": [
        "train, dev, test = 'sst_train.txt','sst_dev.txt','sst_test.txt'\n",
        "corpus = ClassificationCorpus(\n",
        "        '/content/',\n",
        "        train_file=train,\n",
        "        dev_file=dev,\n",
        "        test_file=test,\n",
        "    )"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 18:07:12,291 Reading data from /content\n",
            "2021-06-03 18:07:12,294 Train: /content/sst_train.txt\n",
            "2021-06-03 18:07:12,296 Dev: /content/sst_dev.txt\n",
            "2021-06-03 18:07:12,298 Test: /content/sst_test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbaRlU2OzSdi"
      },
      "source": [
        "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGQSAcN7zriW"
      },
      "source": [
        "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1IQPk59z3fg",
        "outputId": "d9d116cc-e773-4610-84b0-1b7626f23ba5"
      },
      "source": [
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 18:07:16,727 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10754 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 117/10754 [00:00<00:09, 1162.92it/s]\u001b[A\n",
            "  3%|▎         | 273/10754 [00:00<00:08, 1256.34it/s]\u001b[A\n",
            "  4%|▍         | 434/10754 [00:00<00:07, 1340.82it/s]\u001b[A\n",
            "  5%|▌         | 567/10754 [00:00<00:08, 1251.69it/s]\u001b[A\n",
            "  6%|▌         | 668/10754 [00:00<00:09, 1112.51it/s]\u001b[A\n",
            "  8%|▊         | 824/10754 [00:00<00:08, 1216.07it/s]\u001b[A\n",
            "  9%|▉         | 1002/10754 [00:00<00:07, 1343.73it/s]\u001b[A\n",
            " 11%|█         | 1162/10754 [00:00<00:06, 1406.68it/s]\u001b[A\n",
            " 12%|█▏        | 1340/10754 [00:00<00:06, 1496.04it/s]\u001b[A\n",
            " 14%|█▍        | 1525/10754 [00:01<00:05, 1584.68it/s]\u001b[A\n",
            " 16%|█▌        | 1707/10754 [00:01<00:05, 1642.10it/s]\u001b[A\n",
            " 17%|█▋        | 1874/10754 [00:01<00:05, 1609.13it/s]\u001b[A\n",
            " 19%|█▉        | 2052/10754 [00:01<00:05, 1648.65it/s]\u001b[A\n",
            " 21%|██        | 2223/10754 [00:01<00:05, 1657.33it/s]\u001b[A\n",
            " 22%|██▏       | 2390/10754 [00:01<00:05, 1659.15it/s]\u001b[A\n",
            " 24%|██▍       | 2569/10754 [00:01<00:04, 1683.99it/s]\u001b[A\n",
            " 25%|██▌       | 2742/10754 [00:01<00:04, 1697.32it/s]\u001b[A\n",
            " 27%|██▋       | 2913/10754 [00:01<00:04, 1653.56it/s]\u001b[A\n",
            " 29%|██▊       | 3079/10754 [00:01<00:04, 1642.39it/s]\u001b[A\n",
            " 30%|███       | 3244/10754 [00:02<00:04, 1636.19it/s]\u001b[A\n",
            " 32%|███▏      | 3408/10754 [00:02<00:04, 1633.09it/s]\u001b[A\n",
            " 33%|███▎      | 3572/10754 [00:02<00:04, 1629.71it/s]\u001b[A\n",
            " 35%|███▍      | 3741/10754 [00:02<00:04, 1641.46it/s]\u001b[A\n",
            " 36%|███▋      | 3909/10754 [00:02<00:04, 1647.51it/s]\u001b[A\n",
            " 38%|███▊      | 4083/10754 [00:02<00:04, 1649.87it/s]\u001b[A\n",
            " 40%|███▉      | 4249/10754 [00:02<00:04, 1617.57it/s]\u001b[A\n",
            " 41%|████      | 4411/10754 [00:02<00:03, 1599.02it/s]\u001b[A\n",
            " 43%|████▎     | 4572/10754 [00:02<00:03, 1591.53it/s]\u001b[A\n",
            " 44%|████▍     | 4732/10754 [00:03<00:03, 1568.08it/s]\u001b[A\n",
            " 45%|████▌     | 4889/10754 [00:03<00:03, 1538.14it/s]\u001b[A\n",
            " 47%|████▋     | 5068/10754 [00:03<00:03, 1600.01it/s]\u001b[A\n",
            " 49%|████▉     | 5245/10754 [00:03<00:03, 1642.10it/s]\u001b[A\n",
            " 50%|█████     | 5421/10754 [00:03<00:03, 1669.23it/s]\u001b[A\n",
            " 52%|█████▏    | 5599/10754 [00:03<00:03, 1685.53it/s]\u001b[A\n",
            " 54%|█████▎    | 5776/10754 [00:03<00:02, 1709.87it/s]\u001b[A\n",
            " 55%|█████▌    | 5948/10754 [00:03<00:02, 1638.12it/s]\u001b[A\n",
            " 57%|█████▋    | 6113/10754 [00:03<00:02, 1634.38it/s]\u001b[A\n",
            " 58%|█████▊    | 6284/10754 [00:03<00:02, 1645.05it/s]\u001b[A\n",
            " 60%|██████    | 6455/10754 [00:04<00:02, 1662.13it/s]\u001b[A\n",
            " 62%|██████▏   | 6631/10754 [00:04<00:02, 1684.69it/s]\u001b[A\n",
            " 63%|██████▎   | 6800/10754 [00:04<00:02, 1637.31it/s]\u001b[A\n",
            " 65%|██████▍   | 6968/10754 [00:04<00:02, 1632.23it/s]\u001b[A\n",
            " 66%|██████▋   | 7135/10754 [00:04<00:02, 1640.45it/s]\u001b[A\n",
            " 68%|██████▊   | 7308/10754 [00:04<00:02, 1653.79it/s]\u001b[A\n",
            " 70%|██████▉   | 7489/10754 [00:04<00:01, 1687.41it/s]\u001b[A\n",
            " 71%|███████▏  | 7671/10754 [00:04<00:01, 1723.18it/s]\u001b[A\n",
            " 73%|███████▎  | 7854/10754 [00:04<00:01, 1724.34it/s]\u001b[A\n",
            " 75%|███████▍  | 8051/10754 [00:04<00:01, 1748.62it/s]\u001b[A\n",
            " 77%|███████▋  | 8227/10754 [00:05<00:01, 1749.80it/s]\u001b[A\n",
            " 79%|███████▊  | 8451/10754 [00:05<00:01, 1871.85it/s]\u001b[A\n",
            " 80%|████████  | 8652/10754 [00:05<00:01, 1908.36it/s]\u001b[A\n",
            " 82%|████████▏ | 8845/10754 [00:05<00:01, 1854.90it/s]\u001b[A\n",
            " 84%|████████▍ | 9033/10754 [00:05<00:00, 1847.32it/s]\u001b[A\n",
            " 86%|████████▌ | 9219/10754 [00:05<00:00, 1746.87it/s]\u001b[A\n",
            " 87%|████████▋ | 9396/10754 [00:05<00:00, 1714.82it/s]\u001b[A\n",
            " 89%|████████▉ | 9569/10754 [00:05<00:00, 1706.11it/s]\u001b[A\n",
            " 91%|█████████ | 9760/10754 [00:05<00:00, 1741.34it/s]\u001b[A\n",
            " 92%|█████████▏| 9936/10754 [00:06<00:00, 1710.10it/s]\u001b[A\n",
            " 94%|█████████▍| 10108/10754 [00:06<00:00, 1711.03it/s]\u001b[A\n",
            " 96%|█████████▌| 10290/10754 [00:06<00:00, 1738.46it/s]\u001b[A\n",
            " 97%|█████████▋| 10467/10754 [00:06<00:00, 1743.25it/s]\u001b[A\n",
            "100%|██████████| 10754/10754 [00:06<00:00, 1613.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 18:07:23,848 [b'4', b'5', b'3', b'2', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D554414Zz664"
      },
      "source": [
        "trainer = ModelTrainer(classifier, corpus)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHFSdhGIz-rk",
        "outputId": "5b54f785-8502-439c-e19b-d2a7d72e066e"
      },
      "source": [
        "# without data augmentation\n",
        "trainer.train('./', max_epochs=90)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 18:07:36,920 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:07:36,922 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-06-03 18:07:36,925 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:07:36,928 Corpus: \"Corpus: 8544 train + 1101 dev + 2210 test sentences\"\n",
            "2021-06-03 18:07:36,929 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:07:36,931 Parameters:\n",
            "2021-06-03 18:07:36,934  - learning_rate: \"0.1\"\n",
            "2021-06-03 18:07:36,936  - mini_batch_size: \"32\"\n",
            "2021-06-03 18:07:36,938  - patience: \"3\"\n",
            "2021-06-03 18:07:36,940  - anneal_factor: \"0.5\"\n",
            "2021-06-03 18:07:36,942  - max_epochs: \"90\"\n",
            "2021-06-03 18:07:36,944  - shuffle: \"True\"\n",
            "2021-06-03 18:07:36,946  - train_with_dev: \"False\"\n",
            "2021-06-03 18:07:36,949  - batch_growth_annealing: \"False\"\n",
            "2021-06-03 18:07:36,951 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:07:36,952 Model training base path: \".\"\n",
            "2021-06-03 18:07:36,955 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:07:36,957 Device: cuda:0\n",
            "2021-06-03 18:07:36,959 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:07:36,967 Embeddings storage mode: cpu\n",
            "2021-06-03 18:07:36,972 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:07:42,459 epoch 1 - iter 26/267 - loss 1.27897993 - samples/sec: 168.64 - lr: 0.100000\n",
            "2021-06-03 18:07:47,164 epoch 1 - iter 52/267 - loss 1.23685361 - samples/sec: 180.97 - lr: 0.100000\n",
            "2021-06-03 18:07:53,391 epoch 1 - iter 78/267 - loss 1.22493224 - samples/sec: 171.46 - lr: 0.100000\n",
            "2021-06-03 18:07:57,947 epoch 1 - iter 104/267 - loss 1.21289063 - samples/sec: 186.39 - lr: 0.100000\n",
            "2021-06-03 18:08:02,894 epoch 1 - iter 130/267 - loss 1.23081463 - samples/sec: 171.94 - lr: 0.100000\n",
            "2021-06-03 18:08:08,554 epoch 1 - iter 156/267 - loss 1.25092922 - samples/sec: 149.32 - lr: 0.100000\n",
            "2021-06-03 18:08:14,319 epoch 1 - iter 182/267 - loss 1.25008691 - samples/sec: 188.32 - lr: 0.100000\n",
            "2021-06-03 18:08:18,815 epoch 1 - iter 208/267 - loss 1.25374147 - samples/sec: 189.69 - lr: 0.100000\n",
            "2021-06-03 18:08:23,340 epoch 1 - iter 234/267 - loss 1.24975762 - samples/sec: 187.46 - lr: 0.100000\n",
            "2021-06-03 18:08:27,807 epoch 1 - iter 260/267 - loss 1.25805525 - samples/sec: 189.74 - lr: 0.100000\n",
            "2021-06-03 18:08:29,873 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:08:29,875 EPOCH 1 done: loss 1.2664 - lr 0.1000000\n",
            "2021-06-03 18:08:37,026 DEV : loss 1.8895463943481445 - score 0.2652\n",
            "2021-06-03 18:08:37,811 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:08:41,284 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:08:46,631 epoch 2 - iter 26/267 - loss 1.57762256 - samples/sec: 177.03 - lr: 0.100000\n",
            "2021-06-03 18:08:51,271 epoch 2 - iter 52/267 - loss 1.56224549 - samples/sec: 185.27 - lr: 0.100000\n",
            "2021-06-03 18:08:57,295 epoch 2 - iter 78/267 - loss 1.56005282 - samples/sec: 190.08 - lr: 0.100000\n",
            "2021-06-03 18:09:01,823 epoch 2 - iter 104/267 - loss 1.55367230 - samples/sec: 187.89 - lr: 0.100000\n",
            "2021-06-03 18:09:06,304 epoch 2 - iter 130/267 - loss 1.55762788 - samples/sec: 190.61 - lr: 0.100000\n",
            "2021-06-03 18:09:10,762 epoch 2 - iter 156/267 - loss 1.55745212 - samples/sec: 190.60 - lr: 0.100000\n",
            "2021-06-03 18:09:16,430 epoch 2 - iter 182/267 - loss 1.55655586 - samples/sec: 192.11 - lr: 0.100000\n",
            "2021-06-03 18:09:20,817 epoch 2 - iter 208/267 - loss 1.55698632 - samples/sec: 193.67 - lr: 0.100000\n",
            "2021-06-03 18:09:25,263 epoch 2 - iter 234/267 - loss 1.55683984 - samples/sec: 190.97 - lr: 0.100000\n",
            "2021-06-03 18:09:29,796 epoch 2 - iter 260/267 - loss 1.55534503 - samples/sec: 187.37 - lr: 0.100000\n",
            "2021-06-03 18:09:31,217 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:09:31,219 EPOCH 2 done: loss 1.5562 - lr 0.1000000\n",
            "2021-06-03 18:09:39,917 DEV : loss 1.5292648077011108 - score 0.2834\n",
            "2021-06-03 18:09:40,701 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:09:43,870 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:09:48,979 epoch 3 - iter 26/267 - loss 1.53552329 - samples/sec: 184.60 - lr: 0.100000\n",
            "2021-06-03 18:09:53,525 epoch 3 - iter 52/267 - loss 1.52177194 - samples/sec: 188.72 - lr: 0.100000\n",
            "2021-06-03 18:09:58,056 epoch 3 - iter 78/267 - loss 1.51728776 - samples/sec: 187.57 - lr: 0.100000\n",
            "2021-06-03 18:10:03,900 epoch 3 - iter 104/267 - loss 1.51983330 - samples/sec: 192.88 - lr: 0.100000\n",
            "2021-06-03 18:10:08,294 epoch 3 - iter 130/267 - loss 1.52474108 - samples/sec: 193.08 - lr: 0.100000\n",
            "2021-06-03 18:10:12,768 epoch 3 - iter 156/267 - loss 1.52839398 - samples/sec: 189.84 - lr: 0.100000\n",
            "2021-06-03 18:10:17,380 epoch 3 - iter 182/267 - loss 1.53420041 - samples/sec: 184.52 - lr: 0.100000\n",
            "2021-06-03 18:10:23,085 epoch 3 - iter 208/267 - loss 1.53206687 - samples/sec: 190.70 - lr: 0.100000\n",
            "2021-06-03 18:10:27,519 epoch 3 - iter 234/267 - loss 1.53336407 - samples/sec: 191.89 - lr: 0.100000\n",
            "2021-06-03 18:10:32,046 epoch 3 - iter 260/267 - loss 1.53245015 - samples/sec: 188.11 - lr: 0.100000\n",
            "2021-06-03 18:10:33,429 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:10:33,431 EPOCH 3 done: loss 1.5318 - lr 0.1000000\n",
            "2021-06-03 18:10:40,540 DEV : loss 1.5026493072509766 - score 0.3115\n",
            "2021-06-03 18:10:41,301 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:10:44,488 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:10:51,445 epoch 4 - iter 26/267 - loss 1.50255532 - samples/sec: 129.62 - lr: 0.100000\n",
            "2021-06-03 18:10:55,854 epoch 4 - iter 52/267 - loss 1.50984669 - samples/sec: 192.50 - lr: 0.100000\n",
            "2021-06-03 18:11:00,274 epoch 4 - iter 78/267 - loss 1.50142383 - samples/sec: 192.10 - lr: 0.100000\n",
            "2021-06-03 18:11:04,775 epoch 4 - iter 104/267 - loss 1.50340376 - samples/sec: 189.83 - lr: 0.100000\n",
            "2021-06-03 18:11:10,419 epoch 4 - iter 130/267 - loss 1.50132583 - samples/sec: 194.91 - lr: 0.100000\n",
            "2021-06-03 18:11:14,878 epoch 4 - iter 156/267 - loss 1.50833153 - samples/sec: 189.53 - lr: 0.100000\n",
            "2021-06-03 18:11:19,350 epoch 4 - iter 182/267 - loss 1.50843143 - samples/sec: 189.97 - lr: 0.100000\n",
            "2021-06-03 18:11:23,803 epoch 4 - iter 208/267 - loss 1.50986680 - samples/sec: 190.36 - lr: 0.100000\n",
            "2021-06-03 18:11:28,265 epoch 4 - iter 234/267 - loss 1.50850246 - samples/sec: 189.74 - lr: 0.100000\n",
            "2021-06-03 18:11:34,057 epoch 4 - iter 260/267 - loss 1.50903161 - samples/sec: 189.01 - lr: 0.100000\n",
            "2021-06-03 18:11:35,424 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:11:35,426 EPOCH 4 done: loss 1.5080 - lr 0.1000000\n",
            "2021-06-03 18:11:42,618 DEV : loss 1.5123043060302734 - score 0.3415\n",
            "2021-06-03 18:11:43,427 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:11:46,649 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:11:51,929 epoch 5 - iter 26/267 - loss 1.47774540 - samples/sec: 178.89 - lr: 0.100000\n",
            "2021-06-03 18:11:58,029 epoch 5 - iter 52/267 - loss 1.47868814 - samples/sec: 191.60 - lr: 0.100000\n",
            "2021-06-03 18:12:02,452 epoch 5 - iter 78/267 - loss 1.49152275 - samples/sec: 193.21 - lr: 0.100000\n",
            "2021-06-03 18:12:07,103 epoch 5 - iter 104/267 - loss 1.49130092 - samples/sec: 182.33 - lr: 0.100000\n",
            "2021-06-03 18:12:11,463 epoch 5 - iter 130/267 - loss 1.48756223 - samples/sec: 195.33 - lr: 0.100000\n",
            "2021-06-03 18:12:17,141 epoch 5 - iter 156/267 - loss 1.48809686 - samples/sec: 193.45 - lr: 0.100000\n",
            "2021-06-03 18:12:21,606 epoch 5 - iter 182/267 - loss 1.48961613 - samples/sec: 189.70 - lr: 0.100000\n",
            "2021-06-03 18:12:26,108 epoch 5 - iter 208/267 - loss 1.49152893 - samples/sec: 189.12 - lr: 0.100000\n",
            "2021-06-03 18:12:30,592 epoch 5 - iter 234/267 - loss 1.48947077 - samples/sec: 188.89 - lr: 0.100000\n",
            "2021-06-03 18:12:36,374 epoch 5 - iter 260/267 - loss 1.48475977 - samples/sec: 189.96 - lr: 0.100000\n",
            "2021-06-03 18:12:37,774 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:12:37,775 EPOCH 5 done: loss 1.4856 - lr 0.1000000\n",
            "2021-06-03 18:12:45,029 DEV : loss 1.434011697769165 - score 0.3742\n",
            "2021-06-03 18:12:45,806 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:12:49,018 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:12:54,310 epoch 6 - iter 26/267 - loss 1.48987749 - samples/sec: 175.58 - lr: 0.100000\n",
            "2021-06-03 18:13:00,568 epoch 6 - iter 52/267 - loss 1.48824014 - samples/sec: 184.40 - lr: 0.100000\n",
            "2021-06-03 18:13:05,001 epoch 6 - iter 78/267 - loss 1.48129388 - samples/sec: 192.35 - lr: 0.100000\n",
            "2021-06-03 18:13:09,481 epoch 6 - iter 104/267 - loss 1.47912103 - samples/sec: 189.94 - lr: 0.100000\n",
            "2021-06-03 18:13:13,963 epoch 6 - iter 130/267 - loss 1.47929262 - samples/sec: 190.20 - lr: 0.100000\n",
            "2021-06-03 18:13:18,481 epoch 6 - iter 156/267 - loss 1.47906004 - samples/sec: 188.51 - lr: 0.100000\n",
            "2021-06-03 18:13:24,329 epoch 6 - iter 182/267 - loss 1.47924981 - samples/sec: 187.64 - lr: 0.100000\n",
            "2021-06-03 18:13:28,840 epoch 6 - iter 208/267 - loss 1.47686110 - samples/sec: 188.68 - lr: 0.100000\n",
            "2021-06-03 18:13:33,257 epoch 6 - iter 234/267 - loss 1.47625051 - samples/sec: 191.96 - lr: 0.100000\n",
            "2021-06-03 18:13:37,781 epoch 6 - iter 260/267 - loss 1.47543208 - samples/sec: 187.35 - lr: 0.100000\n",
            "2021-06-03 18:13:39,204 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:13:39,206 EPOCH 6 done: loss 1.4749 - lr 0.1000000\n",
            "2021-06-03 18:13:48,012 DEV : loss 1.45767343044281 - score 0.3179\n",
            "2021-06-03 18:13:48,786 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:13:48,789 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:13:53,989 epoch 7 - iter 26/267 - loss 1.45945444 - samples/sec: 178.11 - lr: 0.100000\n",
            "2021-06-03 18:13:58,794 epoch 7 - iter 52/267 - loss 1.46719312 - samples/sec: 179.48 - lr: 0.100000\n",
            "2021-06-03 18:14:03,443 epoch 7 - iter 78/267 - loss 1.46732769 - samples/sec: 184.43 - lr: 0.100000\n",
            "2021-06-03 18:14:09,529 epoch 7 - iter 104/267 - loss 1.46800831 - samples/sec: 188.59 - lr: 0.100000\n",
            "2021-06-03 18:14:14,089 epoch 7 - iter 130/267 - loss 1.47249657 - samples/sec: 186.33 - lr: 0.100000\n",
            "2021-06-03 18:14:18,572 epoch 7 - iter 156/267 - loss 1.47184461 - samples/sec: 189.92 - lr: 0.100000\n",
            "2021-06-03 18:14:23,116 epoch 7 - iter 182/267 - loss 1.47252635 - samples/sec: 187.10 - lr: 0.100000\n",
            "2021-06-03 18:14:28,897 epoch 7 - iter 208/267 - loss 1.47258388 - samples/sec: 191.69 - lr: 0.100000\n",
            "2021-06-03 18:14:33,401 epoch 7 - iter 234/267 - loss 1.47013259 - samples/sec: 188.80 - lr: 0.100000\n",
            "2021-06-03 18:14:37,977 epoch 7 - iter 260/267 - loss 1.46771598 - samples/sec: 186.38 - lr: 0.100000\n",
            "2021-06-03 18:14:39,413 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:14:39,415 EPOCH 7 done: loss 1.4690 - lr 0.1000000\n",
            "2021-06-03 18:14:46,616 DEV : loss 1.4453024864196777 - score 0.3688\n",
            "2021-06-03 18:14:47,385 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:14:47,387 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:14:58,127 epoch 8 - iter 26/267 - loss 1.47353353 - samples/sec: 188.83 - lr: 0.100000\n",
            "2021-06-03 18:15:03,666 epoch 8 - iter 52/267 - loss 1.45225358 - samples/sec: 196.72 - lr: 0.100000\n",
            "2021-06-03 18:15:08,120 epoch 8 - iter 78/267 - loss 1.45427021 - samples/sec: 190.59 - lr: 0.100000\n",
            "2021-06-03 18:15:12,663 epoch 8 - iter 104/267 - loss 1.45976000 - samples/sec: 186.66 - lr: 0.100000\n",
            "2021-06-03 18:15:18,294 epoch 8 - iter 130/267 - loss 1.46322254 - samples/sec: 150.08 - lr: 0.100000\n",
            "2021-06-03 18:15:22,851 epoch 8 - iter 156/267 - loss 1.46321226 - samples/sec: 186.31 - lr: 0.100000\n",
            "2021-06-03 18:15:27,236 epoch 8 - iter 182/267 - loss 1.46017186 - samples/sec: 193.84 - lr: 0.100000\n",
            "2021-06-03 18:15:31,591 epoch 8 - iter 208/267 - loss 1.45899040 - samples/sec: 195.15 - lr: 0.100000\n",
            "2021-06-03 18:15:37,345 epoch 8 - iter 234/267 - loss 1.45852375 - samples/sec: 146.46 - lr: 0.100000\n",
            "2021-06-03 18:15:41,731 epoch 8 - iter 260/267 - loss 1.45340604 - samples/sec: 194.40 - lr: 0.100000\n",
            "2021-06-03 18:15:43,199 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:15:43,201 EPOCH 8 done: loss 1.4530 - lr 0.1000000\n",
            "2021-06-03 18:15:50,363 DEV : loss 1.3718746900558472 - score 0.386\n",
            "2021-06-03 18:15:51,116 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:15:54,347 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:16:01,200 epoch 9 - iter 26/267 - loss 1.48018635 - samples/sec: 181.09 - lr: 0.100000\n",
            "2021-06-03 18:16:05,675 epoch 9 - iter 52/267 - loss 1.46360327 - samples/sec: 189.15 - lr: 0.100000\n",
            "2021-06-03 18:16:10,192 epoch 9 - iter 78/267 - loss 1.45081129 - samples/sec: 188.90 - lr: 0.100000\n",
            "2021-06-03 18:16:14,784 epoch 9 - iter 104/267 - loss 1.45487633 - samples/sec: 184.82 - lr: 0.100000\n",
            "2021-06-03 18:16:19,277 epoch 9 - iter 130/267 - loss 1.45447844 - samples/sec: 188.29 - lr: 0.100000\n",
            "2021-06-03 18:16:25,136 epoch 9 - iter 156/267 - loss 1.44669173 - samples/sec: 188.33 - lr: 0.100000\n",
            "2021-06-03 18:16:29,632 epoch 9 - iter 182/267 - loss 1.44613070 - samples/sec: 188.57 - lr: 0.100000\n",
            "2021-06-03 18:16:34,107 epoch 9 - iter 208/267 - loss 1.44662131 - samples/sec: 189.26 - lr: 0.100000\n",
            "2021-06-03 18:16:39,954 epoch 9 - iter 234/267 - loss 1.44552868 - samples/sec: 188.41 - lr: 0.100000\n",
            "2021-06-03 18:16:44,469 epoch 9 - iter 260/267 - loss 1.44245994 - samples/sec: 187.88 - lr: 0.100000\n",
            "2021-06-03 18:16:45,850 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:16:45,852 EPOCH 9 done: loss 1.4414 - lr 0.1000000\n",
            "2021-06-03 18:16:53,263 DEV : loss 1.4912729263305664 - score 0.347\n",
            "2021-06-03 18:16:54,087 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:16:54,089 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:16:59,401 epoch 10 - iter 26/267 - loss 1.43467973 - samples/sec: 176.38 - lr: 0.100000\n",
            "2021-06-03 18:17:05,710 epoch 10 - iter 52/267 - loss 1.41971922 - samples/sec: 185.16 - lr: 0.100000\n",
            "2021-06-03 18:17:10,246 epoch 10 - iter 78/267 - loss 1.42008213 - samples/sec: 187.82 - lr: 0.100000\n",
            "2021-06-03 18:17:14,853 epoch 10 - iter 104/267 - loss 1.42338515 - samples/sec: 183.85 - lr: 0.100000\n",
            "2021-06-03 18:17:19,419 epoch 10 - iter 130/267 - loss 1.42011575 - samples/sec: 185.86 - lr: 0.100000\n",
            "2021-06-03 18:17:25,152 epoch 10 - iter 156/267 - loss 1.41842567 - samples/sec: 192.40 - lr: 0.100000\n",
            "2021-06-03 18:17:29,595 epoch 10 - iter 182/267 - loss 1.42396027 - samples/sec: 191.12 - lr: 0.100000\n",
            "2021-06-03 18:17:34,261 epoch 10 - iter 208/267 - loss 1.42572930 - samples/sec: 183.03 - lr: 0.100000\n",
            "2021-06-03 18:17:38,801 epoch 10 - iter 234/267 - loss 1.42385484 - samples/sec: 186.95 - lr: 0.100000\n",
            "2021-06-03 18:17:44,734 epoch 10 - iter 260/267 - loss 1.42248690 - samples/sec: 185.01 - lr: 0.100000\n",
            "2021-06-03 18:17:46,116 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:17:46,118 EPOCH 10 done: loss 1.4234 - lr 0.1000000\n",
            "2021-06-03 18:17:53,333 DEV : loss 1.3686164617538452 - score 0.3824\n",
            "2021-06-03 18:17:54,118 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:17:54,120 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:17:59,391 epoch 11 - iter 26/267 - loss 1.38795887 - samples/sec: 176.85 - lr: 0.100000\n",
            "2021-06-03 18:18:05,758 epoch 11 - iter 52/267 - loss 1.40036541 - samples/sec: 182.37 - lr: 0.100000\n",
            "2021-06-03 18:18:10,120 epoch 11 - iter 78/267 - loss 1.39180230 - samples/sec: 194.98 - lr: 0.100000\n",
            "2021-06-03 18:18:14,677 epoch 11 - iter 104/267 - loss 1.39590481 - samples/sec: 186.59 - lr: 0.100000\n",
            "2021-06-03 18:18:19,188 epoch 11 - iter 130/267 - loss 1.39941431 - samples/sec: 189.02 - lr: 0.100000\n",
            "2021-06-03 18:18:25,012 epoch 11 - iter 156/267 - loss 1.40561965 - samples/sec: 145.38 - lr: 0.100000\n",
            "2021-06-03 18:18:29,542 epoch 11 - iter 182/267 - loss 1.40575167 - samples/sec: 187.70 - lr: 0.100000\n",
            "2021-06-03 18:18:34,113 epoch 11 - iter 208/267 - loss 1.40942962 - samples/sec: 186.70 - lr: 0.100000\n",
            "2021-06-03 18:18:38,657 epoch 11 - iter 234/267 - loss 1.41023966 - samples/sec: 186.95 - lr: 0.100000\n",
            "2021-06-03 18:18:43,032 epoch 11 - iter 260/267 - loss 1.41027425 - samples/sec: 193.23 - lr: 0.100000\n",
            "2021-06-03 18:18:45,791 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:18:45,793 EPOCH 11 done: loss 1.4120 - lr 0.1000000\n",
            "2021-06-03 18:18:52,997 DEV : loss 1.3659861087799072 - score 0.4105\n",
            "2021-06-03 18:18:53,773 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:18:56,934 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:19:02,181 epoch 12 - iter 26/267 - loss 1.41832436 - samples/sec: 178.68 - lr: 0.100000\n",
            "2021-06-03 18:19:07,011 epoch 12 - iter 52/267 - loss 1.41415273 - samples/sec: 177.91 - lr: 0.100000\n",
            "2021-06-03 18:19:13,148 epoch 12 - iter 78/267 - loss 1.41111742 - samples/sec: 187.38 - lr: 0.100000\n",
            "2021-06-03 18:19:17,720 epoch 12 - iter 104/267 - loss 1.40817582 - samples/sec: 186.21 - lr: 0.100000\n",
            "2021-06-03 18:19:22,220 epoch 12 - iter 130/267 - loss 1.40891464 - samples/sec: 188.40 - lr: 0.100000\n",
            "2021-06-03 18:19:26,790 epoch 12 - iter 156/267 - loss 1.40655748 - samples/sec: 185.52 - lr: 0.100000\n",
            "2021-06-03 18:19:31,311 epoch 12 - iter 182/267 - loss 1.40515333 - samples/sec: 187.11 - lr: 0.100000\n",
            "2021-06-03 18:19:37,379 epoch 12 - iter 208/267 - loss 1.40106948 - samples/sec: 182.31 - lr: 0.100000\n",
            "2021-06-03 18:19:41,958 epoch 12 - iter 234/267 - loss 1.40370282 - samples/sec: 185.91 - lr: 0.100000\n",
            "2021-06-03 18:19:46,668 epoch 12 - iter 260/267 - loss 1.40043492 - samples/sec: 180.66 - lr: 0.100000\n",
            "2021-06-03 18:19:48,132 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:19:48,134 EPOCH 12 done: loss 1.3992 - lr 0.1000000\n",
            "2021-06-03 18:19:57,000 DEV : loss 1.3922005891799927 - score 0.3769\n",
            "2021-06-03 18:19:57,776 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:19:57,778 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:20:03,305 epoch 13 - iter 26/267 - loss 1.41966662 - samples/sec: 169.09 - lr: 0.100000\n",
            "2021-06-03 18:20:07,975 epoch 13 - iter 52/267 - loss 1.37870068 - samples/sec: 184.57 - lr: 0.100000\n",
            "2021-06-03 18:20:12,699 epoch 13 - iter 78/267 - loss 1.39525863 - samples/sec: 181.37 - lr: 0.100000\n",
            "2021-06-03 18:20:17,567 epoch 13 - iter 104/267 - loss 1.39632514 - samples/sec: 175.11 - lr: 0.100000\n",
            "2021-06-03 18:20:23,968 epoch 13 - iter 130/267 - loss 1.39298695 - samples/sec: 181.00 - lr: 0.100000\n",
            "2021-06-03 18:20:28,531 epoch 13 - iter 156/267 - loss 1.39029155 - samples/sec: 187.07 - lr: 0.100000\n",
            "2021-06-03 18:20:33,247 epoch 13 - iter 182/267 - loss 1.39064030 - samples/sec: 180.51 - lr: 0.100000\n",
            "2021-06-03 18:20:37,875 epoch 13 - iter 208/267 - loss 1.39211880 - samples/sec: 184.47 - lr: 0.100000\n",
            "2021-06-03 18:20:44,099 epoch 13 - iter 234/267 - loss 1.39302659 - samples/sec: 179.30 - lr: 0.100000\n",
            "2021-06-03 18:20:48,713 epoch 13 - iter 260/267 - loss 1.39364428 - samples/sec: 183.86 - lr: 0.100000\n",
            "2021-06-03 18:20:50,103 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:20:50,105 EPOCH 13 done: loss 1.3938 - lr 0.1000000\n",
            "2021-06-03 18:20:57,292 DEV : loss 1.321976661682129 - score 0.4242\n",
            "2021-06-03 18:20:58,077 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:21:01,350 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:21:06,664 epoch 14 - iter 26/267 - loss 1.38541803 - samples/sec: 175.61 - lr: 0.100000\n",
            "2021-06-03 18:21:12,853 epoch 14 - iter 52/267 - loss 1.40360670 - samples/sec: 188.28 - lr: 0.100000\n",
            "2021-06-03 18:21:17,322 epoch 14 - iter 78/267 - loss 1.39633276 - samples/sec: 189.97 - lr: 0.100000\n",
            "2021-06-03 18:21:21,964 epoch 14 - iter 104/267 - loss 1.38965943 - samples/sec: 183.87 - lr: 0.100000\n",
            "2021-06-03 18:21:26,512 epoch 14 - iter 130/267 - loss 1.38878815 - samples/sec: 187.31 - lr: 0.100000\n",
            "2021-06-03 18:21:31,005 epoch 14 - iter 156/267 - loss 1.38776220 - samples/sec: 189.30 - lr: 0.100000\n",
            "2021-06-03 18:21:36,671 epoch 14 - iter 182/267 - loss 1.38812240 - samples/sec: 193.32 - lr: 0.100000\n",
            "2021-06-03 18:21:41,099 epoch 14 - iter 208/267 - loss 1.38839671 - samples/sec: 191.76 - lr: 0.100000\n",
            "2021-06-03 18:21:45,640 epoch 14 - iter 234/267 - loss 1.38669690 - samples/sec: 187.31 - lr: 0.100000\n",
            "2021-06-03 18:21:50,102 epoch 14 - iter 260/267 - loss 1.38323680 - samples/sec: 190.25 - lr: 0.100000\n",
            "2021-06-03 18:21:51,545 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:21:51,547 EPOCH 14 done: loss 1.3841 - lr 0.1000000\n",
            "2021-06-03 18:22:00,385 DEV : loss 1.385625958442688 - score 0.3678\n",
            "2021-06-03 18:22:01,166 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:22:01,168 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:22:06,535 epoch 15 - iter 26/267 - loss 1.40921101 - samples/sec: 173.37 - lr: 0.100000\n",
            "2021-06-03 18:22:11,162 epoch 15 - iter 52/267 - loss 1.36149595 - samples/sec: 186.63 - lr: 0.100000\n",
            "2021-06-03 18:22:15,783 epoch 15 - iter 78/267 - loss 1.37298854 - samples/sec: 184.81 - lr: 0.100000\n",
            "2021-06-03 18:22:21,787 epoch 15 - iter 104/267 - loss 1.37266213 - samples/sec: 188.28 - lr: 0.100000\n",
            "2021-06-03 18:22:26,308 epoch 15 - iter 130/267 - loss 1.37546039 - samples/sec: 188.74 - lr: 0.100000\n",
            "2021-06-03 18:22:30,945 epoch 15 - iter 156/267 - loss 1.37785561 - samples/sec: 183.03 - lr: 0.100000\n",
            "2021-06-03 18:22:35,382 epoch 15 - iter 182/267 - loss 1.37604029 - samples/sec: 190.93 - lr: 0.100000\n",
            "2021-06-03 18:22:41,320 epoch 15 - iter 208/267 - loss 1.37882121 - samples/sec: 142.38 - lr: 0.100000\n",
            "2021-06-03 18:22:45,765 epoch 15 - iter 234/267 - loss 1.37549263 - samples/sec: 190.42 - lr: 0.100000\n",
            "2021-06-03 18:22:50,310 epoch 15 - iter 260/267 - loss 1.37839183 - samples/sec: 186.52 - lr: 0.100000\n",
            "2021-06-03 18:22:51,730 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:22:51,731 EPOCH 15 done: loss 1.3781 - lr 0.1000000\n",
            "2021-06-03 18:23:00,649 DEV : loss 1.3068249225616455 - score 0.426\n",
            "2021-06-03 18:23:01,430 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:23:04,626 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:23:10,022 epoch 16 - iter 26/267 - loss 1.38057355 - samples/sec: 175.71 - lr: 0.100000\n",
            "2021-06-03 18:23:14,757 epoch 16 - iter 52/267 - loss 1.37809165 - samples/sec: 180.43 - lr: 0.100000\n",
            "2021-06-03 18:23:19,453 epoch 16 - iter 78/267 - loss 1.38209200 - samples/sec: 181.24 - lr: 0.100000\n",
            "2021-06-03 18:23:25,440 epoch 16 - iter 104/267 - loss 1.36927333 - samples/sec: 189.91 - lr: 0.100000\n",
            "2021-06-03 18:23:29,883 epoch 16 - iter 130/267 - loss 1.37231565 - samples/sec: 190.66 - lr: 0.100000\n",
            "2021-06-03 18:23:34,440 epoch 16 - iter 156/267 - loss 1.37120865 - samples/sec: 185.94 - lr: 0.100000\n",
            "2021-06-03 18:23:38,863 epoch 16 - iter 182/267 - loss 1.37279224 - samples/sec: 192.58 - lr: 0.100000\n",
            "2021-06-03 18:23:44,617 epoch 16 - iter 208/267 - loss 1.36741524 - samples/sec: 189.85 - lr: 0.100000\n",
            "2021-06-03 18:23:49,032 epoch 16 - iter 234/267 - loss 1.36993593 - samples/sec: 192.00 - lr: 0.100000\n",
            "2021-06-03 18:23:53,545 epoch 16 - iter 260/267 - loss 1.37002273 - samples/sec: 188.28 - lr: 0.100000\n",
            "2021-06-03 18:23:54,990 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:23:54,992 EPOCH 16 done: loss 1.3702 - lr 0.1000000\n",
            "2021-06-03 18:24:03,693 DEV : loss 1.3438165187835693 - score 0.4015\n",
            "2021-06-03 18:24:04,457 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:24:04,459 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:24:09,629 epoch 17 - iter 26/267 - loss 1.39132806 - samples/sec: 182.06 - lr: 0.100000\n",
            "2021-06-03 18:24:14,450 epoch 17 - iter 52/267 - loss 1.38215081 - samples/sec: 179.24 - lr: 0.100000\n",
            "2021-06-03 18:24:18,932 epoch 17 - iter 78/267 - loss 1.36057059 - samples/sec: 190.55 - lr: 0.100000\n",
            "2021-06-03 18:24:24,928 epoch 17 - iter 104/267 - loss 1.36838772 - samples/sec: 140.86 - lr: 0.100000\n",
            "2021-06-03 18:24:29,346 epoch 17 - iter 130/267 - loss 1.35958144 - samples/sec: 193.05 - lr: 0.100000\n",
            "2021-06-03 18:24:33,959 epoch 17 - iter 156/267 - loss 1.36773486 - samples/sec: 184.91 - lr: 0.100000\n",
            "2021-06-03 18:24:38,390 epoch 17 - iter 182/267 - loss 1.37007630 - samples/sec: 191.59 - lr: 0.100000\n",
            "2021-06-03 18:24:44,190 epoch 17 - iter 208/267 - loss 1.36992256 - samples/sec: 190.17 - lr: 0.100000\n",
            "2021-06-03 18:24:48,729 epoch 17 - iter 234/267 - loss 1.36860865 - samples/sec: 187.70 - lr: 0.100000\n",
            "2021-06-03 18:24:53,204 epoch 17 - iter 260/267 - loss 1.36709845 - samples/sec: 189.70 - lr: 0.100000\n",
            "2021-06-03 18:24:54,596 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:24:54,598 EPOCH 17 done: loss 1.3667 - lr 0.1000000\n",
            "2021-06-03 18:25:03,360 DEV : loss 1.3014328479766846 - score 0.426\n",
            "2021-06-03 18:25:04,138 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:25:07,338 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:25:12,595 epoch 18 - iter 26/267 - loss 1.32585350 - samples/sec: 180.33 - lr: 0.100000\n",
            "2021-06-03 18:25:17,257 epoch 18 - iter 52/267 - loss 1.32167837 - samples/sec: 183.16 - lr: 0.100000\n",
            "2021-06-03 18:25:21,903 epoch 18 - iter 78/267 - loss 1.34929036 - samples/sec: 183.73 - lr: 0.100000\n",
            "2021-06-03 18:25:28,054 epoch 18 - iter 104/267 - loss 1.35381792 - samples/sec: 137.59 - lr: 0.100000\n",
            "2021-06-03 18:25:32,596 epoch 18 - iter 130/267 - loss 1.34823586 - samples/sec: 186.47 - lr: 0.100000\n",
            "2021-06-03 18:25:37,071 epoch 18 - iter 156/267 - loss 1.34699654 - samples/sec: 189.72 - lr: 0.100000\n",
            "2021-06-03 18:25:41,462 epoch 18 - iter 182/267 - loss 1.34795352 - samples/sec: 193.41 - lr: 0.100000\n",
            "2021-06-03 18:25:47,393 epoch 18 - iter 208/267 - loss 1.34784924 - samples/sec: 185.37 - lr: 0.100000\n",
            "2021-06-03 18:25:51,965 epoch 18 - iter 234/267 - loss 1.34709681 - samples/sec: 185.12 - lr: 0.100000\n",
            "2021-06-03 18:25:56,429 epoch 18 - iter 260/267 - loss 1.34683738 - samples/sec: 190.23 - lr: 0.100000\n",
            "2021-06-03 18:25:57,806 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:25:57,808 EPOCH 18 done: loss 1.3464 - lr 0.1000000\n",
            "2021-06-03 18:26:06,590 DEV : loss 1.3628509044647217 - score 0.3742\n",
            "2021-06-03 18:26:07,372 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:26:07,375 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:26:12,568 epoch 19 - iter 26/267 - loss 1.32309921 - samples/sec: 179.77 - lr: 0.100000\n",
            "2021-06-03 18:26:17,338 epoch 19 - iter 52/267 - loss 1.34759372 - samples/sec: 179.89 - lr: 0.100000\n",
            "2021-06-03 18:26:22,009 epoch 19 - iter 78/267 - loss 1.35031905 - samples/sec: 184.05 - lr: 0.100000\n",
            "2021-06-03 18:26:28,255 epoch 19 - iter 104/267 - loss 1.34540091 - samples/sec: 181.80 - lr: 0.100000\n",
            "2021-06-03 18:26:32,825 epoch 19 - iter 130/267 - loss 1.34831474 - samples/sec: 186.12 - lr: 0.100000\n",
            "2021-06-03 18:26:37,416 epoch 19 - iter 156/267 - loss 1.34141627 - samples/sec: 185.28 - lr: 0.100000\n",
            "2021-06-03 18:26:41,832 epoch 19 - iter 182/267 - loss 1.34740661 - samples/sec: 191.79 - lr: 0.100000\n",
            "2021-06-03 18:26:47,668 epoch 19 - iter 208/267 - loss 1.34481165 - samples/sec: 188.99 - lr: 0.100000\n",
            "2021-06-03 18:26:52,114 epoch 19 - iter 234/267 - loss 1.34264174 - samples/sec: 190.99 - lr: 0.100000\n",
            "2021-06-03 18:26:56,701 epoch 19 - iter 260/267 - loss 1.34531474 - samples/sec: 185.38 - lr: 0.100000\n",
            "2021-06-03 18:26:58,091 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:26:58,093 EPOCH 19 done: loss 1.3445 - lr 0.1000000\n",
            "2021-06-03 18:27:07,067 DEV : loss 1.2833856344223022 - score 0.4332\n",
            "2021-06-03 18:27:07,834 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:27:10,981 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:27:16,259 epoch 20 - iter 26/267 - loss 1.31730426 - samples/sec: 179.04 - lr: 0.100000\n",
            "2021-06-03 18:27:20,941 epoch 20 - iter 52/267 - loss 1.32843187 - samples/sec: 182.86 - lr: 0.100000\n",
            "2021-06-03 18:27:25,518 epoch 20 - iter 78/267 - loss 1.33220610 - samples/sec: 186.62 - lr: 0.100000\n",
            "2021-06-03 18:27:31,504 epoch 20 - iter 104/267 - loss 1.33261795 - samples/sec: 187.99 - lr: 0.100000\n",
            "2021-06-03 18:27:36,042 epoch 20 - iter 130/267 - loss 1.33774114 - samples/sec: 186.85 - lr: 0.100000\n",
            "2021-06-03 18:27:40,493 epoch 20 - iter 156/267 - loss 1.33509145 - samples/sec: 191.67 - lr: 0.100000\n",
            "2021-06-03 18:27:45,100 epoch 20 - iter 182/267 - loss 1.33481140 - samples/sec: 184.53 - lr: 0.100000\n",
            "2021-06-03 18:27:50,894 epoch 20 - iter 208/267 - loss 1.33399424 - samples/sec: 145.62 - lr: 0.100000\n",
            "2021-06-03 18:27:55,440 epoch 20 - iter 234/267 - loss 1.33543732 - samples/sec: 187.27 - lr: 0.100000\n",
            "2021-06-03 18:27:59,870 epoch 20 - iter 260/267 - loss 1.33302180 - samples/sec: 191.46 - lr: 0.100000\n",
            "2021-06-03 18:28:01,337 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:28:01,339 EPOCH 20 done: loss 1.3341 - lr 0.1000000\n",
            "2021-06-03 18:28:10,041 DEV : loss 1.2830673456192017 - score 0.4405\n",
            "2021-06-03 18:28:10,806 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:28:14,047 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:28:19,370 epoch 21 - iter 26/267 - loss 1.33845869 - samples/sec: 174.93 - lr: 0.100000\n",
            "2021-06-03 18:28:24,124 epoch 21 - iter 52/267 - loss 1.33095093 - samples/sec: 180.60 - lr: 0.100000\n",
            "2021-06-03 18:28:28,838 epoch 21 - iter 78/267 - loss 1.32797822 - samples/sec: 183.04 - lr: 0.100000\n",
            "2021-06-03 18:28:33,552 epoch 21 - iter 104/267 - loss 1.34536296 - samples/sec: 180.96 - lr: 0.100000\n",
            "2021-06-03 18:28:39,662 epoch 21 - iter 130/267 - loss 1.33916496 - samples/sec: 138.44 - lr: 0.100000\n",
            "2021-06-03 18:28:44,242 epoch 21 - iter 156/267 - loss 1.33288561 - samples/sec: 186.32 - lr: 0.100000\n",
            "2021-06-03 18:28:48,946 epoch 21 - iter 182/267 - loss 1.33074980 - samples/sec: 180.42 - lr: 0.100000\n",
            "2021-06-03 18:28:53,522 epoch 21 - iter 208/267 - loss 1.33131183 - samples/sec: 185.54 - lr: 0.100000\n",
            "2021-06-03 18:28:59,585 epoch 21 - iter 234/267 - loss 1.33060251 - samples/sec: 139.28 - lr: 0.100000\n",
            "2021-06-03 18:29:04,133 epoch 21 - iter 260/267 - loss 1.32819018 - samples/sec: 186.09 - lr: 0.100000\n",
            "2021-06-03 18:29:05,569 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:29:05,571 EPOCH 21 done: loss 1.3295 - lr 0.1000000\n",
            "2021-06-03 18:29:12,994 DEV : loss 1.2812750339508057 - score 0.4387\n",
            "2021-06-03 18:29:13,795 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:29:13,797 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:29:20,796 epoch 22 - iter 26/267 - loss 1.28622310 - samples/sec: 129.83 - lr: 0.100000\n",
            "2021-06-03 18:29:25,272 epoch 22 - iter 52/267 - loss 1.33019954 - samples/sec: 189.66 - lr: 0.100000\n",
            "2021-06-03 18:29:29,845 epoch 22 - iter 78/267 - loss 1.32737541 - samples/sec: 186.32 - lr: 0.100000\n",
            "2021-06-03 18:29:34,495 epoch 22 - iter 104/267 - loss 1.32944895 - samples/sec: 182.09 - lr: 0.100000\n",
            "2021-06-03 18:29:40,275 epoch 22 - iter 130/267 - loss 1.33057461 - samples/sec: 145.58 - lr: 0.100000\n",
            "2021-06-03 18:29:44,664 epoch 22 - iter 156/267 - loss 1.32975632 - samples/sec: 193.53 - lr: 0.100000\n",
            "2021-06-03 18:29:49,119 epoch 22 - iter 182/267 - loss 1.32629912 - samples/sec: 190.26 - lr: 0.100000\n",
            "2021-06-03 18:29:53,655 epoch 22 - iter 208/267 - loss 1.32459237 - samples/sec: 187.74 - lr: 0.100000\n",
            "2021-06-03 18:29:58,189 epoch 22 - iter 234/267 - loss 1.32423800 - samples/sec: 187.64 - lr: 0.100000\n",
            "2021-06-03 18:30:03,997 epoch 22 - iter 260/267 - loss 1.32325645 - samples/sec: 189.44 - lr: 0.100000\n",
            "2021-06-03 18:30:05,408 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:30:05,410 EPOCH 22 done: loss 1.3229 - lr 0.1000000\n",
            "2021-06-03 18:30:12,731 DEV : loss 1.2966969013214111 - score 0.4187\n",
            "2021-06-03 18:30:13,521 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:30:13,523 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:30:18,853 epoch 23 - iter 26/267 - loss 1.30107607 - samples/sec: 173.74 - lr: 0.100000\n",
            "2021-06-03 18:30:25,304 epoch 23 - iter 52/267 - loss 1.28817520 - samples/sec: 179.27 - lr: 0.100000\n",
            "2021-06-03 18:30:29,798 epoch 23 - iter 78/267 - loss 1.30089067 - samples/sec: 189.15 - lr: 0.100000\n",
            "2021-06-03 18:30:34,395 epoch 23 - iter 104/267 - loss 1.30210848 - samples/sec: 184.56 - lr: 0.100000\n",
            "2021-06-03 18:30:38,893 epoch 23 - iter 130/267 - loss 1.30356004 - samples/sec: 189.96 - lr: 0.100000\n",
            "2021-06-03 18:30:43,359 epoch 23 - iter 156/267 - loss 1.30353386 - samples/sec: 190.45 - lr: 0.100000\n",
            "2021-06-03 18:30:49,302 epoch 23 - iter 182/267 - loss 1.30717534 - samples/sec: 186.45 - lr: 0.100000\n",
            "2021-06-03 18:30:53,812 epoch 23 - iter 208/267 - loss 1.30954229 - samples/sec: 189.78 - lr: 0.100000\n",
            "2021-06-03 18:30:58,329 epoch 23 - iter 234/267 - loss 1.30914818 - samples/sec: 187.87 - lr: 0.100000\n",
            "2021-06-03 18:31:02,860 epoch 23 - iter 260/267 - loss 1.31085336 - samples/sec: 187.19 - lr: 0.100000\n",
            "2021-06-03 18:31:04,251 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:31:04,253 EPOCH 23 done: loss 1.3108 - lr 0.1000000\n",
            "2021-06-03 18:31:13,052 DEV : loss 1.2966302633285522 - score 0.4142\n",
            "2021-06-03 18:31:13,838 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:31:13,841 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:31:19,159 epoch 24 - iter 26/267 - loss 1.33244310 - samples/sec: 176.68 - lr: 0.100000\n",
            "2021-06-03 18:31:24,045 epoch 24 - iter 52/267 - loss 1.33777732 - samples/sec: 175.95 - lr: 0.100000\n",
            "2021-06-03 18:31:30,160 epoch 24 - iter 78/267 - loss 1.31795488 - samples/sec: 137.98 - lr: 0.100000\n",
            "2021-06-03 18:31:34,639 epoch 24 - iter 104/267 - loss 1.31042663 - samples/sec: 189.46 - lr: 0.100000\n",
            "2021-06-03 18:31:39,074 epoch 24 - iter 130/267 - loss 1.30681142 - samples/sec: 191.96 - lr: 0.100000\n",
            "2021-06-03 18:31:43,609 epoch 24 - iter 156/267 - loss 1.30761398 - samples/sec: 186.85 - lr: 0.100000\n",
            "2021-06-03 18:31:48,160 epoch 24 - iter 182/267 - loss 1.30469720 - samples/sec: 186.96 - lr: 0.100000\n",
            "2021-06-03 18:31:54,114 epoch 24 - iter 208/267 - loss 1.29999653 - samples/sec: 183.74 - lr: 0.100000\n",
            "2021-06-03 18:31:58,699 epoch 24 - iter 234/267 - loss 1.29712359 - samples/sec: 185.93 - lr: 0.100000\n",
            "2021-06-03 18:32:03,249 epoch 24 - iter 260/267 - loss 1.30149891 - samples/sec: 186.28 - lr: 0.100000\n",
            "2021-06-03 18:32:04,695 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:32:04,698 EPOCH 24 done: loss 1.3024 - lr 0.1000000\n",
            "2021-06-03 18:32:13,572 DEV : loss 1.2599409818649292 - score 0.4378\n",
            "Epoch    24: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2021-06-03 18:32:14,342 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 18:32:14,346 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:32:19,730 epoch 25 - iter 26/267 - loss 1.30590133 - samples/sec: 173.05 - lr: 0.050000\n",
            "2021-06-03 18:32:24,241 epoch 25 - iter 52/267 - loss 1.28165982 - samples/sec: 190.43 - lr: 0.050000\n",
            "2021-06-03 18:32:28,961 epoch 25 - iter 78/267 - loss 1.28770183 - samples/sec: 180.93 - lr: 0.050000\n",
            "2021-06-03 18:32:35,094 epoch 25 - iter 104/267 - loss 1.27756417 - samples/sec: 186.39 - lr: 0.050000\n",
            "2021-06-03 18:32:39,650 epoch 25 - iter 130/267 - loss 1.27269160 - samples/sec: 187.26 - lr: 0.050000\n",
            "2021-06-03 18:32:44,232 epoch 25 - iter 156/267 - loss 1.27732827 - samples/sec: 185.51 - lr: 0.050000\n",
            "2021-06-03 18:32:48,889 epoch 25 - iter 182/267 - loss 1.28374376 - samples/sec: 182.71 - lr: 0.050000\n",
            "2021-06-03 18:32:54,754 epoch 25 - iter 208/267 - loss 1.28276803 - samples/sec: 144.30 - lr: 0.050000\n",
            "2021-06-03 18:32:59,313 epoch 25 - iter 234/267 - loss 1.27965152 - samples/sec: 187.04 - lr: 0.050000\n",
            "2021-06-03 18:33:03,795 epoch 25 - iter 260/267 - loss 1.28191940 - samples/sec: 189.01 - lr: 0.050000\n",
            "2021-06-03 18:33:05,207 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:33:05,209 EPOCH 25 done: loss 1.2808 - lr 0.0500000\n",
            "2021-06-03 18:33:13,783 DEV : loss 1.2963993549346924 - score 0.4387\n",
            "2021-06-03 18:33:14,534 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:33:14,537 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:33:19,851 epoch 26 - iter 26/267 - loss 1.29933620 - samples/sec: 176.43 - lr: 0.050000\n",
            "2021-06-03 18:33:24,499 epoch 26 - iter 52/267 - loss 1.28725110 - samples/sec: 183.59 - lr: 0.050000\n",
            "2021-06-03 18:33:29,372 epoch 26 - iter 78/267 - loss 1.28123979 - samples/sec: 176.58 - lr: 0.050000\n",
            "2021-06-03 18:33:35,360 epoch 26 - iter 104/267 - loss 1.27553304 - samples/sec: 189.02 - lr: 0.050000\n",
            "2021-06-03 18:33:39,891 epoch 26 - iter 130/267 - loss 1.27906430 - samples/sec: 186.90 - lr: 0.050000\n",
            "2021-06-03 18:33:44,415 epoch 26 - iter 156/267 - loss 1.27117523 - samples/sec: 187.70 - lr: 0.050000\n",
            "2021-06-03 18:33:48,852 epoch 26 - iter 182/267 - loss 1.27430534 - samples/sec: 190.64 - lr: 0.050000\n",
            "2021-06-03 18:33:53,317 epoch 26 - iter 208/267 - loss 1.27472861 - samples/sec: 189.00 - lr: 0.050000\n",
            "2021-06-03 18:33:59,262 epoch 26 - iter 234/267 - loss 1.27317973 - samples/sec: 183.13 - lr: 0.050000\n",
            "2021-06-03 18:34:03,772 epoch 26 - iter 260/267 - loss 1.27142282 - samples/sec: 187.69 - lr: 0.050000\n",
            "2021-06-03 18:34:05,157 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:34:05,159 EPOCH 26 done: loss 1.2730 - lr 0.0500000\n",
            "2021-06-03 18:34:12,381 DEV : loss 1.2949364185333252 - score 0.4205\n",
            "2021-06-03 18:34:13,151 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:34:13,154 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:34:19,990 epoch 27 - iter 26/267 - loss 1.30357019 - samples/sec: 183.87 - lr: 0.050000\n",
            "2021-06-03 18:34:24,415 epoch 27 - iter 52/267 - loss 1.29956581 - samples/sec: 192.37 - lr: 0.050000\n",
            "2021-06-03 18:34:28,850 epoch 27 - iter 78/267 - loss 1.29302523 - samples/sec: 191.64 - lr: 0.050000\n",
            "2021-06-03 18:34:33,313 epoch 27 - iter 104/267 - loss 1.28190838 - samples/sec: 190.83 - lr: 0.050000\n",
            "2021-06-03 18:34:37,885 epoch 27 - iter 130/267 - loss 1.28387033 - samples/sec: 186.04 - lr: 0.050000\n",
            "2021-06-03 18:34:43,778 epoch 27 - iter 156/267 - loss 1.27740622 - samples/sec: 184.71 - lr: 0.050000\n",
            "2021-06-03 18:34:48,300 epoch 27 - iter 182/267 - loss 1.28205114 - samples/sec: 187.71 - lr: 0.050000\n",
            "2021-06-03 18:34:52,870 epoch 27 - iter 208/267 - loss 1.27573900 - samples/sec: 186.79 - lr: 0.050000\n",
            "2021-06-03 18:34:57,515 epoch 27 - iter 234/267 - loss 1.27146506 - samples/sec: 183.88 - lr: 0.050000\n",
            "2021-06-03 18:35:03,494 epoch 27 - iter 260/267 - loss 1.27505567 - samples/sec: 140.95 - lr: 0.050000\n",
            "2021-06-03 18:35:04,946 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:35:04,948 EPOCH 27 done: loss 1.2753 - lr 0.0500000\n",
            "2021-06-03 18:35:12,288 DEV : loss 1.251914143562317 - score 0.4487\n",
            "2021-06-03 18:35:13,079 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:35:16,299 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:35:21,696 epoch 28 - iter 26/267 - loss 1.29280694 - samples/sec: 173.97 - lr: 0.050000\n",
            "2021-06-03 18:35:26,270 epoch 28 - iter 52/267 - loss 1.28002531 - samples/sec: 186.09 - lr: 0.050000\n",
            "2021-06-03 18:35:32,295 epoch 28 - iter 78/267 - loss 1.26818415 - samples/sec: 190.18 - lr: 0.050000\n",
            "2021-06-03 18:35:36,771 epoch 28 - iter 104/267 - loss 1.27063750 - samples/sec: 189.11 - lr: 0.050000\n",
            "2021-06-03 18:35:41,210 epoch 28 - iter 130/267 - loss 1.26753172 - samples/sec: 190.60 - lr: 0.050000\n",
            "2021-06-03 18:35:45,770 epoch 28 - iter 156/267 - loss 1.27604139 - samples/sec: 185.84 - lr: 0.050000\n",
            "2021-06-03 18:35:51,775 epoch 28 - iter 182/267 - loss 1.27407150 - samples/sec: 140.63 - lr: 0.050000\n",
            "2021-06-03 18:35:56,317 epoch 28 - iter 208/267 - loss 1.27176313 - samples/sec: 186.64 - lr: 0.050000\n",
            "2021-06-03 18:36:00,842 epoch 28 - iter 234/267 - loss 1.27338569 - samples/sec: 188.27 - lr: 0.050000\n",
            "2021-06-03 18:36:06,648 epoch 28 - iter 260/267 - loss 1.27206565 - samples/sec: 145.05 - lr: 0.050000\n",
            "2021-06-03 18:36:08,063 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:36:08,066 EPOCH 28 done: loss 1.2718 - lr 0.0500000\n",
            "2021-06-03 18:36:15,266 DEV : loss 1.2412278652191162 - score 0.445\n",
            "2021-06-03 18:36:16,054 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:36:16,057 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:36:21,354 epoch 29 - iter 26/267 - loss 1.27981640 - samples/sec: 177.07 - lr: 0.050000\n",
            "2021-06-03 18:36:26,159 epoch 29 - iter 52/267 - loss 1.25464150 - samples/sec: 178.57 - lr: 0.050000\n",
            "2021-06-03 18:36:32,301 epoch 29 - iter 78/267 - loss 1.25914591 - samples/sec: 137.30 - lr: 0.050000\n",
            "2021-06-03 18:36:36,769 epoch 29 - iter 104/267 - loss 1.26114665 - samples/sec: 190.83 - lr: 0.050000\n",
            "2021-06-03 18:36:41,292 epoch 29 - iter 130/267 - loss 1.25791161 - samples/sec: 187.75 - lr: 0.050000\n",
            "2021-06-03 18:36:45,749 epoch 29 - iter 156/267 - loss 1.25800830 - samples/sec: 190.94 - lr: 0.050000\n",
            "2021-06-03 18:36:51,682 epoch 29 - iter 182/267 - loss 1.26005130 - samples/sec: 184.86 - lr: 0.050000\n",
            "2021-06-03 18:36:56,151 epoch 29 - iter 208/267 - loss 1.25916584 - samples/sec: 189.60 - lr: 0.050000\n",
            "2021-06-03 18:37:00,742 epoch 29 - iter 234/267 - loss 1.26051494 - samples/sec: 185.57 - lr: 0.050000\n",
            "2021-06-03 18:37:05,284 epoch 29 - iter 260/267 - loss 1.26007250 - samples/sec: 186.72 - lr: 0.050000\n",
            "2021-06-03 18:37:06,636 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:37:06,638 EPOCH 29 done: loss 1.2618 - lr 0.0500000\n",
            "2021-06-03 18:37:15,504 DEV : loss 1.24015474319458 - score 0.446\n",
            "2021-06-03 18:37:16,294 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:37:16,297 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:37:21,705 epoch 30 - iter 26/267 - loss 1.29185236 - samples/sec: 174.71 - lr: 0.050000\n",
            "2021-06-03 18:37:26,392 epoch 30 - iter 52/267 - loss 1.29412067 - samples/sec: 182.64 - lr: 0.050000\n",
            "2021-06-03 18:37:31,051 epoch 30 - iter 78/267 - loss 1.28712976 - samples/sec: 182.99 - lr: 0.050000\n",
            "2021-06-03 18:37:37,188 epoch 30 - iter 104/267 - loss 1.27735727 - samples/sec: 185.72 - lr: 0.050000\n",
            "2021-06-03 18:37:41,667 epoch 30 - iter 130/267 - loss 1.27800258 - samples/sec: 189.88 - lr: 0.050000\n",
            "2021-06-03 18:37:46,168 epoch 30 - iter 156/267 - loss 1.27350132 - samples/sec: 189.06 - lr: 0.050000\n",
            "2021-06-03 18:37:50,630 epoch 30 - iter 182/267 - loss 1.27525238 - samples/sec: 189.70 - lr: 0.050000\n",
            "2021-06-03 18:37:56,603 epoch 30 - iter 208/267 - loss 1.27556898 - samples/sec: 141.48 - lr: 0.050000\n",
            "2021-06-03 18:38:01,123 epoch 30 - iter 234/267 - loss 1.26711238 - samples/sec: 187.85 - lr: 0.050000\n",
            "2021-06-03 18:38:05,547 epoch 30 - iter 260/267 - loss 1.26755768 - samples/sec: 191.54 - lr: 0.050000\n",
            "2021-06-03 18:38:06,902 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:38:06,904 EPOCH 30 done: loss 1.2686 - lr 0.0500000\n",
            "2021-06-03 18:38:14,051 DEV : loss 1.2801177501678467 - score 0.4214\n",
            "2021-06-03 18:38:14,823 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:38:14,826 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:38:22,453 epoch 31 - iter 26/267 - loss 1.22237549 - samples/sec: 176.45 - lr: 0.050000\n",
            "2021-06-03 18:38:27,810 epoch 31 - iter 52/267 - loss 1.24082315 - samples/sec: 166.21 - lr: 0.050000\n",
            "2021-06-03 18:38:32,443 epoch 31 - iter 78/267 - loss 1.25354728 - samples/sec: 183.42 - lr: 0.050000\n",
            "2021-06-03 18:38:37,045 epoch 31 - iter 104/267 - loss 1.25880999 - samples/sec: 184.62 - lr: 0.050000\n",
            "2021-06-03 18:38:42,875 epoch 31 - iter 130/267 - loss 1.25536917 - samples/sec: 191.34 - lr: 0.050000\n",
            "2021-06-03 18:38:47,220 epoch 31 - iter 156/267 - loss 1.25235619 - samples/sec: 195.89 - lr: 0.050000\n",
            "2021-06-03 18:38:51,718 epoch 31 - iter 182/267 - loss 1.25200924 - samples/sec: 189.82 - lr: 0.050000\n",
            "2021-06-03 18:38:56,173 epoch 31 - iter 208/267 - loss 1.25737065 - samples/sec: 191.14 - lr: 0.050000\n",
            "2021-06-03 18:39:02,026 epoch 31 - iter 234/267 - loss 1.25765751 - samples/sec: 187.90 - lr: 0.050000\n",
            "2021-06-03 18:39:06,583 epoch 31 - iter 260/267 - loss 1.26274611 - samples/sec: 186.50 - lr: 0.050000\n",
            "2021-06-03 18:39:08,017 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:39:08,019 EPOCH 31 done: loss 1.2638 - lr 0.0500000\n",
            "2021-06-03 18:39:15,158 DEV : loss 1.2486207485198975 - score 0.4378\n",
            "Epoch    31: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2021-06-03 18:39:15,968 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 18:39:15,971 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:39:21,046 epoch 32 - iter 26/267 - loss 1.24539689 - samples/sec: 184.39 - lr: 0.025000\n",
            "2021-06-03 18:39:27,125 epoch 32 - iter 52/267 - loss 1.24094893 - samples/sec: 139.27 - lr: 0.025000\n",
            "2021-06-03 18:39:31,758 epoch 32 - iter 78/267 - loss 1.23756474 - samples/sec: 183.67 - lr: 0.025000\n",
            "2021-06-03 18:39:36,341 epoch 32 - iter 104/267 - loss 1.24018043 - samples/sec: 185.20 - lr: 0.025000\n",
            "2021-06-03 18:39:40,753 epoch 32 - iter 130/267 - loss 1.24148115 - samples/sec: 191.51 - lr: 0.025000\n",
            "2021-06-03 18:39:46,578 epoch 32 - iter 156/267 - loss 1.24809748 - samples/sec: 144.99 - lr: 0.025000\n",
            "2021-06-03 18:39:51,157 epoch 32 - iter 182/267 - loss 1.24348451 - samples/sec: 185.74 - lr: 0.025000\n",
            "2021-06-03 18:39:55,517 epoch 32 - iter 208/267 - loss 1.24232218 - samples/sec: 194.52 - lr: 0.025000\n",
            "2021-06-03 18:40:00,073 epoch 32 - iter 234/267 - loss 1.24282319 - samples/sec: 186.80 - lr: 0.025000\n",
            "2021-06-03 18:40:06,057 epoch 32 - iter 260/267 - loss 1.24147742 - samples/sec: 184.73 - lr: 0.025000\n",
            "2021-06-03 18:40:07,465 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:40:07,467 EPOCH 32 done: loss 1.2420 - lr 0.0250000\n",
            "2021-06-03 18:40:14,820 DEV : loss 1.2619365453720093 - score 0.4405\n",
            "2021-06-03 18:40:15,607 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:40:15,610 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:40:20,930 epoch 33 - iter 26/267 - loss 1.26963901 - samples/sec: 175.33 - lr: 0.025000\n",
            "2021-06-03 18:40:27,290 epoch 33 - iter 52/267 - loss 1.26060209 - samples/sec: 183.39 - lr: 0.025000\n",
            "2021-06-03 18:40:31,802 epoch 33 - iter 78/267 - loss 1.25200075 - samples/sec: 187.74 - lr: 0.025000\n",
            "2021-06-03 18:40:36,340 epoch 33 - iter 104/267 - loss 1.24244431 - samples/sec: 186.83 - lr: 0.025000\n",
            "2021-06-03 18:40:40,956 epoch 33 - iter 130/267 - loss 1.24493270 - samples/sec: 184.36 - lr: 0.025000\n",
            "2021-06-03 18:40:46,802 epoch 33 - iter 156/267 - loss 1.25018920 - samples/sec: 188.63 - lr: 0.025000\n",
            "2021-06-03 18:40:51,136 epoch 33 - iter 182/267 - loss 1.24511442 - samples/sec: 196.31 - lr: 0.025000\n",
            "2021-06-03 18:40:55,673 epoch 33 - iter 208/267 - loss 1.24110118 - samples/sec: 187.89 - lr: 0.025000\n",
            "2021-06-03 18:41:00,072 epoch 33 - iter 234/267 - loss 1.23872316 - samples/sec: 192.76 - lr: 0.025000\n",
            "2021-06-03 18:41:06,010 epoch 33 - iter 260/267 - loss 1.24024699 - samples/sec: 186.48 - lr: 0.025000\n",
            "2021-06-03 18:41:07,429 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:41:07,432 EPOCH 33 done: loss 1.2418 - lr 0.0250000\n",
            "2021-06-03 18:41:14,710 DEV : loss 1.2472915649414062 - score 0.446\n",
            "2021-06-03 18:41:15,514 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:41:15,517 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:41:20,786 epoch 34 - iter 26/267 - loss 1.23333668 - samples/sec: 178.27 - lr: 0.025000\n",
            "2021-06-03 18:41:27,171 epoch 34 - iter 52/267 - loss 1.24318051 - samples/sec: 180.87 - lr: 0.025000\n",
            "2021-06-03 18:41:31,761 epoch 34 - iter 78/267 - loss 1.24941058 - samples/sec: 185.39 - lr: 0.025000\n",
            "2021-06-03 18:41:36,243 epoch 34 - iter 104/267 - loss 1.24611467 - samples/sec: 188.66 - lr: 0.025000\n",
            "2021-06-03 18:41:40,967 epoch 34 - iter 130/267 - loss 1.24656193 - samples/sec: 179.14 - lr: 0.025000\n",
            "2021-06-03 18:41:47,133 epoch 34 - iter 156/267 - loss 1.24690224 - samples/sec: 179.31 - lr: 0.025000\n",
            "2021-06-03 18:41:51,590 epoch 34 - iter 182/267 - loss 1.24564987 - samples/sec: 189.84 - lr: 0.025000\n",
            "2021-06-03 18:41:56,147 epoch 34 - iter 208/267 - loss 1.23816197 - samples/sec: 187.16 - lr: 0.025000\n",
            "2021-06-03 18:42:00,604 epoch 34 - iter 234/267 - loss 1.23768759 - samples/sec: 190.72 - lr: 0.025000\n",
            "2021-06-03 18:42:06,542 epoch 34 - iter 260/267 - loss 1.23865828 - samples/sec: 185.30 - lr: 0.025000\n",
            "2021-06-03 18:42:07,944 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:42:07,946 EPOCH 34 done: loss 1.2378 - lr 0.0250000\n",
            "2021-06-03 18:42:15,319 DEV : loss 1.2523921728134155 - score 0.4414\n",
            "2021-06-03 18:42:16,113 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:42:16,116 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:42:21,301 epoch 35 - iter 26/267 - loss 1.23339096 - samples/sec: 182.05 - lr: 0.025000\n",
            "2021-06-03 18:42:27,597 epoch 35 - iter 52/267 - loss 1.23294309 - samples/sec: 182.48 - lr: 0.025000\n",
            "2021-06-03 18:42:32,144 epoch 35 - iter 78/267 - loss 1.24327856 - samples/sec: 186.15 - lr: 0.025000\n",
            "2021-06-03 18:42:36,719 epoch 35 - iter 104/267 - loss 1.23382869 - samples/sec: 186.56 - lr: 0.025000\n",
            "2021-06-03 18:42:41,235 epoch 35 - iter 130/267 - loss 1.24128012 - samples/sec: 187.44 - lr: 0.025000\n",
            "2021-06-03 18:42:47,127 epoch 35 - iter 156/267 - loss 1.23798602 - samples/sec: 188.74 - lr: 0.025000\n",
            "2021-06-03 18:42:51,776 epoch 35 - iter 182/267 - loss 1.23752713 - samples/sec: 183.25 - lr: 0.025000\n",
            "2021-06-03 18:42:56,373 epoch 35 - iter 208/267 - loss 1.23488618 - samples/sec: 184.09 - lr: 0.025000\n",
            "2021-06-03 18:43:00,810 epoch 35 - iter 234/267 - loss 1.24085555 - samples/sec: 190.45 - lr: 0.025000\n",
            "2021-06-03 18:43:06,622 epoch 35 - iter 260/267 - loss 1.23781394 - samples/sec: 188.80 - lr: 0.025000\n",
            "2021-06-03 18:43:08,003 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:43:08,004 EPOCH 35 done: loss 1.2370 - lr 0.0250000\n",
            "2021-06-03 18:43:15,313 DEV : loss 1.2374622821807861 - score 0.4623\n",
            "2021-06-03 18:43:16,111 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:43:19,345 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:43:24,785 epoch 36 - iter 26/267 - loss 1.22350895 - samples/sec: 171.83 - lr: 0.025000\n",
            "2021-06-03 18:43:30,954 epoch 36 - iter 52/267 - loss 1.24672662 - samples/sec: 137.12 - lr: 0.025000\n",
            "2021-06-03 18:43:35,515 epoch 36 - iter 78/267 - loss 1.23649657 - samples/sec: 187.20 - lr: 0.025000\n",
            "2021-06-03 18:43:40,044 epoch 36 - iter 104/267 - loss 1.23492139 - samples/sec: 188.26 - lr: 0.025000\n",
            "2021-06-03 18:43:44,580 epoch 36 - iter 130/267 - loss 1.24068240 - samples/sec: 187.61 - lr: 0.025000\n",
            "2021-06-03 18:43:49,028 epoch 36 - iter 156/267 - loss 1.23213248 - samples/sec: 191.65 - lr: 0.025000\n",
            "2021-06-03 18:43:54,777 epoch 36 - iter 182/267 - loss 1.22762177 - samples/sec: 191.18 - lr: 0.025000\n",
            "2021-06-03 18:43:59,278 epoch 36 - iter 208/267 - loss 1.22620579 - samples/sec: 189.60 - lr: 0.025000\n",
            "2021-06-03 18:44:03,793 epoch 36 - iter 234/267 - loss 1.22708092 - samples/sec: 189.34 - lr: 0.025000\n",
            "2021-06-03 18:44:08,344 epoch 36 - iter 260/267 - loss 1.22881022 - samples/sec: 187.05 - lr: 0.025000\n",
            "2021-06-03 18:44:09,752 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:44:09,753 EPOCH 36 done: loss 1.2280 - lr 0.0250000\n",
            "2021-06-03 18:44:18,503 DEV : loss 1.2548518180847168 - score 0.4496\n",
            "2021-06-03 18:44:19,289 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:44:19,291 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:44:24,471 epoch 37 - iter 26/267 - loss 1.23237184 - samples/sec: 180.75 - lr: 0.025000\n",
            "2021-06-03 18:44:29,175 epoch 37 - iter 52/267 - loss 1.22598245 - samples/sec: 182.00 - lr: 0.025000\n",
            "2021-06-03 18:44:33,880 epoch 37 - iter 78/267 - loss 1.23346141 - samples/sec: 181.53 - lr: 0.025000\n",
            "2021-06-03 18:44:39,819 epoch 37 - iter 104/267 - loss 1.23138923 - samples/sec: 142.42 - lr: 0.025000\n",
            "2021-06-03 18:44:44,383 epoch 37 - iter 130/267 - loss 1.22708072 - samples/sec: 185.94 - lr: 0.025000\n",
            "2021-06-03 18:44:48,913 epoch 37 - iter 156/267 - loss 1.21979180 - samples/sec: 188.54 - lr: 0.025000\n",
            "2021-06-03 18:44:53,499 epoch 37 - iter 182/267 - loss 1.22621227 - samples/sec: 185.89 - lr: 0.025000\n",
            "2021-06-03 18:44:59,488 epoch 37 - iter 208/267 - loss 1.22062208 - samples/sec: 141.52 - lr: 0.025000\n",
            "2021-06-03 18:45:04,082 epoch 37 - iter 234/267 - loss 1.22446607 - samples/sec: 185.31 - lr: 0.025000\n",
            "2021-06-03 18:45:08,592 epoch 37 - iter 260/267 - loss 1.22575023 - samples/sec: 189.46 - lr: 0.025000\n",
            "2021-06-03 18:45:09,970 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:45:09,972 EPOCH 37 done: loss 1.2247 - lr 0.0250000\n",
            "2021-06-03 18:45:17,133 DEV : loss 1.231776475906372 - score 0.4587\n",
            "2021-06-03 18:45:17,910 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:45:17,912 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:45:24,659 epoch 38 - iter 26/267 - loss 1.21421128 - samples/sec: 184.94 - lr: 0.025000\n",
            "2021-06-03 18:45:29,093 epoch 38 - iter 52/267 - loss 1.21339633 - samples/sec: 191.44 - lr: 0.025000\n",
            "2021-06-03 18:45:33,703 epoch 38 - iter 78/267 - loss 1.21592385 - samples/sec: 184.68 - lr: 0.025000\n",
            "2021-06-03 18:45:38,440 epoch 38 - iter 104/267 - loss 1.22205834 - samples/sec: 179.88 - lr: 0.025000\n",
            "2021-06-03 18:45:44,315 epoch 38 - iter 130/267 - loss 1.22210611 - samples/sec: 143.59 - lr: 0.025000\n",
            "2021-06-03 18:45:48,797 epoch 38 - iter 156/267 - loss 1.22415611 - samples/sec: 190.29 - lr: 0.025000\n",
            "2021-06-03 18:45:53,370 epoch 38 - iter 182/267 - loss 1.22778349 - samples/sec: 185.83 - lr: 0.025000\n",
            "2021-06-03 18:45:57,918 epoch 38 - iter 208/267 - loss 1.22594405 - samples/sec: 186.21 - lr: 0.025000\n",
            "2021-06-03 18:46:02,328 epoch 38 - iter 234/267 - loss 1.22992073 - samples/sec: 192.70 - lr: 0.025000\n",
            "2021-06-03 18:46:08,142 epoch 38 - iter 260/267 - loss 1.22573034 - samples/sec: 145.15 - lr: 0.025000\n",
            "2021-06-03 18:46:09,530 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:46:09,532 EPOCH 38 done: loss 1.2267 - lr 0.0250000\n",
            "2021-06-03 18:46:16,782 DEV : loss 1.253846526145935 - score 0.4378\n",
            "2021-06-03 18:46:17,571 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:46:17,573 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:46:23,037 epoch 39 - iter 26/267 - loss 1.23491126 - samples/sec: 173.46 - lr: 0.025000\n",
            "2021-06-03 18:46:29,350 epoch 39 - iter 52/267 - loss 1.23441536 - samples/sec: 182.66 - lr: 0.025000\n",
            "2021-06-03 18:46:33,789 epoch 39 - iter 78/267 - loss 1.22167539 - samples/sec: 191.81 - lr: 0.025000\n",
            "2021-06-03 18:46:38,263 epoch 39 - iter 104/267 - loss 1.22490287 - samples/sec: 189.84 - lr: 0.025000\n",
            "2021-06-03 18:46:42,859 epoch 39 - iter 130/267 - loss 1.21909331 - samples/sec: 184.76 - lr: 0.025000\n",
            "2021-06-03 18:46:48,557 epoch 39 - iter 156/267 - loss 1.22601326 - samples/sec: 194.91 - lr: 0.025000\n",
            "2021-06-03 18:46:53,121 epoch 39 - iter 182/267 - loss 1.23246717 - samples/sec: 185.48 - lr: 0.025000\n",
            "2021-06-03 18:46:57,556 epoch 39 - iter 208/267 - loss 1.23322486 - samples/sec: 191.27 - lr: 0.025000\n",
            "2021-06-03 18:47:02,134 epoch 39 - iter 234/267 - loss 1.23339462 - samples/sec: 186.28 - lr: 0.025000\n",
            "2021-06-03 18:47:08,007 epoch 39 - iter 260/267 - loss 1.23616049 - samples/sec: 186.70 - lr: 0.025000\n",
            "2021-06-03 18:47:09,453 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:47:09,455 EPOCH 39 done: loss 1.2360 - lr 0.0250000\n",
            "2021-06-03 18:47:16,667 DEV : loss 1.2420426607131958 - score 0.4641\n",
            "2021-06-03 18:47:17,443 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 18:47:20,644 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:47:26,062 epoch 40 - iter 26/267 - loss 1.21513854 - samples/sec: 173.86 - lr: 0.025000\n",
            "2021-06-03 18:47:32,393 epoch 40 - iter 52/267 - loss 1.21424033 - samples/sec: 183.08 - lr: 0.025000\n",
            "2021-06-03 18:47:36,894 epoch 40 - iter 78/267 - loss 1.21318642 - samples/sec: 188.63 - lr: 0.025000\n",
            "2021-06-03 18:47:41,332 epoch 40 - iter 104/267 - loss 1.21883703 - samples/sec: 191.41 - lr: 0.025000\n",
            "2021-06-03 18:47:45,795 epoch 40 - iter 130/267 - loss 1.22172382 - samples/sec: 190.83 - lr: 0.025000\n",
            "2021-06-03 18:47:51,535 epoch 40 - iter 156/267 - loss 1.22419457 - samples/sec: 191.29 - lr: 0.025000\n",
            "2021-06-03 18:47:56,164 epoch 40 - iter 182/267 - loss 1.22762273 - samples/sec: 183.27 - lr: 0.025000\n",
            "2021-06-03 18:48:00,520 epoch 40 - iter 208/267 - loss 1.22494767 - samples/sec: 195.36 - lr: 0.025000\n",
            "2021-06-03 18:48:04,999 epoch 40 - iter 234/267 - loss 1.22471222 - samples/sec: 189.85 - lr: 0.025000\n",
            "2021-06-03 18:48:10,923 epoch 40 - iter 260/267 - loss 1.22329978 - samples/sec: 142.35 - lr: 0.025000\n",
            "2021-06-03 18:48:12,391 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:48:12,393 EPOCH 40 done: loss 1.2229 - lr 0.0250000\n",
            "2021-06-03 18:48:19,798 DEV : loss 1.2441121339797974 - score 0.436\n",
            "2021-06-03 18:48:20,600 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:48:20,602 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:48:25,984 epoch 41 - iter 26/267 - loss 1.24177420 - samples/sec: 175.56 - lr: 0.025000\n",
            "2021-06-03 18:48:30,691 epoch 41 - iter 52/267 - loss 1.24783606 - samples/sec: 182.12 - lr: 0.025000\n",
            "2021-06-03 18:48:36,959 epoch 41 - iter 78/267 - loss 1.23115086 - samples/sec: 185.87 - lr: 0.025000\n",
            "2021-06-03 18:48:41,537 epoch 41 - iter 104/267 - loss 1.22324251 - samples/sec: 185.72 - lr: 0.025000\n",
            "2021-06-03 18:48:46,174 epoch 41 - iter 130/267 - loss 1.21796537 - samples/sec: 183.51 - lr: 0.025000\n",
            "2021-06-03 18:48:50,646 epoch 41 - iter 156/267 - loss 1.21505870 - samples/sec: 190.44 - lr: 0.025000\n",
            "2021-06-03 18:48:56,648 epoch 41 - iter 182/267 - loss 1.21727667 - samples/sec: 140.62 - lr: 0.025000\n",
            "2021-06-03 18:49:01,210 epoch 41 - iter 208/267 - loss 1.21585667 - samples/sec: 185.98 - lr: 0.025000\n",
            "2021-06-03 18:49:05,707 epoch 41 - iter 234/267 - loss 1.21879408 - samples/sec: 189.41 - lr: 0.025000\n",
            "2021-06-03 18:49:10,184 epoch 41 - iter 260/267 - loss 1.21805965 - samples/sec: 189.62 - lr: 0.025000\n",
            "2021-06-03 18:49:11,603 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:49:11,605 EPOCH 41 done: loss 1.2174 - lr 0.0250000\n",
            "2021-06-03 18:49:23,486 DEV : loss 1.2491366863250732 - score 0.4541\n",
            "2021-06-03 18:49:24,274 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:49:24,277 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:49:29,609 epoch 42 - iter 26/267 - loss 1.21431792 - samples/sec: 175.64 - lr: 0.025000\n",
            "2021-06-03 18:49:34,217 epoch 42 - iter 52/267 - loss 1.21036171 - samples/sec: 186.67 - lr: 0.025000\n",
            "2021-06-03 18:49:38,902 epoch 42 - iter 78/267 - loss 1.19839929 - samples/sec: 182.18 - lr: 0.025000\n",
            "2021-06-03 18:49:45,172 epoch 42 - iter 104/267 - loss 1.20597882 - samples/sec: 183.13 - lr: 0.025000\n",
            "2021-06-03 18:49:49,773 epoch 42 - iter 130/267 - loss 1.21519726 - samples/sec: 185.17 - lr: 0.025000\n",
            "2021-06-03 18:49:54,592 epoch 42 - iter 156/267 - loss 1.21364496 - samples/sec: 177.38 - lr: 0.025000\n",
            "2021-06-03 18:49:59,265 epoch 42 - iter 182/267 - loss 1.22108914 - samples/sec: 182.64 - lr: 0.025000\n",
            "2021-06-03 18:50:05,237 epoch 42 - iter 208/267 - loss 1.21861365 - samples/sec: 141.64 - lr: 0.025000\n",
            "2021-06-03 18:50:09,627 epoch 42 - iter 234/267 - loss 1.21937450 - samples/sec: 194.25 - lr: 0.025000\n",
            "2021-06-03 18:50:14,204 epoch 42 - iter 260/267 - loss 1.21966475 - samples/sec: 185.75 - lr: 0.025000\n",
            "2021-06-03 18:50:15,638 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:50:15,640 EPOCH 42 done: loss 1.2197 - lr 0.0250000\n",
            "2021-06-03 18:50:24,594 DEV : loss 1.2370116710662842 - score 0.4505\n",
            "2021-06-03 18:50:25,378 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:50:25,381 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:50:30,694 epoch 43 - iter 26/267 - loss 1.19758957 - samples/sec: 176.20 - lr: 0.025000\n",
            "2021-06-03 18:50:35,433 epoch 43 - iter 52/267 - loss 1.18154001 - samples/sec: 180.44 - lr: 0.025000\n",
            "2021-06-03 18:50:40,277 epoch 43 - iter 78/267 - loss 1.19806221 - samples/sec: 177.63 - lr: 0.025000\n",
            "2021-06-03 18:50:44,856 epoch 43 - iter 104/267 - loss 1.20383894 - samples/sec: 187.24 - lr: 0.025000\n",
            "2021-06-03 18:50:50,898 epoch 43 - iter 130/267 - loss 1.20351149 - samples/sec: 139.54 - lr: 0.025000\n",
            "2021-06-03 18:50:55,531 epoch 43 - iter 156/267 - loss 1.20176249 - samples/sec: 183.79 - lr: 0.025000\n",
            "2021-06-03 18:51:00,027 epoch 43 - iter 182/267 - loss 1.20347339 - samples/sec: 188.56 - lr: 0.025000\n",
            "2021-06-03 18:51:04,472 epoch 43 - iter 208/267 - loss 1.21142471 - samples/sec: 191.51 - lr: 0.025000\n",
            "2021-06-03 18:51:10,344 epoch 43 - iter 234/267 - loss 1.20978051 - samples/sec: 144.11 - lr: 0.025000\n",
            "2021-06-03 18:51:14,795 epoch 43 - iter 260/267 - loss 1.21246574 - samples/sec: 190.81 - lr: 0.025000\n",
            "2021-06-03 18:51:16,274 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:51:16,276 EPOCH 43 done: loss 1.2161 - lr 0.0250000\n",
            "2021-06-03 18:51:23,605 DEV : loss 1.2394758462905884 - score 0.4496\n",
            "Epoch    43: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2021-06-03 18:51:24,402 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 18:51:24,405 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:51:29,652 epoch 44 - iter 26/267 - loss 1.21755849 - samples/sec: 177.79 - lr: 0.012500\n",
            "2021-06-03 18:51:35,917 epoch 44 - iter 52/267 - loss 1.20720004 - samples/sec: 134.97 - lr: 0.012500\n",
            "2021-06-03 18:51:40,452 epoch 44 - iter 78/267 - loss 1.20373493 - samples/sec: 187.59 - lr: 0.012500\n",
            "2021-06-03 18:51:45,017 epoch 44 - iter 104/267 - loss 1.19450056 - samples/sec: 186.37 - lr: 0.012500\n",
            "2021-06-03 18:51:49,425 epoch 44 - iter 130/267 - loss 1.18890638 - samples/sec: 193.40 - lr: 0.012500\n",
            "2021-06-03 18:51:55,329 epoch 44 - iter 156/267 - loss 1.19580209 - samples/sec: 143.10 - lr: 0.012500\n",
            "2021-06-03 18:51:59,937 epoch 44 - iter 182/267 - loss 1.19385721 - samples/sec: 183.71 - lr: 0.012500\n",
            "2021-06-03 18:52:04,508 epoch 44 - iter 208/267 - loss 1.19482036 - samples/sec: 186.14 - lr: 0.012500\n",
            "2021-06-03 18:52:08,988 epoch 44 - iter 234/267 - loss 1.19882910 - samples/sec: 189.30 - lr: 0.012500\n",
            "2021-06-03 18:52:14,841 epoch 44 - iter 260/267 - loss 1.19726406 - samples/sec: 187.22 - lr: 0.012500\n",
            "2021-06-03 18:52:16,253 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:52:16,257 EPOCH 44 done: loss 1.1970 - lr 0.0125000\n",
            "2021-06-03 18:52:23,482 DEV : loss 1.24481999874115 - score 0.4578\n",
            "2021-06-03 18:52:24,284 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:52:24,287 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:52:29,610 epoch 45 - iter 26/267 - loss 1.16373713 - samples/sec: 176.47 - lr: 0.012500\n",
            "2021-06-03 18:52:34,169 epoch 45 - iter 52/267 - loss 1.18341547 - samples/sec: 187.32 - lr: 0.012500\n",
            "2021-06-03 18:52:40,211 epoch 45 - iter 78/267 - loss 1.19848945 - samples/sec: 139.71 - lr: 0.012500\n",
            "2021-06-03 18:52:44,795 epoch 45 - iter 104/267 - loss 1.19295280 - samples/sec: 184.92 - lr: 0.012500\n",
            "2021-06-03 18:52:49,411 epoch 45 - iter 130/267 - loss 1.19936754 - samples/sec: 184.10 - lr: 0.012500\n",
            "2021-06-03 18:52:54,046 epoch 45 - iter 156/267 - loss 1.20486319 - samples/sec: 182.88 - lr: 0.012500\n",
            "2021-06-03 18:53:00,152 epoch 45 - iter 182/267 - loss 1.20676328 - samples/sec: 138.19 - lr: 0.012500\n",
            "2021-06-03 18:53:04,643 epoch 45 - iter 208/267 - loss 1.20772485 - samples/sec: 189.36 - lr: 0.012500\n",
            "2021-06-03 18:53:09,247 epoch 45 - iter 234/267 - loss 1.20800664 - samples/sec: 185.16 - lr: 0.012500\n",
            "2021-06-03 18:53:13,698 epoch 45 - iter 260/267 - loss 1.20623901 - samples/sec: 190.67 - lr: 0.012500\n",
            "2021-06-03 18:53:16,371 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:53:16,373 EPOCH 45 done: loss 1.2056 - lr 0.0125000\n",
            "2021-06-03 18:53:23,701 DEV : loss 1.2629224061965942 - score 0.4351\n",
            "2021-06-03 18:53:24,483 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:53:24,485 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:53:29,736 epoch 46 - iter 26/267 - loss 1.17407117 - samples/sec: 178.93 - lr: 0.012500\n",
            "2021-06-03 18:53:34,627 epoch 46 - iter 52/267 - loss 1.16088005 - samples/sec: 175.53 - lr: 0.012500\n",
            "2021-06-03 18:53:40,918 epoch 46 - iter 78/267 - loss 1.17334288 - samples/sec: 182.54 - lr: 0.012500\n",
            "2021-06-03 18:53:45,453 epoch 46 - iter 104/267 - loss 1.18877299 - samples/sec: 187.39 - lr: 0.012500\n",
            "2021-06-03 18:53:50,020 epoch 46 - iter 130/267 - loss 1.19026627 - samples/sec: 186.21 - lr: 0.012500\n",
            "2021-06-03 18:53:54,563 epoch 46 - iter 156/267 - loss 1.19012421 - samples/sec: 187.12 - lr: 0.012500\n",
            "2021-06-03 18:54:00,514 epoch 46 - iter 182/267 - loss 1.19107231 - samples/sec: 141.83 - lr: 0.012500\n",
            "2021-06-03 18:54:04,875 epoch 46 - iter 208/267 - loss 1.19333555 - samples/sec: 194.78 - lr: 0.012500\n",
            "2021-06-03 18:54:09,408 epoch 46 - iter 234/267 - loss 1.19405891 - samples/sec: 187.86 - lr: 0.012500\n",
            "2021-06-03 18:54:13,959 epoch 46 - iter 260/267 - loss 1.19717384 - samples/sec: 185.91 - lr: 0.012500\n",
            "2021-06-03 18:54:16,806 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:54:16,808 EPOCH 46 done: loss 1.1970 - lr 0.0125000\n",
            "2021-06-03 18:54:24,149 DEV : loss 1.251117467880249 - score 0.4414\n",
            "2021-06-03 18:54:24,934 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:54:24,936 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:54:30,189 epoch 47 - iter 26/267 - loss 1.19674533 - samples/sec: 179.29 - lr: 0.012500\n",
            "2021-06-03 18:54:34,965 epoch 47 - iter 52/267 - loss 1.19613875 - samples/sec: 179.42 - lr: 0.012500\n",
            "2021-06-03 18:54:41,247 epoch 47 - iter 78/267 - loss 1.20397289 - samples/sec: 134.44 - lr: 0.012500\n",
            "2021-06-03 18:54:45,660 epoch 47 - iter 104/267 - loss 1.20455825 - samples/sec: 192.08 - lr: 0.012500\n",
            "2021-06-03 18:54:50,205 epoch 47 - iter 130/267 - loss 1.20824844 - samples/sec: 187.28 - lr: 0.012500\n",
            "2021-06-03 18:54:54,783 epoch 47 - iter 156/267 - loss 1.20655014 - samples/sec: 185.84 - lr: 0.012500\n",
            "2021-06-03 18:55:00,533 epoch 47 - iter 182/267 - loss 1.20604484 - samples/sec: 190.05 - lr: 0.012500\n",
            "2021-06-03 18:55:05,011 epoch 47 - iter 208/267 - loss 1.20572751 - samples/sec: 189.60 - lr: 0.012500\n",
            "2021-06-03 18:55:09,685 epoch 47 - iter 234/267 - loss 1.20357461 - samples/sec: 182.05 - lr: 0.012500\n",
            "2021-06-03 18:55:14,172 epoch 47 - iter 260/267 - loss 1.20402434 - samples/sec: 189.84 - lr: 0.012500\n",
            "2021-06-03 18:55:15,538 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:55:15,540 EPOCH 47 done: loss 1.2030 - lr 0.0125000\n",
            "2021-06-03 18:55:24,293 DEV : loss 1.2627352476119995 - score 0.4233\n",
            "Epoch    47: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2021-06-03 18:55:25,053 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 18:55:25,055 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:55:30,209 epoch 48 - iter 26/267 - loss 1.17197581 - samples/sec: 182.23 - lr: 0.006250\n",
            "2021-06-03 18:55:34,822 epoch 48 - iter 52/267 - loss 1.18933778 - samples/sec: 185.34 - lr: 0.006250\n",
            "2021-06-03 18:55:39,419 epoch 48 - iter 78/267 - loss 1.19609663 - samples/sec: 186.29 - lr: 0.006250\n",
            "2021-06-03 18:55:45,424 epoch 48 - iter 104/267 - loss 1.20483675 - samples/sec: 140.29 - lr: 0.006250\n",
            "2021-06-03 18:55:49,988 epoch 48 - iter 130/267 - loss 1.19783621 - samples/sec: 186.41 - lr: 0.006250\n",
            "2021-06-03 18:55:54,651 epoch 48 - iter 156/267 - loss 1.20477433 - samples/sec: 182.07 - lr: 0.006250\n",
            "2021-06-03 18:55:59,227 epoch 48 - iter 182/267 - loss 1.20168798 - samples/sec: 185.42 - lr: 0.006250\n",
            "2021-06-03 18:56:05,281 epoch 48 - iter 208/267 - loss 1.20028268 - samples/sec: 180.88 - lr: 0.006250\n",
            "2021-06-03 18:56:09,873 epoch 48 - iter 234/267 - loss 1.19756297 - samples/sec: 185.36 - lr: 0.006250\n",
            "2021-06-03 18:56:14,444 epoch 48 - iter 260/267 - loss 1.20168687 - samples/sec: 186.22 - lr: 0.006250\n",
            "2021-06-03 18:56:15,853 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:56:15,855 EPOCH 48 done: loss 1.2009 - lr 0.0062500\n",
            "2021-06-03 18:56:24,686 DEV : loss 1.2405757904052734 - score 0.455\n",
            "2021-06-03 18:56:25,454 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 18:56:25,456 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:56:30,852 epoch 49 - iter 26/267 - loss 1.19656952 - samples/sec: 175.54 - lr: 0.006250\n",
            "2021-06-03 18:56:35,522 epoch 49 - iter 52/267 - loss 1.20298024 - samples/sec: 183.81 - lr: 0.006250\n",
            "2021-06-03 18:56:40,173 epoch 49 - iter 78/267 - loss 1.19725294 - samples/sec: 183.69 - lr: 0.006250\n",
            "2021-06-03 18:56:44,827 epoch 49 - iter 104/267 - loss 1.19491040 - samples/sec: 183.20 - lr: 0.006250\n",
            "2021-06-03 18:56:50,901 epoch 49 - iter 130/267 - loss 1.18675510 - samples/sec: 138.95 - lr: 0.006250\n",
            "2021-06-03 18:56:55,319 epoch 49 - iter 156/267 - loss 1.18659741 - samples/sec: 192.41 - lr: 0.006250\n",
            "2021-06-03 18:56:59,837 epoch 49 - iter 182/267 - loss 1.19246165 - samples/sec: 188.87 - lr: 0.006250\n",
            "2021-06-03 18:57:04,398 epoch 49 - iter 208/267 - loss 1.19455764 - samples/sec: 186.65 - lr: 0.006250\n",
            "2021-06-03 18:57:10,337 epoch 49 - iter 234/267 - loss 1.19191586 - samples/sec: 187.39 - lr: 0.006250\n",
            "2021-06-03 18:57:15,000 epoch 49 - iter 260/267 - loss 1.19367689 - samples/sec: 183.31 - lr: 0.006250\n",
            "2021-06-03 18:57:16,426 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:57:16,428 EPOCH 49 done: loss 1.1942 - lr 0.0062500\n",
            "2021-06-03 18:57:23,797 DEV : loss 1.2437089681625366 - score 0.4378\n",
            "2021-06-03 18:57:24,593 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:57:24,597 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:57:31,502 epoch 50 - iter 26/267 - loss 1.19856104 - samples/sec: 181.16 - lr: 0.006250\n",
            "2021-06-03 18:57:35,995 epoch 50 - iter 52/267 - loss 1.19122283 - samples/sec: 189.14 - lr: 0.006250\n",
            "2021-06-03 18:57:40,454 epoch 50 - iter 78/267 - loss 1.19049316 - samples/sec: 189.92 - lr: 0.006250\n",
            "2021-06-03 18:57:44,986 epoch 50 - iter 104/267 - loss 1.19134326 - samples/sec: 187.17 - lr: 0.006250\n",
            "2021-06-03 18:57:50,929 epoch 50 - iter 130/267 - loss 1.19337567 - samples/sec: 184.36 - lr: 0.006250\n",
            "2021-06-03 18:57:55,360 epoch 50 - iter 156/267 - loss 1.19049325 - samples/sec: 192.19 - lr: 0.006250\n",
            "2021-06-03 18:57:59,835 epoch 50 - iter 182/267 - loss 1.18549086 - samples/sec: 190.80 - lr: 0.006250\n",
            "2021-06-03 18:58:04,393 epoch 50 - iter 208/267 - loss 1.18679199 - samples/sec: 186.89 - lr: 0.006250\n",
            "2021-06-03 18:58:10,063 epoch 50 - iter 234/267 - loss 1.18471514 - samples/sec: 194.08 - lr: 0.006250\n",
            "2021-06-03 18:58:14,565 epoch 50 - iter 260/267 - loss 1.18733937 - samples/sec: 188.76 - lr: 0.006250\n",
            "2021-06-03 18:58:15,934 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:58:15,936 EPOCH 50 done: loss 1.1886 - lr 0.0062500\n",
            "2021-06-03 18:58:23,208 DEV : loss 1.2567936182022095 - score 0.445\n",
            "2021-06-03 18:58:24,014 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:58:24,018 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:58:29,475 epoch 51 - iter 26/267 - loss 1.20541137 - samples/sec: 172.16 - lr: 0.006250\n",
            "2021-06-03 18:58:35,685 epoch 51 - iter 52/267 - loss 1.19125018 - samples/sec: 188.38 - lr: 0.006250\n",
            "2021-06-03 18:58:40,319 epoch 51 - iter 78/267 - loss 1.18892368 - samples/sec: 184.19 - lr: 0.006250\n",
            "2021-06-03 18:58:44,768 epoch 51 - iter 104/267 - loss 1.18442641 - samples/sec: 190.38 - lr: 0.006250\n",
            "2021-06-03 18:58:49,216 epoch 51 - iter 130/267 - loss 1.18194652 - samples/sec: 190.50 - lr: 0.006250\n",
            "2021-06-03 18:58:55,248 epoch 51 - iter 156/267 - loss 1.18917298 - samples/sec: 140.30 - lr: 0.006250\n",
            "2021-06-03 18:58:59,785 epoch 51 - iter 182/267 - loss 1.18717032 - samples/sec: 186.82 - lr: 0.006250\n",
            "2021-06-03 18:59:04,187 epoch 51 - iter 208/267 - loss 1.19020674 - samples/sec: 192.89 - lr: 0.006250\n",
            "2021-06-03 18:59:08,638 epoch 51 - iter 234/267 - loss 1.18816479 - samples/sec: 191.22 - lr: 0.006250\n",
            "2021-06-03 18:59:14,538 epoch 51 - iter 260/267 - loss 1.19112823 - samples/sec: 142.78 - lr: 0.006250\n",
            "2021-06-03 18:59:16,010 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:59:16,012 EPOCH 51 done: loss 1.1927 - lr 0.0062500\n",
            "2021-06-03 18:59:23,330 DEV : loss 1.2528934478759766 - score 0.4405\n",
            "Epoch    51: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2021-06-03 18:59:24,128 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 18:59:24,131 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:59:29,464 epoch 52 - iter 26/267 - loss 1.19477844 - samples/sec: 175.13 - lr: 0.003125\n",
            "2021-06-03 18:59:35,766 epoch 52 - iter 52/267 - loss 1.17441342 - samples/sec: 134.25 - lr: 0.003125\n",
            "2021-06-03 18:59:40,165 epoch 52 - iter 78/267 - loss 1.18495072 - samples/sec: 193.69 - lr: 0.003125\n",
            "2021-06-03 18:59:44,645 epoch 52 - iter 104/267 - loss 1.18061725 - samples/sec: 189.66 - lr: 0.003125\n",
            "2021-06-03 18:59:49,228 epoch 52 - iter 130/267 - loss 1.18617809 - samples/sec: 185.98 - lr: 0.003125\n",
            "2021-06-03 18:59:55,212 epoch 52 - iter 156/267 - loss 1.18008963 - samples/sec: 185.35 - lr: 0.003125\n",
            "2021-06-03 18:59:59,782 epoch 52 - iter 182/267 - loss 1.18538667 - samples/sec: 185.94 - lr: 0.003125\n",
            "2021-06-03 19:00:04,406 epoch 52 - iter 208/267 - loss 1.18655813 - samples/sec: 183.96 - lr: 0.003125\n",
            "2021-06-03 19:00:08,920 epoch 52 - iter 234/267 - loss 1.18609039 - samples/sec: 188.65 - lr: 0.003125\n",
            "2021-06-03 19:00:13,391 epoch 52 - iter 260/267 - loss 1.18675033 - samples/sec: 189.06 - lr: 0.003125\n",
            "2021-06-03 19:00:16,133 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:00:16,134 EPOCH 52 done: loss 1.1850 - lr 0.0031250\n",
            "2021-06-03 19:00:23,382 DEV : loss 1.240958571434021 - score 0.4478\n",
            "2021-06-03 19:00:24,166 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 19:00:24,168 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:00:29,464 epoch 53 - iter 26/267 - loss 1.17002729 - samples/sec: 176.93 - lr: 0.003125\n",
            "2021-06-03 19:00:34,175 epoch 53 - iter 52/267 - loss 1.19130771 - samples/sec: 183.00 - lr: 0.003125\n",
            "2021-06-03 19:00:40,269 epoch 53 - iter 78/267 - loss 1.20034214 - samples/sec: 186.47 - lr: 0.003125\n",
            "2021-06-03 19:00:44,688 epoch 53 - iter 104/267 - loss 1.19179973 - samples/sec: 192.24 - lr: 0.003125\n",
            "2021-06-03 19:00:49,049 epoch 53 - iter 130/267 - loss 1.19342086 - samples/sec: 194.99 - lr: 0.003125\n",
            "2021-06-03 19:00:53,652 epoch 53 - iter 156/267 - loss 1.19474186 - samples/sec: 184.56 - lr: 0.003125\n",
            "2021-06-03 19:00:59,509 epoch 53 - iter 182/267 - loss 1.19352505 - samples/sec: 188.23 - lr: 0.003125\n",
            "2021-06-03 19:01:04,125 epoch 53 - iter 208/267 - loss 1.19516933 - samples/sec: 184.48 - lr: 0.003125\n",
            "2021-06-03 19:01:08,532 epoch 53 - iter 234/267 - loss 1.19568514 - samples/sec: 192.87 - lr: 0.003125\n",
            "2021-06-03 19:01:13,004 epoch 53 - iter 260/267 - loss 1.19401996 - samples/sec: 190.24 - lr: 0.003125\n",
            "2021-06-03 19:01:14,376 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:01:14,378 EPOCH 53 done: loss 1.1925 - lr 0.0031250\n",
            "2021-06-03 19:01:22,989 DEV : loss 1.2447879314422607 - score 0.446\n",
            "2021-06-03 19:01:23,765 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 19:01:23,767 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:01:28,876 epoch 54 - iter 26/267 - loss 1.15051234 - samples/sec: 184.25 - lr: 0.003125\n",
            "2021-06-03 19:01:33,587 epoch 54 - iter 52/267 - loss 1.17203699 - samples/sec: 181.67 - lr: 0.003125\n",
            "2021-06-03 19:01:38,170 epoch 54 - iter 78/267 - loss 1.17082515 - samples/sec: 186.57 - lr: 0.003125\n",
            "2021-06-03 19:01:44,442 epoch 54 - iter 104/267 - loss 1.17613752 - samples/sec: 182.43 - lr: 0.003125\n",
            "2021-06-03 19:01:49,039 epoch 54 - iter 130/267 - loss 1.18307567 - samples/sec: 185.13 - lr: 0.003125\n",
            "2021-06-03 19:01:53,494 epoch 54 - iter 156/267 - loss 1.17918090 - samples/sec: 190.54 - lr: 0.003125\n",
            "2021-06-03 19:01:58,031 epoch 54 - iter 182/267 - loss 1.18847841 - samples/sec: 187.43 - lr: 0.003125\n",
            "2021-06-03 19:02:03,898 epoch 54 - iter 208/267 - loss 1.19099471 - samples/sec: 186.81 - lr: 0.003125\n",
            "2021-06-03 19:02:08,336 epoch 54 - iter 234/267 - loss 1.18621107 - samples/sec: 191.33 - lr: 0.003125\n",
            "2021-06-03 19:02:12,884 epoch 54 - iter 260/267 - loss 1.18413337 - samples/sec: 187.03 - lr: 0.003125\n",
            "2021-06-03 19:02:14,275 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:02:14,276 EPOCH 54 done: loss 1.1838 - lr 0.0031250\n",
            "2021-06-03 19:02:21,671 DEV : loss 1.24740469455719 - score 0.4396\n",
            "2021-06-03 19:02:22,445 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 19:02:22,447 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:02:29,410 epoch 55 - iter 26/267 - loss 1.17766312 - samples/sec: 130.01 - lr: 0.003125\n",
            "2021-06-03 19:02:33,856 epoch 55 - iter 52/267 - loss 1.19301900 - samples/sec: 191.68 - lr: 0.003125\n",
            "2021-06-03 19:02:38,382 epoch 55 - iter 78/267 - loss 1.17955756 - samples/sec: 187.69 - lr: 0.003125\n",
            "2021-06-03 19:02:43,050 epoch 55 - iter 104/267 - loss 1.18614046 - samples/sec: 182.46 - lr: 0.003125\n",
            "2021-06-03 19:02:48,833 epoch 55 - iter 130/267 - loss 1.18240825 - samples/sec: 190.34 - lr: 0.003125\n",
            "2021-06-03 19:02:53,345 epoch 55 - iter 156/267 - loss 1.17755896 - samples/sec: 189.16 - lr: 0.003125\n",
            "2021-06-03 19:02:57,860 epoch 55 - iter 182/267 - loss 1.17578809 - samples/sec: 187.45 - lr: 0.003125\n",
            "2021-06-03 19:03:02,343 epoch 55 - iter 208/267 - loss 1.17886178 - samples/sec: 189.01 - lr: 0.003125\n",
            "2021-06-03 19:03:08,111 epoch 55 - iter 234/267 - loss 1.18398061 - samples/sec: 191.73 - lr: 0.003125\n",
            "2021-06-03 19:03:12,606 epoch 55 - iter 260/267 - loss 1.18241883 - samples/sec: 188.51 - lr: 0.003125\n",
            "2021-06-03 19:03:14,010 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:03:14,013 EPOCH 55 done: loss 1.1825 - lr 0.0031250\n",
            "2021-06-03 19:03:21,271 DEV : loss 1.2392477989196777 - score 0.4505\n",
            "Epoch    55: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2021-06-03 19:03:22,061 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 19:03:22,064 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:03:27,420 epoch 56 - iter 26/267 - loss 1.19711018 - samples/sec: 175.29 - lr: 0.001563\n",
            "2021-06-03 19:03:33,566 epoch 56 - iter 52/267 - loss 1.17582935 - samples/sec: 189.75 - lr: 0.001563\n",
            "2021-06-03 19:03:37,930 epoch 56 - iter 78/267 - loss 1.17230026 - samples/sec: 193.84 - lr: 0.001563\n",
            "2021-06-03 19:03:42,283 epoch 56 - iter 104/267 - loss 1.17570790 - samples/sec: 194.96 - lr: 0.001563\n",
            "2021-06-03 19:03:46,781 epoch 56 - iter 130/267 - loss 1.17093819 - samples/sec: 188.35 - lr: 0.001563\n",
            "2021-06-03 19:03:52,691 epoch 56 - iter 156/267 - loss 1.17316674 - samples/sec: 185.16 - lr: 0.001563\n",
            "2021-06-03 19:03:57,036 epoch 56 - iter 182/267 - loss 1.16940845 - samples/sec: 195.93 - lr: 0.001563\n",
            "2021-06-03 19:04:01,636 epoch 56 - iter 208/267 - loss 1.17173228 - samples/sec: 184.64 - lr: 0.001563\n",
            "2021-06-03 19:04:06,163 epoch 56 - iter 234/267 - loss 1.17675281 - samples/sec: 187.28 - lr: 0.001563\n",
            "2021-06-03 19:04:12,250 epoch 56 - iter 260/267 - loss 1.17652760 - samples/sec: 182.79 - lr: 0.001563\n",
            "2021-06-03 19:04:13,698 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:04:13,699 EPOCH 56 done: loss 1.1775 - lr 0.0015625\n",
            "2021-06-03 19:04:20,951 DEV : loss 1.2418889999389648 - score 0.4487\n",
            "2021-06-03 19:04:21,751 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 19:04:21,753 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:04:26,985 epoch 57 - iter 26/267 - loss 1.21329430 - samples/sec: 176.79 - lr: 0.001563\n",
            "2021-06-03 19:04:33,148 epoch 57 - iter 52/267 - loss 1.19538145 - samples/sec: 188.18 - lr: 0.001563\n",
            "2021-06-03 19:04:37,695 epoch 57 - iter 78/267 - loss 1.19851823 - samples/sec: 186.57 - lr: 0.001563\n",
            "2021-06-03 19:04:42,154 epoch 57 - iter 104/267 - loss 1.18957747 - samples/sec: 190.40 - lr: 0.001563\n",
            "2021-06-03 19:04:46,704 epoch 57 - iter 130/267 - loss 1.18920899 - samples/sec: 187.34 - lr: 0.001563\n",
            "2021-06-03 19:04:52,615 epoch 57 - iter 156/267 - loss 1.18946876 - samples/sec: 185.90 - lr: 0.001563\n",
            "2021-06-03 19:04:57,142 epoch 57 - iter 182/267 - loss 1.18361782 - samples/sec: 186.92 - lr: 0.001563\n",
            "2021-06-03 19:05:01,718 epoch 57 - iter 208/267 - loss 1.18508868 - samples/sec: 185.96 - lr: 0.001563\n",
            "2021-06-03 19:05:06,230 epoch 57 - iter 234/267 - loss 1.18102752 - samples/sec: 187.58 - lr: 0.001563\n",
            "2021-06-03 19:05:12,095 epoch 57 - iter 260/267 - loss 1.18176419 - samples/sec: 189.43 - lr: 0.001563\n",
            "2021-06-03 19:05:13,466 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:05:13,468 EPOCH 57 done: loss 1.1794 - lr 0.0015625\n",
            "2021-06-03 19:05:20,697 DEV : loss 1.2432814836502075 - score 0.4469\n",
            "2021-06-03 19:05:21,485 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 19:05:21,488 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:05:26,878 epoch 58 - iter 26/267 - loss 1.16904804 - samples/sec: 175.88 - lr: 0.001563\n",
            "2021-06-03 19:05:33,337 epoch 58 - iter 52/267 - loss 1.17789089 - samples/sec: 180.81 - lr: 0.001563\n",
            "2021-06-03 19:05:38,058 epoch 58 - iter 78/267 - loss 1.19182660 - samples/sec: 180.04 - lr: 0.001563\n",
            "2021-06-03 19:05:42,599 epoch 58 - iter 104/267 - loss 1.18534555 - samples/sec: 186.96 - lr: 0.001563\n",
            "2021-06-03 19:05:47,207 epoch 58 - iter 130/267 - loss 1.18705920 - samples/sec: 184.87 - lr: 0.001563\n",
            "2021-06-03 19:05:53,221 epoch 58 - iter 156/267 - loss 1.18479016 - samples/sec: 140.34 - lr: 0.001563\n",
            "2021-06-03 19:05:57,816 epoch 58 - iter 182/267 - loss 1.18683862 - samples/sec: 184.53 - lr: 0.001563\n",
            "2021-06-03 19:06:02,312 epoch 58 - iter 208/267 - loss 1.18703642 - samples/sec: 189.69 - lr: 0.001563\n",
            "2021-06-03 19:06:06,961 epoch 58 - iter 234/267 - loss 1.18955070 - samples/sec: 183.27 - lr: 0.001563\n",
            "2021-06-03 19:06:11,382 epoch 58 - iter 260/267 - loss 1.18498758 - samples/sec: 191.79 - lr: 0.001563\n",
            "2021-06-03 19:06:14,171 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:06:14,173 EPOCH 58 done: loss 1.1869 - lr 0.0015625\n",
            "2021-06-03 19:06:21,499 DEV : loss 1.2451821565628052 - score 0.4396\n",
            "2021-06-03 19:06:22,287 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 19:06:22,290 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:06:27,516 epoch 59 - iter 26/267 - loss 1.19968840 - samples/sec: 180.83 - lr: 0.001563\n",
            "2021-06-03 19:06:32,192 epoch 59 - iter 52/267 - loss 1.20049304 - samples/sec: 182.31 - lr: 0.001563\n",
            "2021-06-03 19:06:38,445 epoch 59 - iter 78/267 - loss 1.20148887 - samples/sec: 135.21 - lr: 0.001563\n",
            "2021-06-03 19:06:42,998 epoch 59 - iter 104/267 - loss 1.18317487 - samples/sec: 186.28 - lr: 0.001563\n",
            "2021-06-03 19:06:47,582 epoch 59 - iter 130/267 - loss 1.17998591 - samples/sec: 185.05 - lr: 0.001563\n",
            "2021-06-03 19:06:51,998 epoch 59 - iter 156/267 - loss 1.17855704 - samples/sec: 193.04 - lr: 0.001563\n",
            "2021-06-03 19:06:57,878 epoch 59 - iter 182/267 - loss 1.17382175 - samples/sec: 188.38 - lr: 0.001563\n",
            "2021-06-03 19:07:02,390 epoch 59 - iter 208/267 - loss 1.17393308 - samples/sec: 188.61 - lr: 0.001563\n",
            "2021-06-03 19:07:07,000 epoch 59 - iter 234/267 - loss 1.17682782 - samples/sec: 184.93 - lr: 0.001563\n",
            "2021-06-03 19:07:11,347 epoch 59 - iter 260/267 - loss 1.17864318 - samples/sec: 195.30 - lr: 0.001563\n",
            "2021-06-03 19:07:12,762 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:07:12,764 EPOCH 59 done: loss 1.1778 - lr 0.0015625\n",
            "2021-06-03 19:07:21,522 DEV : loss 1.2435338497161865 - score 0.4423\n",
            "Epoch    59: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2021-06-03 19:07:22,290 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 19:07:22,294 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:07:27,557 epoch 60 - iter 26/267 - loss 1.18074441 - samples/sec: 177.93 - lr: 0.000781\n",
            "2021-06-03 19:07:32,145 epoch 60 - iter 52/267 - loss 1.18385207 - samples/sec: 187.14 - lr: 0.000781\n",
            "2021-06-03 19:07:36,907 epoch 60 - iter 78/267 - loss 1.17935000 - samples/sec: 180.18 - lr: 0.000781\n",
            "2021-06-03 19:07:42,988 epoch 60 - iter 104/267 - loss 1.17726032 - samples/sec: 139.05 - lr: 0.000781\n",
            "2021-06-03 19:07:47,450 epoch 60 - iter 130/267 - loss 1.18524769 - samples/sec: 190.45 - lr: 0.000781\n",
            "2021-06-03 19:07:51,946 epoch 60 - iter 156/267 - loss 1.18449696 - samples/sec: 189.00 - lr: 0.000781\n",
            "2021-06-03 19:07:56,495 epoch 60 - iter 182/267 - loss 1.18776374 - samples/sec: 186.74 - lr: 0.000781\n",
            "2021-06-03 19:08:01,948 epoch 60 - iter 208/267 - loss 1.19275319 - samples/sec: 154.96 - lr: 0.000781\n",
            "2021-06-03 19:08:06,321 epoch 60 - iter 234/267 - loss 1.19311852 - samples/sec: 194.10 - lr: 0.000781\n",
            "2021-06-03 19:08:10,465 epoch 60 - iter 260/267 - loss 1.19133536 - samples/sec: 204.14 - lr: 0.000781\n",
            "2021-06-03 19:08:11,832 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:08:11,834 EPOCH 60 done: loss 1.1886 - lr 0.0007813\n",
            "2021-06-03 19:08:20,256 DEV : loss 1.24122154712677 - score 0.4496\n",
            "2021-06-03 19:08:21,001 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 19:08:21,003 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:08:26,187 epoch 61 - iter 26/267 - loss 1.19966688 - samples/sec: 181.16 - lr: 0.000781\n",
            "2021-06-03 19:08:30,823 epoch 61 - iter 52/267 - loss 1.18606712 - samples/sec: 183.84 - lr: 0.000781\n",
            "2021-06-03 19:08:35,296 epoch 61 - iter 78/267 - loss 1.19738691 - samples/sec: 191.49 - lr: 0.000781\n",
            "2021-06-03 19:08:41,005 epoch 61 - iter 104/267 - loss 1.20160705 - samples/sec: 147.87 - lr: 0.000781\n",
            "2021-06-03 19:08:45,359 epoch 61 - iter 130/267 - loss 1.20039123 - samples/sec: 194.05 - lr: 0.000781\n",
            "2021-06-03 19:08:49,560 epoch 61 - iter 156/267 - loss 1.20484479 - samples/sec: 201.86 - lr: 0.000781\n",
            "2021-06-03 19:08:53,893 epoch 61 - iter 182/267 - loss 1.19920094 - samples/sec: 195.11 - lr: 0.000781\n",
            "2021-06-03 19:08:59,503 epoch 61 - iter 208/267 - loss 1.19305299 - samples/sec: 150.20 - lr: 0.000781\n",
            "2021-06-03 19:09:03,892 epoch 61 - iter 234/267 - loss 1.18879922 - samples/sec: 193.38 - lr: 0.000781\n",
            "2021-06-03 19:09:08,261 epoch 61 - iter 260/267 - loss 1.18954489 - samples/sec: 193.83 - lr: 0.000781\n",
            "2021-06-03 19:09:09,578 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:09:09,580 EPOCH 61 done: loss 1.1878 - lr 0.0007813\n",
            "2021-06-03 19:09:16,480 DEV : loss 1.244757890701294 - score 0.4441\n",
            "2021-06-03 19:09:17,240 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 19:09:17,241 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:09:26,176 epoch 62 - iter 26/267 - loss 1.22796881 - samples/sec: 181.90 - lr: 0.000781\n",
            "2021-06-03 19:09:30,985 epoch 62 - iter 52/267 - loss 1.19957837 - samples/sec: 189.03 - lr: 0.000781\n",
            "2021-06-03 19:09:35,218 epoch 62 - iter 78/267 - loss 1.19788897 - samples/sec: 200.54 - lr: 0.000781\n",
            "2021-06-03 19:09:39,480 epoch 62 - iter 104/267 - loss 1.18396925 - samples/sec: 198.51 - lr: 0.000781\n",
            "2021-06-03 19:09:45,018 epoch 62 - iter 130/267 - loss 1.19033216 - samples/sec: 191.92 - lr: 0.000781\n",
            "2021-06-03 19:09:49,507 epoch 62 - iter 156/267 - loss 1.18715726 - samples/sec: 189.15 - lr: 0.000781\n",
            "2021-06-03 19:09:53,885 epoch 62 - iter 182/267 - loss 1.18507196 - samples/sec: 193.59 - lr: 0.000781\n",
            "2021-06-03 19:09:58,242 epoch 62 - iter 208/267 - loss 1.19088014 - samples/sec: 194.10 - lr: 0.000781\n",
            "2021-06-03 19:10:03,730 epoch 62 - iter 234/267 - loss 1.18450130 - samples/sec: 153.73 - lr: 0.000781\n",
            "2021-06-03 19:10:08,122 epoch 62 - iter 260/267 - loss 1.18592594 - samples/sec: 193.38 - lr: 0.000781\n",
            "2021-06-03 19:10:09,602 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:10:09,604 EPOCH 62 done: loss 1.1861 - lr 0.0007813\n",
            "2021-06-03 19:10:16,594 DEV : loss 1.2420741319656372 - score 0.4469\n",
            "2021-06-03 19:10:17,346 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 19:10:17,348 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:10:25,594 epoch 63 - iter 26/267 - loss 1.16735071 - samples/sec: 178.33 - lr: 0.000781\n",
            "2021-06-03 19:10:29,969 epoch 63 - iter 52/267 - loss 1.16497319 - samples/sec: 194.75 - lr: 0.000781\n",
            "2021-06-03 19:10:34,316 epoch 63 - iter 78/267 - loss 1.16547840 - samples/sec: 195.41 - lr: 0.000781\n",
            "2021-06-03 19:10:39,706 epoch 63 - iter 104/267 - loss 1.15982243 - samples/sec: 197.12 - lr: 0.000781\n",
            "2021-06-03 19:10:44,004 epoch 63 - iter 130/267 - loss 1.16991813 - samples/sec: 197.58 - lr: 0.000781\n",
            "2021-06-03 19:10:48,272 epoch 63 - iter 156/267 - loss 1.16712058 - samples/sec: 199.25 - lr: 0.000781\n",
            "2021-06-03 19:10:52,696 epoch 63 - iter 182/267 - loss 1.17417532 - samples/sec: 192.46 - lr: 0.000781\n",
            "2021-06-03 19:10:57,020 epoch 63 - iter 208/267 - loss 1.17305401 - samples/sec: 196.50 - lr: 0.000781\n",
            "2021-06-03 19:11:02,589 epoch 63 - iter 234/267 - loss 1.18111192 - samples/sec: 151.46 - lr: 0.000781\n",
            "2021-06-03 19:11:06,954 epoch 63 - iter 260/267 - loss 1.18099068 - samples/sec: 194.25 - lr: 0.000781\n",
            "2021-06-03 19:11:08,315 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:11:08,316 EPOCH 63 done: loss 1.1807 - lr 0.0007813\n",
            "2021-06-03 19:11:15,245 DEV : loss 1.2437591552734375 - score 0.4478\n",
            "Epoch    63: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2021-06-03 19:11:16,006 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 19:11:16,008 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:11:22,455 epoch 64 - iter 26/267 - loss 1.13299885 - samples/sec: 141.29 - lr: 0.000391\n",
            "2021-06-03 19:11:26,802 epoch 64 - iter 52/267 - loss 1.14977040 - samples/sec: 195.43 - lr: 0.000391\n",
            "2021-06-03 19:11:31,122 epoch 64 - iter 78/267 - loss 1.17148235 - samples/sec: 196.18 - lr: 0.000391\n",
            "2021-06-03 19:11:35,622 epoch 64 - iter 104/267 - loss 1.17374845 - samples/sec: 187.97 - lr: 0.000391\n",
            "2021-06-03 19:11:41,238 epoch 64 - iter 130/267 - loss 1.17761848 - samples/sec: 188.03 - lr: 0.000391\n",
            "2021-06-03 19:11:45,817 epoch 64 - iter 156/267 - loss 1.17786165 - samples/sec: 185.21 - lr: 0.000391\n",
            "2021-06-03 19:11:50,074 epoch 64 - iter 182/267 - loss 1.18050057 - samples/sec: 198.79 - lr: 0.000391\n",
            "2021-06-03 19:11:54,374 epoch 64 - iter 208/267 - loss 1.18194931 - samples/sec: 197.65 - lr: 0.000391\n",
            "2021-06-03 19:11:58,745 epoch 64 - iter 234/267 - loss 1.17871368 - samples/sec: 193.64 - lr: 0.000391\n",
            "2021-06-03 19:12:04,277 epoch 64 - iter 260/267 - loss 1.17895319 - samples/sec: 152.26 - lr: 0.000391\n",
            "2021-06-03 19:12:05,586 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:12:05,588 EPOCH 64 done: loss 1.1780 - lr 0.0003906\n",
            "2021-06-03 19:12:12,566 DEV : loss 1.2424348592758179 - score 0.4496\n",
            "2021-06-03 19:12:13,317 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 19:12:13,320 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:12:18,478 epoch 65 - iter 26/267 - loss 1.18669875 - samples/sec: 181.79 - lr: 0.000391\n",
            "2021-06-03 19:12:24,298 epoch 65 - iter 52/267 - loss 1.18940980 - samples/sec: 145.25 - lr: 0.000391\n",
            "2021-06-03 19:12:28,688 epoch 65 - iter 78/267 - loss 1.17728274 - samples/sec: 193.31 - lr: 0.000391\n",
            "2021-06-03 19:12:33,036 epoch 65 - iter 104/267 - loss 1.16789291 - samples/sec: 194.69 - lr: 0.000391\n",
            "2021-06-03 19:12:37,371 epoch 65 - iter 130/267 - loss 1.17034044 - samples/sec: 195.51 - lr: 0.000391\n",
            "2021-06-03 19:12:42,878 epoch 65 - iter 156/267 - loss 1.17109011 - samples/sec: 191.40 - lr: 0.000391\n",
            "2021-06-03 19:12:47,125 epoch 65 - iter 182/267 - loss 1.17831445 - samples/sec: 199.47 - lr: 0.000391\n",
            "2021-06-03 19:12:51,586 epoch 65 - iter 208/267 - loss 1.18171550 - samples/sec: 190.50 - lr: 0.000391\n",
            "2021-06-03 19:12:55,856 epoch 65 - iter 234/267 - loss 1.18202495 - samples/sec: 197.74 - lr: 0.000391\n",
            "2021-06-03 19:13:01,200 epoch 65 - iter 260/267 - loss 1.18287620 - samples/sec: 200.69 - lr: 0.000391\n",
            "2021-06-03 19:13:02,607 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:13:02,608 EPOCH 65 done: loss 1.1802 - lr 0.0003906\n",
            "2021-06-03 19:13:09,640 DEV : loss 1.2416660785675049 - score 0.4541\n",
            "2021-06-03 19:13:10,381 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 19:13:10,384 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:13:15,473 epoch 66 - iter 26/267 - loss 1.22575866 - samples/sec: 183.34 - lr: 0.000391\n",
            "2021-06-03 19:13:21,351 epoch 66 - iter 52/267 - loss 1.20286616 - samples/sec: 192.06 - lr: 0.000391\n",
            "2021-06-03 19:13:25,611 epoch 66 - iter 78/267 - loss 1.17662649 - samples/sec: 199.29 - lr: 0.000391\n",
            "2021-06-03 19:13:29,972 epoch 66 - iter 104/267 - loss 1.17830383 - samples/sec: 194.47 - lr: 0.000391\n",
            "2021-06-03 19:13:34,366 epoch 66 - iter 130/267 - loss 1.17627153 - samples/sec: 193.34 - lr: 0.000391\n",
            "2021-06-03 19:13:39,945 epoch 66 - iter 156/267 - loss 1.17774189 - samples/sec: 190.85 - lr: 0.000391\n",
            "2021-06-03 19:13:44,236 epoch 66 - iter 182/267 - loss 1.17583978 - samples/sec: 197.30 - lr: 0.000391\n",
            "2021-06-03 19:13:48,526 epoch 66 - iter 208/267 - loss 1.17534057 - samples/sec: 198.54 - lr: 0.000391\n",
            "2021-06-03 19:13:52,994 epoch 66 - iter 234/267 - loss 1.17801029 - samples/sec: 190.31 - lr: 0.000391\n",
            "2021-06-03 19:13:57,345 epoch 66 - iter 260/267 - loss 1.18004183 - samples/sec: 194.76 - lr: 0.000391\n",
            "2021-06-03 19:13:59,772 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:13:59,774 EPOCH 66 done: loss 1.1800 - lr 0.0003906\n",
            "2021-06-03 19:14:06,783 DEV : loss 1.242282748222351 - score 0.4523\n",
            "2021-06-03 19:14:07,526 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 19:14:07,527 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:14:12,612 epoch 67 - iter 26/267 - loss 1.18471557 - samples/sec: 183.86 - lr: 0.000391\n",
            "2021-06-03 19:14:17,211 epoch 67 - iter 52/267 - loss 1.20219462 - samples/sec: 186.17 - lr: 0.000391\n",
            "2021-06-03 19:14:22,957 epoch 67 - iter 78/267 - loss 1.20142350 - samples/sec: 194.80 - lr: 0.000391\n",
            "2021-06-03 19:14:27,441 epoch 67 - iter 104/267 - loss 1.19133532 - samples/sec: 189.27 - lr: 0.000391\n",
            "2021-06-03 19:14:31,733 epoch 67 - iter 130/267 - loss 1.18409061 - samples/sec: 198.43 - lr: 0.000391\n",
            "2021-06-03 19:14:36,176 epoch 67 - iter 156/267 - loss 1.18789381 - samples/sec: 192.14 - lr: 0.000391\n",
            "2021-06-03 19:14:40,564 epoch 67 - iter 182/267 - loss 1.19178151 - samples/sec: 193.86 - lr: 0.000391\n",
            "2021-06-03 19:14:45,937 epoch 67 - iter 208/267 - loss 1.19161227 - samples/sec: 157.31 - lr: 0.000391\n",
            "2021-06-03 19:14:50,163 epoch 67 - iter 234/267 - loss 1.18678642 - samples/sec: 200.90 - lr: 0.000391\n",
            "2021-06-03 19:14:54,487 epoch 67 - iter 260/267 - loss 1.18558374 - samples/sec: 197.08 - lr: 0.000391\n",
            "2021-06-03 19:14:55,804 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:14:55,806 EPOCH 67 done: loss 1.1839 - lr 0.0003906\n",
            "2021-06-03 19:15:02,785 DEV : loss 1.2421045303344727 - score 0.4514\n",
            "Epoch    67: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2021-06-03 19:15:03,541 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 19:15:03,542 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:15:11,055 epoch 68 - iter 26/267 - loss 1.15141485 - samples/sec: 196.48 - lr: 0.000195\n",
            "2021-06-03 19:15:17,903 epoch 68 - iter 52/267 - loss 1.16370850 - samples/sec: 187.74 - lr: 0.000195\n",
            "2021-06-03 19:15:23,390 epoch 68 - iter 78/267 - loss 1.15289324 - samples/sec: 190.16 - lr: 0.000195\n",
            "2021-06-03 19:15:27,809 epoch 68 - iter 104/267 - loss 1.16752581 - samples/sec: 191.75 - lr: 0.000195\n",
            "2021-06-03 19:15:33,238 epoch 68 - iter 130/267 - loss 1.17010765 - samples/sec: 155.57 - lr: 0.000195\n",
            "2021-06-03 19:15:37,630 epoch 68 - iter 156/267 - loss 1.17195037 - samples/sec: 192.58 - lr: 0.000195\n",
            "2021-06-03 19:15:41,930 epoch 68 - iter 182/267 - loss 1.17471013 - samples/sec: 196.76 - lr: 0.000195\n",
            "2021-06-03 19:15:46,241 epoch 68 - iter 208/267 - loss 1.17842755 - samples/sec: 197.22 - lr: 0.000195\n",
            "2021-06-03 19:15:51,762 epoch 68 - iter 234/267 - loss 1.17831758 - samples/sec: 153.30 - lr: 0.000195\n",
            "2021-06-03 19:15:56,048 epoch 68 - iter 260/267 - loss 1.17872403 - samples/sec: 198.47 - lr: 0.000195\n",
            "2021-06-03 19:15:57,432 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:15:57,434 EPOCH 68 done: loss 1.1782 - lr 0.0001953\n",
            "2021-06-03 19:16:04,306 DEV : loss 1.24201238155365 - score 0.4523\n",
            "2021-06-03 19:16:05,056 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 19:16:05,058 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:16:11,480 epoch 69 - iter 26/267 - loss 1.17367013 - samples/sec: 190.43 - lr: 0.000195\n",
            "2021-06-03 19:16:15,922 epoch 69 - iter 52/267 - loss 1.18152695 - samples/sec: 191.01 - lr: 0.000195\n",
            "2021-06-03 19:16:20,297 epoch 69 - iter 78/267 - loss 1.17537437 - samples/sec: 193.67 - lr: 0.000195\n",
            "2021-06-03 19:16:24,656 epoch 69 - iter 104/267 - loss 1.16137713 - samples/sec: 194.22 - lr: 0.000195\n",
            "2021-06-03 19:16:30,127 epoch 69 - iter 130/267 - loss 1.16139291 - samples/sec: 154.21 - lr: 0.000195\n",
            "2021-06-03 19:16:34,515 epoch 69 - iter 156/267 - loss 1.15921672 - samples/sec: 193.18 - lr: 0.000195\n",
            "2021-06-03 19:16:38,864 epoch 69 - iter 182/267 - loss 1.16105783 - samples/sec: 195.69 - lr: 0.000195\n",
            "2021-06-03 19:16:43,205 epoch 69 - iter 208/267 - loss 1.16679895 - samples/sec: 195.31 - lr: 0.000195\n",
            "2021-06-03 19:16:48,659 epoch 69 - iter 234/267 - loss 1.17165114 - samples/sec: 195.28 - lr: 0.000195\n",
            "2021-06-03 19:16:53,047 epoch 69 - iter 260/267 - loss 1.17308448 - samples/sec: 192.90 - lr: 0.000195\n",
            "2021-06-03 19:16:54,365 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:16:54,368 EPOCH 69 done: loss 1.1737 - lr 0.0001953\n",
            "2021-06-03 19:17:01,412 DEV : loss 1.2426769733428955 - score 0.4514\n",
            "2021-06-03 19:17:02,161 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 19:17:02,163 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:17:07,279 epoch 70 - iter 26/267 - loss 1.18750678 - samples/sec: 184.02 - lr: 0.000195\n",
            "2021-06-03 19:17:13,181 epoch 70 - iter 52/267 - loss 1.18814162 - samples/sec: 189.76 - lr: 0.000195\n",
            "2021-06-03 19:17:17,531 epoch 70 - iter 78/267 - loss 1.18408795 - samples/sec: 195.30 - lr: 0.000195\n",
            "2021-06-03 19:17:21,886 epoch 70 - iter 104/267 - loss 1.17653914 - samples/sec: 194.36 - lr: 0.000195\n",
            "2021-06-03 19:17:26,286 epoch 70 - iter 130/267 - loss 1.17695222 - samples/sec: 192.42 - lr: 0.000195\n",
            "2021-06-03 19:17:31,878 epoch 70 - iter 156/267 - loss 1.17819716 - samples/sec: 191.97 - lr: 0.000195\n",
            "2021-06-03 19:17:36,243 epoch 70 - iter 182/267 - loss 1.17720612 - samples/sec: 194.14 - lr: 0.000195\n",
            "2021-06-03 19:17:40,717 epoch 70 - iter 208/267 - loss 1.17661667 - samples/sec: 188.97 - lr: 0.000195\n",
            "2021-06-03 19:17:46,247 epoch 70 - iter 234/267 - loss 1.17924456 - samples/sec: 191.75 - lr: 0.000195\n",
            "2021-06-03 19:17:50,483 epoch 70 - iter 260/267 - loss 1.17642993 - samples/sec: 199.65 - lr: 0.000195\n",
            "2021-06-03 19:17:51,816 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:17:51,818 EPOCH 70 done: loss 1.1765 - lr 0.0001953\n",
            "2021-06-03 19:17:58,775 DEV : loss 1.2428364753723145 - score 0.4514\n",
            "2021-06-03 19:17:59,536 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 19:17:59,538 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:18:04,680 epoch 71 - iter 26/267 - loss 1.21627826 - samples/sec: 182.39 - lr: 0.000195\n",
            "2021-06-03 19:18:10,636 epoch 71 - iter 52/267 - loss 1.19105203 - samples/sec: 188.50 - lr: 0.000195\n",
            "2021-06-03 19:18:15,096 epoch 71 - iter 78/267 - loss 1.19909560 - samples/sec: 190.67 - lr: 0.000195\n",
            "2021-06-03 19:18:19,401 epoch 71 - iter 104/267 - loss 1.19896139 - samples/sec: 196.72 - lr: 0.000195\n",
            "2021-06-03 19:18:23,757 epoch 71 - iter 130/267 - loss 1.19398741 - samples/sec: 194.53 - lr: 0.000195\n",
            "2021-06-03 19:18:29,194 epoch 71 - iter 156/267 - loss 1.19620490 - samples/sec: 197.84 - lr: 0.000195\n",
            "2021-06-03 19:18:33,450 epoch 71 - iter 182/267 - loss 1.19081871 - samples/sec: 199.07 - lr: 0.000195\n",
            "2021-06-03 19:18:37,743 epoch 71 - iter 208/267 - loss 1.18589516 - samples/sec: 197.49 - lr: 0.000195\n",
            "2021-06-03 19:18:42,036 epoch 71 - iter 234/267 - loss 1.18359508 - samples/sec: 198.25 - lr: 0.000195\n",
            "2021-06-03 19:18:47,591 epoch 71 - iter 260/267 - loss 1.18026243 - samples/sec: 151.68 - lr: 0.000195\n",
            "2021-06-03 19:18:48,970 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:18:48,971 EPOCH 71 done: loss 1.1823 - lr 0.0001953\n",
            "2021-06-03 19:18:55,899 DEV : loss 1.242762565612793 - score 0.4514\n",
            "Epoch    71: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2021-06-03 19:18:56,644 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 19:18:56,646 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:18:56,648 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:18:56,650 learning rate too small - quitting training!\n",
            "2021-06-03 19:18:56,656 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:18:59,649 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 19:18:59,651 Testing using best model ...\n",
            "2021-06-03 19:18:59,652 loading file best-model.pt\n",
            "2021-06-03 19:19:07,454 \t0.4561\n",
            "2021-06-03 19:19:07,456 \n",
            "Results:\n",
            "- F-score (micro) 0.4561\n",
            "- F-score (macro) 0.3827\n",
            "- Accuracy 0.4561\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4     0.4204    0.5176    0.4640       510\n",
            "           5     0.5936    0.3734    0.4585       399\n",
            "           3     0.4014    0.1465    0.2147       389\n",
            "           2     0.4467    0.7946    0.5719       633\n",
            "           1     0.5556    0.1254    0.2047       279\n",
            "\n",
            "   micro avg     0.4561    0.4561    0.4561      2210\n",
            "   macro avg     0.4835    0.3915    0.3827      2210\n",
            "weighted avg     0.4729    0.4561    0.4173      2210\n",
            " samples avg     0.4561    0.4561    0.4561      2210\n",
            "\n",
            "2021-06-03 19:19:07,458 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [1.8895463943481445,\n",
              "  1.5292648077011108,\n",
              "  1.5026493072509766,\n",
              "  1.5123043060302734,\n",
              "  1.434011697769165,\n",
              "  1.45767343044281,\n",
              "  1.4453024864196777,\n",
              "  1.3718746900558472,\n",
              "  1.4912729263305664,\n",
              "  1.3686164617538452,\n",
              "  1.3659861087799072,\n",
              "  1.3922005891799927,\n",
              "  1.321976661682129,\n",
              "  1.385625958442688,\n",
              "  1.3068249225616455,\n",
              "  1.3438165187835693,\n",
              "  1.3014328479766846,\n",
              "  1.3628509044647217,\n",
              "  1.2833856344223022,\n",
              "  1.2830673456192017,\n",
              "  1.2812750339508057,\n",
              "  1.2966969013214111,\n",
              "  1.2966302633285522,\n",
              "  1.2599409818649292,\n",
              "  1.2963993549346924,\n",
              "  1.2949364185333252,\n",
              "  1.251914143562317,\n",
              "  1.2412278652191162,\n",
              "  1.24015474319458,\n",
              "  1.2801177501678467,\n",
              "  1.2486207485198975,\n",
              "  1.2619365453720093,\n",
              "  1.2472915649414062,\n",
              "  1.2523921728134155,\n",
              "  1.2374622821807861,\n",
              "  1.2548518180847168,\n",
              "  1.231776475906372,\n",
              "  1.253846526145935,\n",
              "  1.2420426607131958,\n",
              "  1.2441121339797974,\n",
              "  1.2491366863250732,\n",
              "  1.2370116710662842,\n",
              "  1.2394758462905884,\n",
              "  1.24481999874115,\n",
              "  1.2629224061965942,\n",
              "  1.251117467880249,\n",
              "  1.2627352476119995,\n",
              "  1.2405757904052734,\n",
              "  1.2437089681625366,\n",
              "  1.2567936182022095,\n",
              "  1.2528934478759766,\n",
              "  1.240958571434021,\n",
              "  1.2447879314422607,\n",
              "  1.24740469455719,\n",
              "  1.2392477989196777,\n",
              "  1.2418889999389648,\n",
              "  1.2432814836502075,\n",
              "  1.2451821565628052,\n",
              "  1.2435338497161865,\n",
              "  1.24122154712677,\n",
              "  1.244757890701294,\n",
              "  1.2420741319656372,\n",
              "  1.2437591552734375,\n",
              "  1.2424348592758179,\n",
              "  1.2416660785675049,\n",
              "  1.242282748222351,\n",
              "  1.2421045303344727,\n",
              "  1.24201238155365,\n",
              "  1.2426769733428955,\n",
              "  1.2428364753723145,\n",
              "  1.242762565612793],\n",
              " 'dev_score_history': [0.2652,\n",
              "  0.2834,\n",
              "  0.3115,\n",
              "  0.3415,\n",
              "  0.3742,\n",
              "  0.3179,\n",
              "  0.3688,\n",
              "  0.386,\n",
              "  0.347,\n",
              "  0.3824,\n",
              "  0.4105,\n",
              "  0.3769,\n",
              "  0.4242,\n",
              "  0.3678,\n",
              "  0.426,\n",
              "  0.4015,\n",
              "  0.426,\n",
              "  0.3742,\n",
              "  0.4332,\n",
              "  0.4405,\n",
              "  0.4387,\n",
              "  0.4187,\n",
              "  0.4142,\n",
              "  0.4378,\n",
              "  0.4387,\n",
              "  0.4205,\n",
              "  0.4487,\n",
              "  0.445,\n",
              "  0.446,\n",
              "  0.4214,\n",
              "  0.4378,\n",
              "  0.4405,\n",
              "  0.446,\n",
              "  0.4414,\n",
              "  0.4623,\n",
              "  0.4496,\n",
              "  0.4587,\n",
              "  0.4378,\n",
              "  0.4641,\n",
              "  0.436,\n",
              "  0.4541,\n",
              "  0.4505,\n",
              "  0.4496,\n",
              "  0.4578,\n",
              "  0.4351,\n",
              "  0.4414,\n",
              "  0.4233,\n",
              "  0.455,\n",
              "  0.4378,\n",
              "  0.445,\n",
              "  0.4405,\n",
              "  0.4478,\n",
              "  0.446,\n",
              "  0.4396,\n",
              "  0.4505,\n",
              "  0.4487,\n",
              "  0.4469,\n",
              "  0.4396,\n",
              "  0.4423,\n",
              "  0.4496,\n",
              "  0.4441,\n",
              "  0.4469,\n",
              "  0.4478,\n",
              "  0.4496,\n",
              "  0.4541,\n",
              "  0.4523,\n",
              "  0.4514,\n",
              "  0.4523,\n",
              "  0.4514,\n",
              "  0.4514,\n",
              "  0.4514],\n",
              " 'test_score': 0.4561,\n",
              " 'train_loss_history': [1.2664124429895636,\n",
              "  1.5562493010853113,\n",
              "  1.5318417075867956,\n",
              "  1.507988808306862,\n",
              "  1.485611668240265,\n",
              "  1.47493997718511,\n",
              "  1.4690227696065152,\n",
              "  1.4530426589737224,\n",
              "  1.4414307642518804,\n",
              "  1.4233560539809953,\n",
              "  1.4119645437497772,\n",
              "  1.3992470877893854,\n",
              "  1.3938264163692347,\n",
              "  1.3840805296594283,\n",
              "  1.378113336554181,\n",
              "  1.3701799152495708,\n",
              "  1.366690596837676,\n",
              "  1.3463829407531225,\n",
              "  1.3444920903288022,\n",
              "  1.33411327506719,\n",
              "  1.3294637649693293,\n",
              "  1.3228502278024337,\n",
              "  1.3108192490281236,\n",
              "  1.3024144038725436,\n",
              "  1.2808390186074075,\n",
              "  1.2730489286144129,\n",
              "  1.275323384710019,\n",
              "  1.2717529600032706,\n",
              "  1.2617583768198106,\n",
              "  1.2686337893375297,\n",
              "  1.263765388883455,\n",
              "  1.2420349471577992,\n",
              "  1.2418392843075012,\n",
              "  1.237777330678947,\n",
              "  1.2370302331135068,\n",
              "  1.2280419267965166,\n",
              "  1.2247099516990032,\n",
              "  1.2266707603404585,\n",
              "  1.2360150101925997,\n",
              "  1.2228865034124825,\n",
              "  1.217421178067668,\n",
              "  1.219679982697919,\n",
              "  1.216119086920992,\n",
              "  1.1970205970024794,\n",
              "  1.205588935466295,\n",
              "  1.1970147267263034,\n",
              "  1.2029596951123926,\n",
              "  1.2009343326315005,\n",
              "  1.1941987452435583,\n",
              "  1.1885854349600689,\n",
              "  1.1927112499426367,\n",
              "  1.1850347427393166,\n",
              "  1.192460927847173,\n",
              "  1.183791383152151,\n",
              "  1.182500571124116,\n",
              "  1.1775494077232447,\n",
              "  1.179372841945748,\n",
              "  1.1868556639674896,\n",
              "  1.177829173620274,\n",
              "  1.1886106113369546,\n",
              "  1.1878462840108837,\n",
              "  1.1861188802379794,\n",
              "  1.180743590499578,\n",
              "  1.1779639417312564,\n",
              "  1.1801954681953688,\n",
              "  1.1799769312254944,\n",
              "  1.1839029065678628,\n",
              "  1.1782273266199377,\n",
              "  1.1736694844474507,\n",
              "  1.1765211126331085,\n",
              "  1.1822570281082325]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAfXUFHdY3PU"
      },
      "source": [
        "# plotter = Plotter()\n",
        "# plotter.plot_training_curves('/content/loss.tsv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTAgldJIiOzb"
      },
      "source": [
        "# CONFUSION MATRIX - GENERATION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJKW_lZ67qBN",
        "outputId": "ee504325-c7fb-475e-f5cc-68901eb6f349"
      },
      "source": [
        "classifier = TextClassifier.load('/content/best-model.pt')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 06:20:02,721 loading file /content/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uluxUqsv7-tN",
        "outputId": "1a4a13d0-6108-4eba-db46-729f97fdb24b"
      },
      "source": [
        "sentence = Sentence(\"Steers turns in a snappy screenplay that curls at the edges ; it 's so clever you want to hate it .\")\n",
        "classifier.predict(sentence)\n",
        "print(sentence.labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 (0.4502)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuYRET7g_U75",
        "outputId": "b7a3917f-9c1a-4347-e4b9-c3a4cea7c6bc"
      },
      "source": [
        "sentence = Sentence(\"An utterly compelling ` who wrote it ' in which the reputation of the most famous author who ever lived comes into question  .\")\n",
        "classifier.predict(sentence)\n",
        "print(sentence.labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 (0.3889)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfL7-UEO_nZE",
        "outputId": "188364cf-49f1-4169-f758-9c01ef115b77"
      },
      "source": [
        "sentence = Sentence(\"Very great movie, worth watching 100 times\")\n",
        "classifier.predict(sentence)\n",
        "print(sentence.labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 (0.5575)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbWWQwfwBryL",
        "outputId": "555ed61b-034d-4620-eaab-b786c001b89a"
      },
      "source": [
        "sentence = Sentence(\"Worst movie ever. I could never understand whats going on\")\n",
        "classifier.predict(sentence)\n",
        "print(sentence.labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 (0.427)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEj7UuoIpUx5",
        "outputId": "08da1a8b-f82f-4991-e8a9-39aa58bb1541"
      },
      "source": [
        "sentence = Sentence(\"It all started on high note but the suspense started dropping towards the end\")\n",
        "classifier.predict(sentence)\n",
        "print(sentence.labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 (0.3711)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiMQI4IkZ02S",
        "outputId": "d8e5a262-875a-46f1-de1b-fdade1b62183"
      },
      "source": [
        "sentence = Sentence(\"A disturbing and frighteningly evocative assembly of imagery and hypnotic music composed by Philip Glass .\")\n",
        "classifier.predict(sentence)\n",
        "print(sentence.labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 (0.7684)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LRlmI87Z7V6"
      },
      "source": [
        "sentence = Sentence(\"The story loses its bite in a last-minute happy ending that 's even less plausible than the rest of the picture .\")\n",
        "classifier.predict(sentence)\n",
        "print(sentence.labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0br2vWQCKL4X",
        "outputId": "fd11ed2c-b4d0-4493-ff15-c918632187a0"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv('/content/sst_train.txt', sep='\\t', header=None, names=['Labels', 'text'])\n",
        "df_train['Labels'] = df_train['Labels'].str.replace('__label__', '')\n",
        "df_train['Labels'] = df_train['Labels'].astype(int).astype('category')\n",
        "\n",
        "print(df_train.head())\n",
        "print(df_train.Labels.value_counts(sort=False))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Labels                                               text\n",
            "0      4  The Rock is destined to be the 21st Century 's...\n",
            "1      5  The gorgeously elaborate continuation of `` Th...\n",
            "2      4  Singer/composer Bryan Adams contributes a slew...\n",
            "3      3  You 'd think by now America would have had eno...\n",
            "4      4               Yet the act is still charming here .\n",
            "1    1092\n",
            "2    2218\n",
            "3    1624\n",
            "4    2322\n",
            "5    1288\n",
            "Name: Labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu9bt5Q_lBsN",
        "outputId": "594a055f-7d29-4eed-d868-6a4f93af518f"
      },
      "source": [
        "# with data augmentation\n",
        "## Perform data augmentation on train data frame\n",
        "# Random Delete\n",
        "# Random Swap\n",
        "# Back Translate (facing issue - too many requests)\n",
        "\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "# Augmenting  data basis class distribution (class with less samples will have higher % of augmentation samples)\n",
        "# Augmenting size\n",
        "\n",
        "samples_1=int(df_train['Labels'].value_counts()[0]*.4)\n",
        "samples_2=int(df_train['Labels'].value_counts()[1]*.2)\n",
        "samples_3=int(df_train['Labels'].value_counts()[2]*.3)\n",
        "samples_4=int(df_train['Labels'].value_counts()[3]*.2)\n",
        "samples_5=int(df_train['Labels'].value_counts()[4]*.4)\n",
        "\n",
        "\n",
        "    \n",
        "##selecting the class samples\n",
        "df_1=df_train[df_train.Labels==1].reset_index(drop=True)\n",
        "df_2=df_train[df_train.Labels==2].reset_index(drop=True)\n",
        "df_3=df_train[df_train.Labels==3].reset_index(drop=True)\n",
        "df_4=df_train[df_train.Labels==4].reset_index(drop=True)\n",
        "df_5=df_train[df_train.Labels==5].reset_index(drop=True)\n",
        "\n",
        "## Random Delete ####\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 1\n",
        "for i in tqdm(np.random.randint(0,len(df_1),samples_1)):\n",
        "  text = df_1.iloc[i]['text'].split()\n",
        "  augmented_text = ' '.join(random_deletion(text,0.1))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rd_new_1=pd.DataFrame({'text':new_text,'Labels':1})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 2\n",
        "for i in tqdm(np.random.randint(0,len(df_2),samples_2)):\n",
        "  text = df_2.iloc[i]['text'].split()\n",
        "  augmented_text = ' '.join(random_deletion(text,0.1))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rd_new_2=pd.DataFrame({'text':new_text,'Labels':2})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 3\n",
        "for i in tqdm(np.random.randint(0,len(df_3),samples_3)):\n",
        "  text = df_3.iloc[i]['text'].split()\n",
        "  augmented_text = ' '.join(random_deletion(text,0.1))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rd_new_3=pd.DataFrame({'text':new_text,'Labels':3})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 4\n",
        "for i in tqdm(np.random.randint(0,len(df_4),samples_4)):\n",
        "  text = df_4.iloc[i]['text'].split()\n",
        "  augmented_text = ' '.join(random_deletion(text,0.1))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rd_new_4=pd.DataFrame({'text':new_text,'Labels':4})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 4\n",
        "for i in tqdm(np.random.randint(0,len(df_5),samples_5)):\n",
        "  text = df_5.iloc[i]['text'].split()\n",
        "  augmented_text = ' '.join(random_deletion(text,0.1))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rd_new_5=pd.DataFrame({'text':new_text,'Labels':5})\n",
        "\n",
        "print('\\n',rd_new_1.shape,rd_new_2.shape,rd_new_3.shape,rd_new_4.shape,rd_new_5.shape)\n",
        "\n",
        "\n",
        "## Random Swap ####\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 1\n",
        "for i in tqdm(np.random.randint(0,len(df_1),samples_1)):\n",
        "  text = df_1.iloc[i]['text'].split()\n",
        "  if len(text)>=2:\n",
        "    augmented_text = ' '.join(random_swap(text))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rs_new_1=pd.DataFrame({'text':new_text,'Labels':1})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 2\n",
        "for i in tqdm(np.random.randint(0,len(df_2),samples_2)):\n",
        "  text = df_2.iloc[i]['text'].split()\n",
        "  if len(text)>=2:\n",
        "    augmented_text = ' '.join(random_swap(text))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rs_new_2=pd.DataFrame({'text':new_text,'Labels':2})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 3\n",
        "for i in tqdm(np.random.randint(0,len(df_3),samples_3)):\n",
        "  text = df_3.iloc[i]['text'].split()\n",
        "  if len(text)>=2:\n",
        "    augmented_text = ' '.join(random_swap(text))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rs_new_3=pd.DataFrame({'text':new_text,'Labels':3})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 4\n",
        "for i in tqdm(np.random.randint(0,len(df_4),samples_4)):\n",
        "  text = df_4.iloc[i]['text'].split()\n",
        "  if len(text)>=2:\n",
        "    augmented_text = ' '.join(random_swap(text))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rs_new_4=pd.DataFrame({'text':new_text,'Labels':4})\n",
        "\n",
        "new_text=[]\n",
        "## data augmentation loop - class 5\n",
        "for i in tqdm(np.random.randint(0,len(df_5),samples_5)):\n",
        "  text = df_5.iloc[i]['text'].split()\n",
        "  if len(text)>=2:\n",
        "    augmented_text = ' '.join(random_swap(text))\n",
        "  new_text.append(augmented_text)\n",
        "## dataframe\n",
        "rs_new_5=pd.DataFrame({'text':new_text,'Labels':5})\n",
        "\n",
        "\n",
        "\n",
        "print('\\n',rs_new_1.shape,rs_new_2.shape,rs_new_3.shape,rs_new_4.shape,rs_new_5.shape)\n",
        "\n",
        "\n",
        "## Back Translate ####\n",
        "\n",
        "# translator=google_translator()\n",
        "# available_langs = list(google_trans_new.LANGUAGES.keys()) \n",
        "\n",
        "# new_text=[]\n",
        "# ## data augmentation loop - class 1\n",
        "# for i in tqdm(np.random.randint(0,len(df_1),100)):\n",
        "#   trans_lang = random.choice(available_langs)\n",
        "#   text = df_1.iloc[i]['text']\n",
        "#   translations=translator.translate(text, lang_tgt=trans_lang)\n",
        "#   augmented_text=translator.translate(translations, lang_src=trans_lang, lang_tgt='en')\n",
        "#   new_text.append(augmented_text)\n",
        "# ## dataframe\n",
        "# bt_new_1=pd.DataFrame({'text':new_text,'Labels':1})\n",
        "\n",
        "# new_text=[]\n",
        "# ## data augmentation loop - class 2\n",
        "# for i in tqdm(np.random.randint(0,len(df_2),50)):\n",
        "#   trans_lang = random.choice(available_langs)\n",
        "#   text = df_2.iloc[i]['text']\n",
        "#   translations=translator.translate(text, lang_tgt=trans_lang)\n",
        "#   augmented_text=translator.translate(translations, lang_src=trans_lang, lang_tgt='en')\n",
        "#   new_text.append(augmented_text)\n",
        "# ## dataframe\n",
        "# bt_new_2=pd.DataFrame({'text':new_text,'Labels':2})\n",
        "\n",
        "# new_text=[]\n",
        "# ## data augmentation loop - class 3\n",
        "# for i in tqdm(np.random.randint(0,len(df_3),50)):\n",
        "#   trans_lang = random.choice(available_langs)\n",
        "#   text = df_3.iloc[i]['text']\n",
        "#   translations=translator.translate(text, lang_tgt=trans_lang)\n",
        "#   augmented_text=translator.translate(translations, lang_src=trans_lang, lang_tgt='en')\n",
        "#   new_text.append(augmented_text)\n",
        "# ## dataframe\n",
        "# bt_new_3=pd.DataFrame({'text':new_text,'Labels':3})\n",
        "\n",
        "# new_text=[]\n",
        "# ## data augmentation loop - class 4\n",
        "# for i in tqdm(np.random.randint(0,len(df_4),50)):\n",
        "#   trans_lang = random.choice(available_langs)\n",
        "#   text = df_4.iloc[i]['text']\n",
        "#   translations=translator.translate(text, lang_tgt=trans_lang)\n",
        "#   augmented_text=translator.translate(translations, lang_src=trans_lang, lang_tgt='en')\n",
        "#   new_text.append(augmented_text)\n",
        "# ## dataframe\n",
        "# bt_new_4=pd.DataFrame({'text':new_text,'Labels':4})\n",
        "\n",
        "# new_text=[]\n",
        "# ## data augmentation loop - class 5\n",
        "# for i in tqdm(np.random.randint(0,len(df_5),100)):\n",
        "#   trans_lang = random.choice(available_langs)\n",
        "#   text = df_5.iloc[i]['text']\n",
        "#   translations=translator.translate(text, lang_tgt=trans_lang)\n",
        "#   augmented_text=translator.translate(translations, lang_src=trans_lang, lang_tgt='en')\n",
        "#   new_text.append(augmented_text)\n",
        "# ## dataframe\n",
        "# bt_new_5=pd.DataFrame({'text':new_text,'Labels':5})\n",
        "\n",
        "\n",
        "# print('\\n',bt_new_1.shape,bt_new_2.shape,bt_new_3.shape, bt_new_4.shape, bt_new_5.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/928 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 156/928 [00:00<00:00, 1550.75it/s]\u001b[A\n",
            " 34%|███▍      | 314/928 [00:00<00:00, 1558.71it/s]\u001b[A\n",
            " 50%|█████     | 467/928 [00:00<00:00, 1547.20it/s]\u001b[A\n",
            " 65%|██████▌   | 606/928 [00:00<00:00, 1493.67it/s]\u001b[A\n",
            " 82%|████████▏ | 757/928 [00:00<00:00, 1495.31it/s]\u001b[A\n",
            "100%|██████████| 928/928 [00:00<00:00, 1471.76it/s]\n",
            "\n",
            "  0%|          | 0/443 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▍      | 153/443 [00:00<00:00, 1523.27it/s]\u001b[A\n",
            "100%|██████████| 443/443 [00:00<00:00, 1505.11it/s]\n",
            "\n",
            "  0%|          | 0/487 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|███▎      | 162/487 [00:00<00:00, 1619.54it/s]\u001b[A\n",
            " 63%|██████▎   | 306/487 [00:00<00:00, 1559.91it/s]\u001b[A\n",
            "100%|██████████| 487/487 [00:00<00:00, 1440.84it/s]\n",
            "\n",
            "  0%|          | 0/257 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 257/257 [00:00<00:00, 1514.21it/s]\n",
            "\n",
            "  0%|          | 0/436 [00:00<?, ?it/s]\u001b[A\n",
            " 36%|███▌      | 157/436 [00:00<00:00, 1565.80it/s]\u001b[A\n",
            "100%|██████████| 436/436 [00:00<00:00, 1496.16it/s]\n",
            "\n",
            "  0%|          | 0/928 [00:00<?, ?it/s]\u001b[A\n",
            " 16%|█▌        | 145/928 [00:00<00:00, 1446.27it/s]\u001b[A\n",
            " 31%|███       | 284/928 [00:00<00:00, 1427.76it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " (928, 2) (443, 2) (487, 2) (257, 2) (436, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 46%|████▋     | 431/928 [00:00<00:00, 1439.42it/s]\u001b[A\n",
            " 62%|██████▏   | 578/928 [00:00<00:00, 1447.69it/s]\u001b[A\n",
            " 76%|███████▋  | 709/928 [00:00<00:00, 1402.59it/s]\u001b[A\n",
            "100%|██████████| 928/928 [00:00<00:00, 1398.27it/s]\n",
            "\n",
            "  0%|          | 0/443 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|███▎      | 146/443 [00:00<00:00, 1451.62it/s]\u001b[A\n",
            " 63%|██████▎   | 280/443 [00:00<00:00, 1413.71it/s]\u001b[A\n",
            "100%|██████████| 443/443 [00:00<00:00, 1363.03it/s]\n",
            "\n",
            "  0%|          | 0/487 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 148/487 [00:00<00:00, 1475.19it/s]\u001b[A\n",
            " 59%|█████▊    | 285/487 [00:00<00:00, 1441.37it/s]\u001b[A\n",
            "100%|██████████| 487/487 [00:00<00:00, 1382.43it/s]\n",
            "\n",
            "  0%|          | 0/257 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 257/257 [00:00<00:00, 1439.91it/s]\n",
            "\n",
            "  0%|          | 0/436 [00:00<?, ?it/s]\u001b[A\n",
            " 36%|███▌      | 158/436 [00:00<00:00, 1571.60it/s]\u001b[A\n",
            " 68%|██████▊   | 297/436 [00:00<00:00, 1512.31it/s]\u001b[A\n",
            "100%|██████████| 436/436 [00:00<00:00, 1375.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " (928, 2) (443, 2) (487, 2) (257, 2) (436, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "9J9ciHIkmI8T",
        "outputId": "a214b294-b5bd-45c2-ba77-923664d98125"
      },
      "source": [
        "rs_new_1.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>( Lee ) unassuming his audience the same treat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Viewers will need all they luck the this muste...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machine terrorists to wonder if just some Hopk...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>. awful Thoroughly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bears is than worse . even imagined a ever mov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  Labels\n",
              "0  ( Lee ) unassuming his audience the same treat...       1\n",
              "1  Viewers will need all they luck the this muste...       1\n",
              "2  machine terrorists to wonder if just some Hopk...       1\n",
              "3                                 . awful Thoroughly       1\n",
              "4  Bears is than worse . even imagined a ever mov...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XphIA2lsoRya",
        "outputId": "cc388c67-5534-4d3f-a140-7ebe7ca66eb6"
      },
      "source": [
        "df_train_new=shuffle(df_train.append([rd_new_1,rd_new_2,rd_new_3,rd_new_4,rd_new_5,rs_new_1,rs_new_2,rs_new_3,rs_new_4,rs_new_5]).reset_index(drop=True)).reset_index(drop=True)\n",
        "print('\\n',df_train.head(),'\\n',df_train_new.head(),'\\n',df_train.shape,'\\n', df_train_new.shape )\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "   Labels                                               text\n",
            "0      4  The Rock is destined to be the 21st Century 's...\n",
            "1      5  The gorgeously elaborate continuation of `` Th...\n",
            "2      4  Singer/composer Bryan Adams contributes a slew...\n",
            "3      3  You 'd think by now America would have had eno...\n",
            "4      4               Yet the act is still charming here . \n",
            "    Labels                                               text\n",
            "0       3  From beginning to end , this overheated melodr...\n",
            "1       1  Master of Disguise runs for only 71 minutes an...\n",
            "2       4  Argento , at only 26 , brings a youthful , out...\n",
            "3       3  How I Killed My Father would be a rarity in Ho...\n",
            "4       5  Features what is surely the funniest and most ... \n",
            " (8544, 2) \n",
            " (13646, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta3FrhEjoR_f"
      },
      "source": [
        "df_train_new['Labels']=df_train_new['Labels'].apply(lambda x: '__label__'+ str(x))"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "sRYlsOsYpsW_",
        "outputId": "8d62485f-a488-44ac-f2da-c1235f1ff14c"
      },
      "source": [
        "df_train_new.sethead()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__label__3</td>\n",
              "      <td>From beginning to end , this overheated melodr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>Master of Disguise runs for only 71 minutes an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__label__4</td>\n",
              "      <td>Argento , at only 26 , brings a youthful , out...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__label__3</td>\n",
              "      <td>How I Killed My Father would be a rarity in Ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__label__5</td>\n",
              "      <td>Features what is surely the funniest and most ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Labels                                               text\n",
              "0  __label__3  From beginning to end , this overheated melodr...\n",
              "1  __label__1  Master of Disguise runs for only 71 minutes an...\n",
              "2  __label__4  Argento , at only 26 , brings a youthful , out...\n",
              "3  __label__3  How I Killed My Father would be a rarity in Ho...\n",
              "4  __label__5  Features what is surely the funniest and most ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYXutfjXqXW7"
      },
      "source": [
        "df_train_new.set_index('Labels').to_csv('/content/sst_train_augmented.txt', sep='\\t', header=None)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIIrzGUysMY4"
      },
      "source": [
        "# After data augmentation in train sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NOlFB3isMhr",
        "outputId": "a8d9d5fe-c0ef-4f95-de43-fc896231e71e"
      },
      "source": [
        "train, dev, test = 'sst_train_augmented.txt','sst_dev.txt','sst_test.txt'\n",
        "corpus_new = ClassificationCorpus(\n",
        "        '/content/',\n",
        "        train_file=train,\n",
        "        dev_file=dev,\n",
        "        test_file=test,\n",
        "    )"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 16:26:12,447 Reading data from /content\n",
            "2021-06-03 16:26:12,451 Train: /content/sst_train_augmented.txt\n",
            "2021-06-03 16:26:12,453 Dev: /content/sst_dev.txt\n",
            "2021-06-03 16:26:12,455 Test: /content/sst_test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8EZ3JTvdsMkE",
        "outputId": "0e90a4bf-f1ee-4347-8bf8-39d7416abf6a"
      },
      "source": [
        "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
        "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier_new = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer_new = ModelTrainer(classifier_new, corpus_new)\n",
        "# with train data augmentation\n",
        "trainer_new.train('./', max_epochs=90)\n",
        "plotter = Plotter()\n",
        "plotter.plot_training_curves('/content/loss.tsv')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 16:26:46,445 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/15856 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 53/15856 [00:00<00:30, 520.39it/s]\u001b[A\n",
            "  1%|▏         | 222/15856 [00:00<00:24, 646.53it/s]\u001b[A\n",
            "  2%|▏         | 299/15856 [00:00<00:22, 677.68it/s]\u001b[A\n",
            "  3%|▎         | 459/15856 [00:00<00:18, 818.29it/s]\u001b[A\n",
            "  4%|▍         | 633/15856 [00:00<00:15, 970.16it/s]\u001b[A\n",
            "  5%|▍         | 778/15856 [00:00<00:14, 1073.60it/s]\u001b[A\n",
            "  6%|▌         | 951/15856 [00:00<00:12, 1208.30it/s]\u001b[A\n",
            "  7%|▋         | 1140/15856 [00:00<00:10, 1343.05it/s]\u001b[A\n",
            "  8%|▊         | 1335/15856 [00:00<00:09, 1467.52it/s]\u001b[A\n",
            " 10%|▉         | 1519/15856 [00:01<00:09, 1558.15it/s]\u001b[A\n",
            " 11%|█         | 1697/15856 [00:01<00:08, 1611.67it/s]\u001b[A\n",
            " 12%|█▏        | 1898/15856 [00:01<00:08, 1712.58it/s]\u001b[A\n",
            " 13%|█▎        | 2078/15856 [00:01<00:08, 1711.86it/s]\u001b[A\n",
            " 14%|█▍        | 2255/15856 [00:01<00:07, 1715.10it/s]\u001b[A\n",
            " 15%|█▌        | 2431/15856 [00:01<00:07, 1702.36it/s]\u001b[A\n",
            " 16%|█▋        | 2604/15856 [00:01<00:08, 1654.54it/s]\u001b[A\n",
            " 18%|█▊        | 2794/15856 [00:01<00:07, 1719.57it/s]\u001b[A\n",
            " 19%|█▊        | 2969/15856 [00:01<00:07, 1694.77it/s]\u001b[A\n",
            " 20%|█▉        | 3141/15856 [00:01<00:07, 1682.42it/s]\u001b[A\n",
            " 21%|██        | 3329/15856 [00:02<00:07, 1728.14it/s]\u001b[A\n",
            " 22%|██▏       | 3505/15856 [00:02<00:07, 1736.81it/s]\u001b[A\n",
            " 23%|██▎       | 3680/15856 [00:02<00:07, 1733.62it/s]\u001b[A\n",
            " 24%|██▍       | 3854/15856 [00:02<00:06, 1728.92it/s]\u001b[A\n",
            " 25%|██▌       | 4028/15856 [00:02<00:07, 1676.02it/s]\u001b[A\n",
            " 27%|██▋       | 4210/15856 [00:02<00:06, 1706.99it/s]\u001b[A\n",
            " 28%|██▊       | 4382/15856 [00:02<00:06, 1689.20it/s]\u001b[A\n",
            " 29%|██▊       | 4552/15856 [00:02<00:06, 1676.97it/s]\u001b[A\n",
            " 30%|██▉       | 4721/15856 [00:02<00:06, 1656.35it/s]\u001b[A\n",
            " 31%|███       | 4887/15856 [00:03<00:06, 1622.84it/s]\u001b[A\n",
            " 32%|███▏      | 5073/15856 [00:03<00:06, 1678.13it/s]\u001b[A\n",
            " 33%|███▎      | 5247/15856 [00:03<00:06, 1691.07it/s]\u001b[A\n",
            " 34%|███▍      | 5417/15856 [00:03<00:06, 1684.58it/s]\u001b[A\n",
            " 35%|███▌      | 5586/15856 [00:03<00:06, 1684.33it/s]\u001b[A\n",
            " 36%|███▋      | 5755/15856 [00:03<00:06, 1680.13it/s]\u001b[A\n",
            " 37%|███▋      | 5928/15856 [00:03<00:05, 1693.16it/s]\u001b[A\n",
            " 38%|███▊      | 6101/15856 [00:03<00:05, 1683.38it/s]\u001b[A\n",
            " 40%|███▉      | 6280/15856 [00:03<00:05, 1691.63it/s]\u001b[A\n",
            " 41%|████      | 6479/15856 [00:03<00:05, 1738.71it/s]\u001b[A\n",
            " 42%|████▏     | 6656/15856 [00:04<00:05, 1743.51it/s]\u001b[A\n",
            " 43%|████▎     | 6831/15856 [00:04<00:05, 1741.15it/s]\u001b[A\n",
            " 44%|████▍     | 7006/15856 [00:04<00:05, 1740.93it/s]\u001b[A\n",
            " 45%|████▌     | 7191/15856 [00:04<00:04, 1755.33it/s]\u001b[A\n",
            " 46%|████▋     | 7367/15856 [00:04<00:04, 1740.88it/s]\u001b[A\n",
            " 48%|████▊     | 7542/15856 [00:04<00:04, 1734.41it/s]\u001b[A\n",
            " 49%|████▊     | 7716/15856 [00:04<00:04, 1699.83it/s]\u001b[A\n",
            " 50%|████▉     | 7890/15856 [00:04<00:04, 1705.22it/s]\u001b[A\n",
            " 51%|█████     | 8069/15856 [00:04<00:04, 1711.79it/s]\u001b[A\n",
            " 52%|█████▏    | 8241/15856 [00:04<00:04, 1711.89it/s]\u001b[A\n",
            " 53%|█████▎    | 8417/15856 [00:05<00:04, 1723.22it/s]\u001b[A\n",
            " 54%|█████▍    | 8590/15856 [00:05<00:04, 1715.17it/s]\u001b[A\n",
            " 55%|█████▌    | 8762/15856 [00:05<00:04, 1702.59it/s]\u001b[A\n",
            " 56%|█████▋    | 8943/15856 [00:05<00:04, 1724.21it/s]\u001b[A\n",
            " 58%|█████▊    | 9120/15856 [00:05<00:03, 1722.71it/s]\u001b[A\n",
            " 59%|█████▊    | 9304/15856 [00:05<00:03, 1746.04it/s]\u001b[A\n",
            " 60%|█████▉    | 9507/15856 [00:05<00:03, 1815.67it/s]\u001b[A\n",
            " 61%|██████    | 9690/15856 [00:05<00:03, 1819.02it/s]\u001b[A\n",
            " 62%|██████▏   | 9873/15856 [00:05<00:03, 1801.39it/s]\u001b[A\n",
            " 63%|██████▎   | 10054/15856 [00:05<00:03, 1755.42it/s]\u001b[A\n",
            " 65%|██████▍   | 10236/15856 [00:06<00:03, 1766.26it/s]\u001b[A\n",
            " 66%|██████▌   | 10435/15856 [00:06<00:02, 1816.77it/s]\u001b[A\n",
            " 67%|██████▋   | 10618/15856 [00:06<00:02, 1815.61it/s]\u001b[A\n",
            " 68%|██████▊   | 10813/15856 [00:06<00:02, 1853.91it/s]\u001b[A\n",
            " 69%|██████▉   | 11007/15856 [00:06<00:02, 1871.76it/s]\u001b[A\n",
            " 71%|███████   | 11195/15856 [00:06<00:02, 1871.73it/s]\u001b[A\n",
            " 72%|███████▏  | 11383/15856 [00:06<00:02, 1854.93it/s]\u001b[A\n",
            " 73%|███████▎  | 11571/15856 [00:06<00:02, 1831.31it/s]\u001b[A\n",
            " 74%|███████▍  | 11766/15856 [00:06<00:02, 1862.89it/s]\u001b[A\n",
            " 75%|███████▌  | 11962/15856 [00:06<00:02, 1887.28it/s]\u001b[A\n",
            " 77%|███████▋  | 12152/15856 [00:07<00:01, 1863.49it/s]\u001b[A\n",
            " 78%|███████▊  | 12339/15856 [00:07<00:01, 1805.67it/s]\u001b[A\n",
            " 79%|███████▉  | 12521/15856 [00:07<00:01, 1793.92it/s]\u001b[A\n",
            " 80%|████████  | 12701/15856 [00:07<00:01, 1742.24it/s]\u001b[A\n",
            " 81%|████████▏ | 12885/15856 [00:07<00:01, 1763.68it/s]\u001b[A\n",
            " 82%|████████▏ | 13064/15856 [00:07<00:01, 1752.43it/s]\u001b[A\n",
            " 84%|████████▎ | 13254/15856 [00:07<00:01, 1762.03it/s]\u001b[A\n",
            " 85%|████████▍ | 13441/15856 [00:07<00:01, 1792.70it/s]\u001b[A\n",
            " 86%|████████▌ | 13621/15856 [00:07<00:01, 1792.35it/s]\u001b[A\n",
            " 87%|████████▋ | 13801/15856 [00:08<00:01, 1705.57it/s]\u001b[A\n",
            " 88%|████████▊ | 13973/15856 [00:08<00:01, 1706.10it/s]\u001b[A\n",
            " 89%|████████▉ | 14145/15856 [00:08<00:01, 1696.08it/s]\u001b[A\n",
            " 90%|█████████ | 14316/15856 [00:08<00:00, 1673.06it/s]\u001b[A\n",
            " 91%|█████████▏| 14505/15856 [00:08<00:00, 1731.53it/s]\u001b[A\n",
            " 93%|█████████▎| 14679/15856 [00:08<00:00, 1727.39it/s]\u001b[A\n",
            " 94%|█████████▍| 14867/15856 [00:08<00:00, 1769.42it/s]\u001b[A\n",
            " 95%|█████████▍| 15045/15856 [00:08<00:00, 1737.18it/s]\u001b[A\n",
            " 96%|█████████▌| 15220/15856 [00:08<00:00, 1731.77it/s]\u001b[A\n",
            " 97%|█████████▋| 15394/15856 [00:08<00:00, 1705.77it/s]\u001b[A\n",
            " 98%|█████████▊| 15565/15856 [00:09<00:00, 1694.98it/s]\u001b[A\n",
            "100%|██████████| 15856/15856 [00:09<00:00, 1697.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 16:26:56,091 [b'3', b'1', b'4', b'5', b'2']\n",
            "2021-06-03 16:26:56,100 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:26:56,101 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-06-03 16:26:56,103 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:26:56,106 Corpus: \"Corpus: 13646 train + 1101 dev + 2210 test sentences\"\n",
            "2021-06-03 16:26:56,108 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:26:56,110 Parameters:\n",
            "2021-06-03 16:26:56,113  - learning_rate: \"0.1\"\n",
            "2021-06-03 16:26:56,114  - mini_batch_size: \"32\"\n",
            "2021-06-03 16:26:56,117  - patience: \"3\"\n",
            "2021-06-03 16:26:56,118  - anneal_factor: \"0.5\"\n",
            "2021-06-03 16:26:56,120  - max_epochs: \"90\"\n",
            "2021-06-03 16:26:56,124  - shuffle: \"True\"\n",
            "2021-06-03 16:26:56,126  - train_with_dev: \"False\"\n",
            "2021-06-03 16:26:56,127  - batch_growth_annealing: \"False\"\n",
            "2021-06-03 16:26:56,130 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 16:26:56,133 Model training base path: \".\"\n",
            "2021-06-03 16:26:56,136 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:26:56,142 Device: cuda:0\n",
            "2021-06-03 16:26:56,146 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:26:56,148 Embeddings storage mode: cpu\n",
            "2021-06-03 16:26:56,154 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:27:04,775 epoch 1 - iter 42/427 - loss 1.62218262 - samples/sec: 164.13 - lr: 0.100000\n",
            "2021-06-03 16:27:12,850 epoch 1 - iter 84/427 - loss 1.61524338 - samples/sec: 187.70 - lr: 0.100000\n",
            "2021-06-03 16:27:20,340 epoch 1 - iter 126/427 - loss 1.61150726 - samples/sec: 198.96 - lr: 0.100000\n",
            "2021-06-03 16:27:27,950 epoch 1 - iter 168/427 - loss 1.60776693 - samples/sec: 195.50 - lr: 0.100000\n",
            "2021-06-03 16:27:34,811 epoch 1 - iter 210/427 - loss 1.60213575 - samples/sec: 199.38 - lr: 0.100000\n",
            "2021-06-03 16:27:42,372 epoch 1 - iter 252/427 - loss 1.59861775 - samples/sec: 196.83 - lr: 0.100000\n",
            "2021-06-03 16:27:49,830 epoch 1 - iter 294/427 - loss 1.59678342 - samples/sec: 200.36 - lr: 0.100000\n",
            "2021-06-03 16:27:57,281 epoch 1 - iter 336/427 - loss 1.59309392 - samples/sec: 199.81 - lr: 0.100000\n",
            "2021-06-03 16:28:04,654 epoch 1 - iter 378/427 - loss 1.59134528 - samples/sec: 185.42 - lr: 0.100000\n",
            "2021-06-03 16:28:11,531 epoch 1 - iter 420/427 - loss 1.58869999 - samples/sec: 199.09 - lr: 0.100000\n",
            "2021-06-03 16:28:12,735 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:28:12,737 EPOCH 1 done: loss 1.5878 - lr 0.1000000\n",
            "2021-06-03 16:28:20,085 DEV : loss 1.5981301069259644 - score 0.2561\n",
            "2021-06-03 16:28:20,865 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:28:24,290 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:28:32,521 epoch 2 - iter 42/427 - loss 1.53494094 - samples/sec: 173.94 - lr: 0.100000\n",
            "2021-06-03 16:28:40,226 epoch 2 - iter 84/427 - loss 1.53888920 - samples/sec: 193.38 - lr: 0.100000\n",
            "2021-06-03 16:28:47,093 epoch 2 - iter 126/427 - loss 1.54064516 - samples/sec: 199.35 - lr: 0.100000\n",
            "2021-06-03 16:28:54,617 epoch 2 - iter 168/427 - loss 1.54324054 - samples/sec: 198.30 - lr: 0.100000\n",
            "2021-06-03 16:29:02,294 epoch 2 - iter 210/427 - loss 1.54176884 - samples/sec: 177.75 - lr: 0.100000\n",
            "2021-06-03 16:29:09,699 epoch 2 - iter 252/427 - loss 1.54113441 - samples/sec: 184.28 - lr: 0.100000\n",
            "2021-06-03 16:29:17,381 epoch 2 - iter 294/427 - loss 1.53793384 - samples/sec: 193.99 - lr: 0.100000\n",
            "2021-06-03 16:29:24,982 epoch 2 - iter 336/427 - loss 1.53877374 - samples/sec: 179.62 - lr: 0.100000\n",
            "2021-06-03 16:29:31,982 epoch 2 - iter 378/427 - loss 1.53827056 - samples/sec: 195.28 - lr: 0.100000\n",
            "2021-06-03 16:29:39,439 epoch 2 - iter 420/427 - loss 1.53722023 - samples/sec: 183.13 - lr: 0.100000\n",
            "2021-06-03 16:29:40,617 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:29:40,619 EPOCH 2 done: loss 1.5367 - lr 0.1000000\n",
            "2021-06-03 16:29:48,126 DEV : loss 1.5190943479537964 - score 0.3224\n",
            "2021-06-03 16:29:48,895 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:29:52,015 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:30:00,188 epoch 3 - iter 42/427 - loss 1.51442586 - samples/sec: 192.82 - lr: 0.100000\n",
            "2021-06-03 16:30:07,101 epoch 3 - iter 84/427 - loss 1.52008221 - samples/sec: 198.82 - lr: 0.100000\n",
            "2021-06-03 16:30:14,630 epoch 3 - iter 126/427 - loss 1.52073851 - samples/sec: 182.19 - lr: 0.100000\n",
            "2021-06-03 16:30:22,284 epoch 3 - iter 168/427 - loss 1.51460217 - samples/sec: 194.92 - lr: 0.100000\n",
            "2021-06-03 16:30:29,965 epoch 3 - iter 210/427 - loss 1.51779999 - samples/sec: 194.35 - lr: 0.100000\n",
            "2021-06-03 16:30:37,021 epoch 3 - iter 252/427 - loss 1.51695585 - samples/sec: 194.80 - lr: 0.100000\n",
            "2021-06-03 16:30:44,559 epoch 3 - iter 294/427 - loss 1.51723637 - samples/sec: 198.45 - lr: 0.100000\n",
            "2021-06-03 16:30:51,997 epoch 3 - iter 336/427 - loss 1.51410640 - samples/sec: 200.71 - lr: 0.100000\n",
            "2021-06-03 16:30:58,789 epoch 3 - iter 378/427 - loss 1.51308565 - samples/sec: 202.08 - lr: 0.100000\n",
            "2021-06-03 16:31:06,245 epoch 3 - iter 420/427 - loss 1.51240113 - samples/sec: 200.10 - lr: 0.100000\n",
            "2021-06-03 16:31:07,501 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:31:07,503 EPOCH 3 done: loss 1.5135 - lr 0.1000000\n",
            "2021-06-03 16:31:14,873 DEV : loss 1.684680461883545 - score 0.2589\n",
            "2021-06-03 16:31:15,626 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 16:31:15,629 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:31:23,775 epoch 4 - iter 42/427 - loss 1.49038151 - samples/sec: 195.09 - lr: 0.100000\n",
            "2021-06-03 16:31:31,385 epoch 4 - iter 84/427 - loss 1.49468226 - samples/sec: 179.58 - lr: 0.100000\n",
            "2021-06-03 16:31:38,246 epoch 4 - iter 126/427 - loss 1.49210210 - samples/sec: 199.33 - lr: 0.100000\n",
            "2021-06-03 16:31:45,931 epoch 4 - iter 168/427 - loss 1.48930195 - samples/sec: 194.26 - lr: 0.100000\n",
            "2021-06-03 16:31:53,714 epoch 4 - iter 210/427 - loss 1.48702804 - samples/sec: 191.56 - lr: 0.100000\n",
            "2021-06-03 16:32:01,481 epoch 4 - iter 252/427 - loss 1.49427631 - samples/sec: 192.07 - lr: 0.100000\n",
            "2021-06-03 16:32:09,280 epoch 4 - iter 294/427 - loss 1.49241821 - samples/sec: 192.54 - lr: 0.100000\n",
            "2021-06-03 16:32:16,198 epoch 4 - iter 336/427 - loss 1.49133893 - samples/sec: 198.10 - lr: 0.100000\n",
            "2021-06-03 16:32:23,891 epoch 4 - iter 378/427 - loss 1.48764650 - samples/sec: 195.00 - lr: 0.100000\n",
            "2021-06-03 16:32:31,332 epoch 4 - iter 420/427 - loss 1.48714491 - samples/sec: 201.06 - lr: 0.100000\n",
            "2021-06-03 16:32:32,589 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:32:32,590 EPOCH 4 done: loss 1.4864 - lr 0.1000000\n",
            "2021-06-03 16:32:40,107 DEV : loss 1.4898282289505005 - score 0.2934\n",
            "2021-06-03 16:32:40,869 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 16:32:40,871 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:32:49,197 epoch 5 - iter 42/427 - loss 1.46431219 - samples/sec: 191.20 - lr: 0.100000\n",
            "2021-06-03 16:32:56,071 epoch 5 - iter 84/427 - loss 1.45955742 - samples/sec: 199.36 - lr: 0.100000\n",
            "2021-06-03 16:33:03,802 epoch 5 - iter 126/427 - loss 1.46912134 - samples/sec: 193.05 - lr: 0.100000\n",
            "2021-06-03 16:33:11,443 epoch 5 - iter 168/427 - loss 1.46195675 - samples/sec: 196.62 - lr: 0.100000\n",
            "2021-06-03 16:33:18,963 epoch 5 - iter 210/427 - loss 1.45969386 - samples/sec: 197.41 - lr: 0.100000\n",
            "2021-06-03 16:33:26,616 epoch 5 - iter 252/427 - loss 1.45875731 - samples/sec: 195.61 - lr: 0.100000\n",
            "2021-06-03 16:33:33,414 epoch 5 - iter 294/427 - loss 1.45855809 - samples/sec: 201.64 - lr: 0.100000\n",
            "2021-06-03 16:33:41,003 epoch 5 - iter 336/427 - loss 1.45682229 - samples/sec: 180.09 - lr: 0.100000\n",
            "2021-06-03 16:33:48,625 epoch 5 - iter 378/427 - loss 1.45578403 - samples/sec: 196.56 - lr: 0.100000\n",
            "2021-06-03 16:33:55,886 epoch 5 - iter 420/427 - loss 1.45365520 - samples/sec: 205.37 - lr: 0.100000\n",
            "2021-06-03 16:33:57,168 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:33:57,170 EPOCH 5 done: loss 1.4543 - lr 0.1000000\n",
            "2021-06-03 16:34:04,870 DEV : loss 1.6685502529144287 - score 0.2352\n",
            "2021-06-03 16:34:05,646 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 16:34:05,648 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:34:13,373 epoch 6 - iter 42/427 - loss 1.44116026 - samples/sec: 186.06 - lr: 0.100000\n",
            "2021-06-03 16:34:21,217 epoch 6 - iter 84/427 - loss 1.44784419 - samples/sec: 192.88 - lr: 0.100000\n",
            "2021-06-03 16:34:28,879 epoch 6 - iter 126/427 - loss 1.43985698 - samples/sec: 196.13 - lr: 0.100000\n",
            "2021-06-03 16:34:36,566 epoch 6 - iter 168/427 - loss 1.44303207 - samples/sec: 178.00 - lr: 0.100000\n",
            "2021-06-03 16:34:44,332 epoch 6 - iter 210/427 - loss 1.44288221 - samples/sec: 175.96 - lr: 0.100000\n",
            "2021-06-03 16:34:51,290 epoch 6 - iter 252/427 - loss 1.43825412 - samples/sec: 196.56 - lr: 0.100000\n",
            "2021-06-03 16:34:58,847 epoch 6 - iter 294/427 - loss 1.43567850 - samples/sec: 197.81 - lr: 0.100000\n",
            "2021-06-03 16:35:06,515 epoch 6 - iter 336/427 - loss 1.43298476 - samples/sec: 195.66 - lr: 0.100000\n",
            "2021-06-03 16:35:14,046 epoch 6 - iter 378/427 - loss 1.43178992 - samples/sec: 198.94 - lr: 0.100000\n",
            "2021-06-03 16:35:21,554 epoch 6 - iter 420/427 - loss 1.43096354 - samples/sec: 199.04 - lr: 0.100000\n",
            "2021-06-03 16:35:22,789 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:35:22,791 EPOCH 6 done: loss 1.4305 - lr 0.1000000\n",
            "2021-06-03 16:35:29,625 DEV : loss 1.400009036064148 - score 0.3606\n",
            "2021-06-03 16:35:30,406 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:35:33,656 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:35:42,052 epoch 7 - iter 42/427 - loss 1.42290587 - samples/sec: 169.89 - lr: 0.100000\n",
            "2021-06-03 16:35:49,850 epoch 7 - iter 84/427 - loss 1.41611704 - samples/sec: 191.56 - lr: 0.100000\n",
            "2021-06-03 16:35:57,663 epoch 7 - iter 126/427 - loss 1.40899862 - samples/sec: 191.79 - lr: 0.100000\n",
            "2021-06-03 16:36:04,602 epoch 7 - iter 168/427 - loss 1.40898446 - samples/sec: 197.35 - lr: 0.100000\n",
            "2021-06-03 16:36:12,715 epoch 7 - iter 210/427 - loss 1.40848704 - samples/sec: 192.76 - lr: 0.100000\n",
            "2021-06-03 16:36:21,100 epoch 7 - iter 252/427 - loss 1.40466138 - samples/sec: 197.98 - lr: 0.100000\n",
            "2021-06-03 16:36:28,666 epoch 7 - iter 294/427 - loss 1.40359982 - samples/sec: 197.66 - lr: 0.100000\n",
            "2021-06-03 16:36:35,677 epoch 7 - iter 336/427 - loss 1.40311932 - samples/sec: 195.42 - lr: 0.100000\n",
            "2021-06-03 16:36:43,452 epoch 7 - iter 378/427 - loss 1.40335825 - samples/sec: 193.18 - lr: 0.100000\n",
            "2021-06-03 16:36:51,060 epoch 7 - iter 420/427 - loss 1.40072141 - samples/sec: 179.44 - lr: 0.100000\n",
            "2021-06-03 16:36:52,330 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:36:52,335 EPOCH 7 done: loss 1.4012 - lr 0.1000000\n",
            "2021-06-03 16:36:59,941 DEV : loss 1.4190655946731567 - score 0.3433\n",
            "2021-06-03 16:37:00,720 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 16:37:00,722 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:37:09,194 epoch 8 - iter 42/427 - loss 1.37205367 - samples/sec: 168.39 - lr: 0.100000\n",
            "2021-06-03 16:37:16,380 epoch 8 - iter 84/427 - loss 1.38256267 - samples/sec: 190.65 - lr: 0.100000\n",
            "2021-06-03 16:37:24,014 epoch 8 - iter 126/427 - loss 1.38772094 - samples/sec: 196.73 - lr: 0.100000\n",
            "2021-06-03 16:37:31,883 epoch 8 - iter 168/427 - loss 1.38666732 - samples/sec: 190.41 - lr: 0.100000\n",
            "2021-06-03 16:37:39,720 epoch 8 - iter 210/427 - loss 1.38913217 - samples/sec: 174.59 - lr: 0.100000\n",
            "2021-06-03 16:37:47,403 epoch 8 - iter 252/427 - loss 1.38743383 - samples/sec: 195.83 - lr: 0.100000\n",
            "2021-06-03 16:37:54,532 epoch 8 - iter 294/427 - loss 1.38506141 - samples/sec: 192.41 - lr: 0.100000\n",
            "2021-06-03 16:38:02,135 epoch 8 - iter 336/427 - loss 1.38468020 - samples/sec: 198.65 - lr: 0.100000\n",
            "2021-06-03 16:38:10,134 epoch 8 - iter 378/427 - loss 1.38292038 - samples/sec: 187.34 - lr: 0.100000\n",
            "2021-06-03 16:38:17,963 epoch 8 - iter 420/427 - loss 1.38406793 - samples/sec: 190.48 - lr: 0.100000\n",
            "2021-06-03 16:38:19,231 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:38:19,232 EPOCH 8 done: loss 1.3836 - lr 0.1000000\n",
            "2021-06-03 16:38:26,978 DEV : loss 1.3300065994262695 - score 0.4078\n",
            "2021-06-03 16:38:27,755 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:38:31,061 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:38:39,631 epoch 9 - iter 42/427 - loss 1.39832113 - samples/sec: 184.31 - lr: 0.100000\n",
            "2021-06-03 16:38:46,640 epoch 9 - iter 84/427 - loss 1.39285138 - samples/sec: 195.34 - lr: 0.100000\n",
            "2021-06-03 16:38:54,282 epoch 9 - iter 126/427 - loss 1.38239217 - samples/sec: 178.92 - lr: 0.100000\n",
            "2021-06-03 16:39:02,186 epoch 9 - iter 168/427 - loss 1.38402487 - samples/sec: 172.65 - lr: 0.100000\n",
            "2021-06-03 16:39:10,155 epoch 9 - iter 210/427 - loss 1.38047429 - samples/sec: 171.31 - lr: 0.100000\n",
            "2021-06-03 16:39:18,099 epoch 9 - iter 252/427 - loss 1.37840244 - samples/sec: 188.30 - lr: 0.100000\n",
            "2021-06-03 16:39:25,007 epoch 9 - iter 294/427 - loss 1.37678861 - samples/sec: 198.14 - lr: 0.100000\n",
            "2021-06-03 16:39:32,654 epoch 9 - iter 336/427 - loss 1.37573195 - samples/sec: 178.91 - lr: 0.100000\n",
            "2021-06-03 16:39:40,430 epoch 9 - iter 378/427 - loss 1.37266110 - samples/sec: 192.61 - lr: 0.100000\n",
            "2021-06-03 16:39:48,258 epoch 9 - iter 420/427 - loss 1.36729509 - samples/sec: 190.79 - lr: 0.100000\n",
            "2021-06-03 16:39:49,499 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:39:49,501 EPOCH 9 done: loss 1.3654 - lr 0.1000000\n",
            "2021-06-03 16:39:57,282 DEV : loss 1.3063477277755737 - score 0.3987\n",
            "2021-06-03 16:39:58,057 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 16:39:58,060 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:40:06,558 epoch 10 - iter 42/427 - loss 1.33933957 - samples/sec: 187.94 - lr: 0.100000\n",
            "2021-06-03 16:40:13,804 epoch 10 - iter 84/427 - loss 1.35273921 - samples/sec: 188.81 - lr: 0.100000\n",
            "2021-06-03 16:40:21,563 epoch 10 - iter 126/427 - loss 1.35265152 - samples/sec: 176.25 - lr: 0.100000\n",
            "2021-06-03 16:40:29,112 epoch 10 - iter 168/427 - loss 1.35253762 - samples/sec: 180.95 - lr: 0.100000\n",
            "2021-06-03 16:40:36,889 epoch 10 - iter 210/427 - loss 1.35551307 - samples/sec: 175.55 - lr: 0.100000\n",
            "2021-06-03 16:40:44,809 epoch 10 - iter 252/427 - loss 1.35262808 - samples/sec: 172.33 - lr: 0.100000\n",
            "2021-06-03 16:40:52,649 epoch 10 - iter 294/427 - loss 1.35306932 - samples/sec: 190.33 - lr: 0.100000\n",
            "2021-06-03 16:40:59,825 epoch 10 - iter 336/427 - loss 1.35367657 - samples/sec: 190.55 - lr: 0.100000\n",
            "2021-06-03 16:41:07,698 epoch 10 - iter 378/427 - loss 1.35352684 - samples/sec: 191.07 - lr: 0.100000\n",
            "2021-06-03 16:41:15,722 epoch 10 - iter 420/427 - loss 1.35301379 - samples/sec: 188.39 - lr: 0.100000\n",
            "2021-06-03 16:41:16,997 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:41:16,999 EPOCH 10 done: loss 1.3524 - lr 0.1000000\n",
            "2021-06-03 16:41:24,931 DEV : loss 1.2928447723388672 - score 0.3924\n",
            "2021-06-03 16:41:25,719 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 16:41:25,722 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:41:34,451 epoch 11 - iter 42/427 - loss 1.32653471 - samples/sec: 183.02 - lr: 0.100000\n",
            "2021-06-03 16:41:41,873 epoch 11 - iter 84/427 - loss 1.32508395 - samples/sec: 184.76 - lr: 0.100000\n",
            "2021-06-03 16:41:49,844 epoch 11 - iter 126/427 - loss 1.33740994 - samples/sec: 171.66 - lr: 0.100000\n",
            "2021-06-03 16:41:57,689 epoch 11 - iter 168/427 - loss 1.33791086 - samples/sec: 190.84 - lr: 0.100000\n",
            "2021-06-03 16:42:05,461 epoch 11 - iter 210/427 - loss 1.34414983 - samples/sec: 192.85 - lr: 0.100000\n",
            "2021-06-03 16:42:12,617 epoch 11 - iter 252/427 - loss 1.34517441 - samples/sec: 191.70 - lr: 0.100000\n",
            "2021-06-03 16:42:20,543 epoch 11 - iter 294/427 - loss 1.34352369 - samples/sec: 172.75 - lr: 0.100000\n",
            "2021-06-03 16:42:28,507 epoch 11 - iter 336/427 - loss 1.34145640 - samples/sec: 188.50 - lr: 0.100000\n",
            "2021-06-03 16:42:36,248 epoch 11 - iter 378/427 - loss 1.34086979 - samples/sec: 176.74 - lr: 0.100000\n",
            "2021-06-03 16:42:43,994 epoch 11 - iter 420/427 - loss 1.34203578 - samples/sec: 192.54 - lr: 0.100000\n",
            "2021-06-03 16:42:45,268 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:42:45,269 EPOCH 11 done: loss 1.3415 - lr 0.1000000\n",
            "2021-06-03 16:42:52,999 DEV : loss 1.3023560047149658 - score 0.4205\n",
            "2021-06-03 16:42:53,771 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:42:57,022 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:43:04,964 epoch 12 - iter 42/427 - loss 1.34714444 - samples/sec: 180.46 - lr: 0.100000\n",
            "2021-06-03 16:43:13,107 epoch 12 - iter 84/427 - loss 1.33833358 - samples/sec: 186.72 - lr: 0.100000\n",
            "2021-06-03 16:43:20,943 epoch 12 - iter 126/427 - loss 1.34074259 - samples/sec: 192.04 - lr: 0.100000\n",
            "2021-06-03 16:43:28,860 epoch 12 - iter 168/427 - loss 1.34070750 - samples/sec: 188.76 - lr: 0.100000\n",
            "2021-06-03 16:43:35,941 epoch 12 - iter 210/427 - loss 1.33891118 - samples/sec: 193.66 - lr: 0.100000\n",
            "2021-06-03 16:43:43,846 epoch 12 - iter 252/427 - loss 1.33664119 - samples/sec: 189.26 - lr: 0.100000\n",
            "2021-06-03 16:43:51,594 epoch 12 - iter 294/427 - loss 1.33493473 - samples/sec: 193.48 - lr: 0.100000\n",
            "2021-06-03 16:43:58,582 epoch 12 - iter 336/427 - loss 1.34033484 - samples/sec: 196.44 - lr: 0.100000\n",
            "2021-06-03 16:44:06,346 epoch 12 - iter 378/427 - loss 1.34075249 - samples/sec: 193.29 - lr: 0.100000\n",
            "2021-06-03 16:44:14,070 epoch 12 - iter 420/427 - loss 1.34199593 - samples/sec: 193.26 - lr: 0.100000\n",
            "2021-06-03 16:44:15,373 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:44:15,375 EPOCH 12 done: loss 1.3409 - lr 0.1000000\n",
            "2021-06-03 16:44:23,111 DEV : loss 1.3012323379516602 - score 0.4214\n",
            "2021-06-03 16:44:23,898 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:44:27,157 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:44:35,769 epoch 13 - iter 42/427 - loss 1.31823078 - samples/sec: 165.64 - lr: 0.100000\n",
            "2021-06-03 16:44:42,966 epoch 13 - iter 84/427 - loss 1.31261781 - samples/sec: 190.66 - lr: 0.100000\n",
            "2021-06-03 16:44:50,910 epoch 13 - iter 126/427 - loss 1.31052585 - samples/sec: 172.18 - lr: 0.100000\n",
            "2021-06-03 16:44:58,729 epoch 13 - iter 168/427 - loss 1.31236935 - samples/sec: 191.15 - lr: 0.100000\n",
            "2021-06-03 16:45:05,974 epoch 13 - iter 210/427 - loss 1.31193333 - samples/sec: 189.69 - lr: 0.100000\n",
            "2021-06-03 16:45:13,722 epoch 13 - iter 252/427 - loss 1.31206388 - samples/sec: 193.13 - lr: 0.100000\n",
            "2021-06-03 16:45:21,725 epoch 13 - iter 294/427 - loss 1.31504626 - samples/sec: 186.76 - lr: 0.100000\n",
            "2021-06-03 16:45:29,687 epoch 13 - iter 336/427 - loss 1.31629680 - samples/sec: 188.86 - lr: 0.100000\n",
            "2021-06-03 16:45:36,827 epoch 13 - iter 378/427 - loss 1.31650302 - samples/sec: 191.91 - lr: 0.100000\n",
            "2021-06-03 16:45:44,766 epoch 13 - iter 420/427 - loss 1.32102090 - samples/sec: 189.15 - lr: 0.100000\n",
            "2021-06-03 16:45:46,036 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:45:46,038 EPOCH 13 done: loss 1.3203 - lr 0.1000000\n",
            "2021-06-03 16:45:54,003 DEV : loss 1.2991889715194702 - score 0.3896\n",
            "2021-06-03 16:45:54,777 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 16:45:54,780 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:46:03,603 epoch 14 - iter 42/427 - loss 1.31214259 - samples/sec: 179.66 - lr: 0.100000\n",
            "2021-06-03 16:46:11,475 epoch 14 - iter 84/427 - loss 1.31231313 - samples/sec: 191.21 - lr: 0.100000\n",
            "2021-06-03 16:46:18,630 epoch 14 - iter 126/427 - loss 1.32651937 - samples/sec: 192.22 - lr: 0.100000\n",
            "2021-06-03 16:46:26,457 epoch 14 - iter 168/427 - loss 1.31993891 - samples/sec: 191.84 - lr: 0.100000\n",
            "2021-06-03 16:46:34,459 epoch 14 - iter 210/427 - loss 1.31637911 - samples/sec: 171.27 - lr: 0.100000\n",
            "2021-06-03 16:46:42,617 epoch 14 - iter 252/427 - loss 1.32044995 - samples/sec: 185.76 - lr: 0.100000\n",
            "2021-06-03 16:46:50,052 epoch 14 - iter 294/427 - loss 1.31946246 - samples/sec: 184.75 - lr: 0.100000\n",
            "2021-06-03 16:46:57,934 epoch 14 - iter 336/427 - loss 1.31861626 - samples/sec: 173.38 - lr: 0.100000\n",
            "2021-06-03 16:47:05,970 epoch 14 - iter 378/427 - loss 1.32180525 - samples/sec: 169.99 - lr: 0.100000\n",
            "2021-06-03 16:47:14,179 epoch 14 - iter 420/427 - loss 1.32095119 - samples/sec: 166.96 - lr: 0.100000\n",
            "2021-06-03 16:47:15,425 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:47:15,426 EPOCH 14 done: loss 1.3214 - lr 0.1000000\n",
            "2021-06-03 16:47:22,581 DEV : loss 1.2734938859939575 - score 0.4233\n",
            "2021-06-03 16:47:23,392 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:47:26,767 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:47:35,487 epoch 15 - iter 42/427 - loss 1.30610081 - samples/sec: 183.33 - lr: 0.100000\n",
            "2021-06-03 16:47:43,440 epoch 15 - iter 84/427 - loss 1.30277640 - samples/sec: 187.72 - lr: 0.100000\n",
            "2021-06-03 16:47:51,211 epoch 15 - iter 126/427 - loss 1.31107306 - samples/sec: 192.30 - lr: 0.100000\n",
            "2021-06-03 16:47:59,179 epoch 15 - iter 168/427 - loss 1.30201187 - samples/sec: 188.78 - lr: 0.100000\n",
            "2021-06-03 16:48:06,232 epoch 15 - iter 210/427 - loss 1.30775731 - samples/sec: 193.73 - lr: 0.100000\n",
            "2021-06-03 16:48:14,190 epoch 15 - iter 252/427 - loss 1.31100853 - samples/sec: 171.73 - lr: 0.100000\n",
            "2021-06-03 16:48:22,161 epoch 15 - iter 294/427 - loss 1.30914406 - samples/sec: 187.33 - lr: 0.100000\n",
            "2021-06-03 16:48:29,882 epoch 15 - iter 336/427 - loss 1.31053631 - samples/sec: 193.95 - lr: 0.100000\n",
            "2021-06-03 16:48:38,133 epoch 15 - iter 378/427 - loss 1.30712822 - samples/sec: 189.78 - lr: 0.100000\n",
            "2021-06-03 16:48:46,239 epoch 15 - iter 420/427 - loss 1.30650895 - samples/sec: 184.93 - lr: 0.100000\n",
            "2021-06-03 16:48:47,573 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:48:47,575 EPOCH 15 done: loss 1.3058 - lr 0.1000000\n",
            "2021-06-03 16:48:55,532 DEV : loss 1.3847318887710571 - score 0.3315\n",
            "2021-06-03 16:48:56,349 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 16:48:56,351 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:49:05,280 epoch 16 - iter 42/427 - loss 1.34931382 - samples/sec: 160.37 - lr: 0.100000\n",
            "2021-06-03 16:49:13,292 epoch 16 - iter 84/427 - loss 1.33406116 - samples/sec: 187.82 - lr: 0.100000\n",
            "2021-06-03 16:49:20,422 epoch 16 - iter 126/427 - loss 1.33581834 - samples/sec: 192.20 - lr: 0.100000\n",
            "2021-06-03 16:49:28,525 epoch 16 - iter 168/427 - loss 1.32980311 - samples/sec: 184.52 - lr: 0.100000\n",
            "2021-06-03 16:49:36,543 epoch 16 - iter 210/427 - loss 1.32520391 - samples/sec: 187.86 - lr: 0.100000\n",
            "2021-06-03 16:49:44,544 epoch 16 - iter 252/427 - loss 1.32509166 - samples/sec: 171.03 - lr: 0.100000\n",
            "2021-06-03 16:49:52,270 epoch 16 - iter 294/427 - loss 1.31709173 - samples/sec: 177.17 - lr: 0.100000\n",
            "2021-06-03 16:49:59,498 epoch 16 - iter 336/427 - loss 1.31467723 - samples/sec: 189.74 - lr: 0.100000\n",
            "2021-06-03 16:50:07,463 epoch 16 - iter 378/427 - loss 1.31039338 - samples/sec: 187.84 - lr: 0.100000\n",
            "2021-06-03 16:50:15,560 epoch 16 - iter 420/427 - loss 1.30930195 - samples/sec: 185.13 - lr: 0.100000\n",
            "2021-06-03 16:50:16,823 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:50:16,824 EPOCH 16 done: loss 1.3098 - lr 0.1000000\n",
            "2021-06-03 16:50:24,714 DEV : loss 1.3031716346740723 - score 0.4069\n",
            "2021-06-03 16:50:25,505 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 16:50:25,507 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:50:33,477 epoch 17 - iter 42/427 - loss 1.27907467 - samples/sec: 180.91 - lr: 0.100000\n",
            "2021-06-03 16:50:41,620 epoch 17 - iter 84/427 - loss 1.29372887 - samples/sec: 168.50 - lr: 0.100000\n",
            "2021-06-03 16:50:49,682 epoch 17 - iter 126/427 - loss 1.28627059 - samples/sec: 170.19 - lr: 0.100000\n",
            "2021-06-03 16:50:56,922 epoch 17 - iter 168/427 - loss 1.29324454 - samples/sec: 190.01 - lr: 0.100000\n",
            "2021-06-03 16:51:04,881 epoch 17 - iter 210/427 - loss 1.28740327 - samples/sec: 188.77 - lr: 0.100000\n",
            "2021-06-03 16:51:12,798 epoch 17 - iter 252/427 - loss 1.28899906 - samples/sec: 190.10 - lr: 0.100000\n",
            "2021-06-03 16:51:20,145 epoch 17 - iter 294/427 - loss 1.28522397 - samples/sec: 187.38 - lr: 0.100000\n",
            "2021-06-03 16:51:28,070 epoch 17 - iter 336/427 - loss 1.28849147 - samples/sec: 172.78 - lr: 0.100000\n",
            "2021-06-03 16:51:35,476 epoch 17 - iter 378/427 - loss 1.29084860 - samples/sec: 186.10 - lr: 0.100000\n",
            "2021-06-03 16:51:43,480 epoch 17 - iter 420/427 - loss 1.28826675 - samples/sec: 187.99 - lr: 0.100000\n",
            "2021-06-03 16:51:44,746 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:51:44,748 EPOCH 17 done: loss 1.2881 - lr 0.1000000\n",
            "2021-06-03 16:51:52,708 DEV : loss 1.3312829732894897 - score 0.3933\n",
            "2021-06-03 16:51:53,522 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 16:51:53,525 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:52:02,339 epoch 18 - iter 42/427 - loss 1.30535281 - samples/sec: 181.79 - lr: 0.100000\n",
            "2021-06-03 16:52:09,566 epoch 18 - iter 84/427 - loss 1.30505378 - samples/sec: 190.42 - lr: 0.100000\n",
            "2021-06-03 16:52:17,666 epoch 18 - iter 126/427 - loss 1.29910588 - samples/sec: 185.66 - lr: 0.100000\n",
            "2021-06-03 16:52:25,583 epoch 18 - iter 168/427 - loss 1.30078049 - samples/sec: 189.69 - lr: 0.100000\n",
            "2021-06-03 16:52:32,895 epoch 18 - iter 210/427 - loss 1.29752223 - samples/sec: 187.43 - lr: 0.100000\n",
            "2021-06-03 16:52:41,034 epoch 18 - iter 252/427 - loss 1.29941026 - samples/sec: 184.80 - lr: 0.100000\n",
            "2021-06-03 16:52:49,105 epoch 18 - iter 294/427 - loss 1.29746628 - samples/sec: 185.39 - lr: 0.100000\n",
            "2021-06-03 16:52:56,931 epoch 18 - iter 336/427 - loss 1.29482691 - samples/sec: 191.82 - lr: 0.100000\n",
            "2021-06-03 16:53:04,942 epoch 18 - iter 378/427 - loss 1.29401996 - samples/sec: 170.93 - lr: 0.100000\n",
            "2021-06-03 16:53:12,357 epoch 18 - iter 420/427 - loss 1.29403814 - samples/sec: 184.89 - lr: 0.100000\n",
            "2021-06-03 16:53:13,631 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:53:13,633 EPOCH 18 done: loss 1.2945 - lr 0.1000000\n",
            "2021-06-03 16:53:21,627 DEV : loss 1.3374038934707642 - score 0.3887\n",
            "Epoch    18: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2021-06-03 16:53:22,459 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 16:53:22,463 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:53:31,581 epoch 19 - iter 42/427 - loss 1.26216288 - samples/sec: 175.02 - lr: 0.050000\n",
            "2021-06-03 16:53:39,697 epoch 19 - iter 84/427 - loss 1.26173162 - samples/sec: 168.35 - lr: 0.050000\n",
            "2021-06-03 16:53:47,759 epoch 19 - iter 126/427 - loss 1.26018528 - samples/sec: 185.89 - lr: 0.050000\n",
            "2021-06-03 16:53:54,953 epoch 19 - iter 168/427 - loss 1.25819670 - samples/sec: 190.16 - lr: 0.050000\n",
            "2021-06-03 16:54:03,145 epoch 19 - iter 210/427 - loss 1.25551303 - samples/sec: 184.41 - lr: 0.050000\n",
            "2021-06-03 16:54:11,157 epoch 19 - iter 252/427 - loss 1.25036955 - samples/sec: 170.85 - lr: 0.050000\n",
            "2021-06-03 16:54:19,300 epoch 19 - iter 294/427 - loss 1.25003206 - samples/sec: 167.82 - lr: 0.050000\n",
            "2021-06-03 16:54:27,158 epoch 19 - iter 336/427 - loss 1.25184807 - samples/sec: 190.06 - lr: 0.050000\n",
            "2021-06-03 16:54:34,346 epoch 19 - iter 378/427 - loss 1.25111063 - samples/sec: 190.58 - lr: 0.050000\n",
            "2021-06-03 16:54:42,268 epoch 19 - iter 420/427 - loss 1.25180128 - samples/sec: 172.37 - lr: 0.050000\n",
            "2021-06-03 16:54:43,516 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:54:43,518 EPOCH 19 done: loss 1.2523 - lr 0.0500000\n",
            "2021-06-03 16:54:51,355 DEV : loss 1.3235251903533936 - score 0.3833\n",
            "2021-06-03 16:54:52,153 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 16:54:52,156 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:55:00,814 epoch 20 - iter 42/427 - loss 1.26245822 - samples/sec: 183.06 - lr: 0.050000\n",
            "2021-06-03 16:55:08,043 epoch 20 - iter 84/427 - loss 1.25654596 - samples/sec: 189.75 - lr: 0.050000\n",
            "2021-06-03 16:55:16,185 epoch 20 - iter 126/427 - loss 1.24160163 - samples/sec: 183.09 - lr: 0.050000\n",
            "2021-06-03 16:55:24,221 epoch 20 - iter 168/427 - loss 1.24092009 - samples/sec: 186.49 - lr: 0.050000\n",
            "2021-06-03 16:55:32,131 epoch 20 - iter 210/427 - loss 1.24402594 - samples/sec: 189.65 - lr: 0.050000\n",
            "2021-06-03 16:55:40,128 epoch 20 - iter 252/427 - loss 1.24755612 - samples/sec: 187.80 - lr: 0.050000\n",
            "2021-06-03 16:55:47,512 epoch 20 - iter 294/427 - loss 1.24526674 - samples/sec: 185.51 - lr: 0.050000\n",
            "2021-06-03 16:55:55,389 epoch 20 - iter 336/427 - loss 1.24544857 - samples/sec: 190.23 - lr: 0.050000\n",
            "2021-06-03 16:56:03,501 epoch 20 - iter 378/427 - loss 1.24775668 - samples/sec: 168.42 - lr: 0.050000\n",
            "2021-06-03 16:56:10,981 epoch 20 - iter 420/427 - loss 1.24941399 - samples/sec: 183.04 - lr: 0.050000\n",
            "2021-06-03 16:56:12,956 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:56:12,957 EPOCH 20 done: loss 1.2490 - lr 0.0500000\n",
            "2021-06-03 16:56:20,011 DEV : loss 1.256679892539978 - score 0.4323\n",
            "2021-06-03 16:56:20,809 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:56:24,157 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:56:32,890 epoch 21 - iter 42/427 - loss 1.26048995 - samples/sec: 163.04 - lr: 0.050000\n",
            "2021-06-03 16:56:40,779 epoch 21 - iter 84/427 - loss 1.25075990 - samples/sec: 190.25 - lr: 0.050000\n",
            "2021-06-03 16:56:48,768 epoch 21 - iter 126/427 - loss 1.24793337 - samples/sec: 189.04 - lr: 0.050000\n",
            "2021-06-03 16:56:56,068 epoch 21 - iter 168/427 - loss 1.24777484 - samples/sec: 187.66 - lr: 0.050000\n",
            "2021-06-03 16:57:04,089 epoch 21 - iter 210/427 - loss 1.24448102 - samples/sec: 170.43 - lr: 0.050000\n",
            "2021-06-03 16:57:12,004 epoch 21 - iter 252/427 - loss 1.24921590 - samples/sec: 189.40 - lr: 0.050000\n",
            "2021-06-03 16:57:20,088 epoch 21 - iter 294/427 - loss 1.24631642 - samples/sec: 169.12 - lr: 0.050000\n",
            "2021-06-03 16:57:28,183 epoch 21 - iter 336/427 - loss 1.24634293 - samples/sec: 184.63 - lr: 0.050000\n",
            "2021-06-03 16:57:35,314 epoch 21 - iter 378/427 - loss 1.24106024 - samples/sec: 192.21 - lr: 0.050000\n",
            "2021-06-03 16:57:43,274 epoch 21 - iter 420/427 - loss 1.23930720 - samples/sec: 189.22 - lr: 0.050000\n",
            "2021-06-03 16:57:44,517 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:57:44,519 EPOCH 21 done: loss 1.2379 - lr 0.0500000\n",
            "2021-06-03 16:57:52,394 DEV : loss 1.269914150238037 - score 0.436\n",
            "2021-06-03 16:57:53,201 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 16:57:56,580 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:58:05,322 epoch 22 - iter 42/427 - loss 1.26145838 - samples/sec: 163.92 - lr: 0.050000\n",
            "2021-06-03 16:58:12,648 epoch 22 - iter 84/427 - loss 1.24270480 - samples/sec: 187.07 - lr: 0.050000\n",
            "2021-06-03 16:58:20,513 epoch 22 - iter 126/427 - loss 1.23797706 - samples/sec: 190.73 - lr: 0.050000\n",
            "2021-06-03 16:58:28,323 epoch 22 - iter 168/427 - loss 1.23314873 - samples/sec: 191.28 - lr: 0.050000\n",
            "2021-06-03 16:58:35,499 epoch 22 - iter 210/427 - loss 1.23001547 - samples/sec: 190.62 - lr: 0.050000\n",
            "2021-06-03 16:58:43,385 epoch 22 - iter 252/427 - loss 1.22287906 - samples/sec: 190.43 - lr: 0.050000\n",
            "2021-06-03 16:58:51,310 epoch 22 - iter 294/427 - loss 1.22459477 - samples/sec: 188.02 - lr: 0.050000\n",
            "2021-06-03 16:58:59,305 epoch 22 - iter 336/427 - loss 1.22686504 - samples/sec: 188.92 - lr: 0.050000\n",
            "2021-06-03 16:59:06,807 epoch 22 - iter 378/427 - loss 1.22964077 - samples/sec: 182.87 - lr: 0.050000\n",
            "2021-06-03 16:59:14,795 epoch 22 - iter 420/427 - loss 1.22985148 - samples/sec: 188.08 - lr: 0.050000\n",
            "2021-06-03 16:59:16,054 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:59:16,055 EPOCH 22 done: loss 1.2283 - lr 0.0500000\n",
            "2021-06-03 16:59:23,872 DEV : loss 1.3454101085662842 - score 0.396\n",
            "2021-06-03 16:59:24,685 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 16:59:24,687 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 16:59:33,395 epoch 23 - iter 42/427 - loss 1.29631810 - samples/sec: 164.93 - lr: 0.050000\n",
            "2021-06-03 16:59:40,705 epoch 23 - iter 84/427 - loss 1.25618783 - samples/sec: 188.13 - lr: 0.050000\n",
            "2021-06-03 16:59:48,653 epoch 23 - iter 126/427 - loss 1.26644655 - samples/sec: 190.22 - lr: 0.050000\n",
            "2021-06-03 16:59:56,659 epoch 23 - iter 168/427 - loss 1.25832202 - samples/sec: 188.73 - lr: 0.050000\n",
            "2021-06-03 17:00:03,999 epoch 23 - iter 210/427 - loss 1.25023705 - samples/sec: 186.74 - lr: 0.050000\n",
            "2021-06-03 17:00:11,979 epoch 23 - iter 252/427 - loss 1.24937735 - samples/sec: 171.37 - lr: 0.050000\n",
            "2021-06-03 17:00:19,958 epoch 23 - iter 294/427 - loss 1.24977655 - samples/sec: 188.89 - lr: 0.050000\n",
            "2021-06-03 17:00:27,899 epoch 23 - iter 336/427 - loss 1.24618025 - samples/sec: 189.75 - lr: 0.050000\n",
            "2021-06-03 17:00:35,037 epoch 23 - iter 378/427 - loss 1.24439310 - samples/sec: 192.76 - lr: 0.050000\n",
            "2021-06-03 17:00:43,005 epoch 23 - iter 420/427 - loss 1.24183190 - samples/sec: 188.30 - lr: 0.050000\n",
            "2021-06-03 17:00:44,268 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:00:44,270 EPOCH 23 done: loss 1.2419 - lr 0.0500000\n",
            "2021-06-03 17:00:52,062 DEV : loss 1.296913981437683 - score 0.416\n",
            "2021-06-03 17:00:52,848 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:00:52,851 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:01:00,704 epoch 24 - iter 42/427 - loss 1.23608393 - samples/sec: 184.50 - lr: 0.050000\n",
            "2021-06-03 17:01:08,895 epoch 24 - iter 84/427 - loss 1.22218381 - samples/sec: 185.67 - lr: 0.050000\n",
            "2021-06-03 17:01:16,908 epoch 24 - iter 126/427 - loss 1.22456967 - samples/sec: 170.91 - lr: 0.050000\n",
            "2021-06-03 17:01:24,743 epoch 24 - iter 168/427 - loss 1.23649215 - samples/sec: 191.54 - lr: 0.050000\n",
            "2021-06-03 17:01:32,020 epoch 24 - iter 210/427 - loss 1.23806199 - samples/sec: 188.70 - lr: 0.050000\n",
            "2021-06-03 17:01:40,170 epoch 24 - iter 252/427 - loss 1.24051174 - samples/sec: 168.03 - lr: 0.050000\n",
            "2021-06-03 17:01:48,130 epoch 24 - iter 294/427 - loss 1.23893460 - samples/sec: 172.60 - lr: 0.050000\n",
            "2021-06-03 17:01:55,481 epoch 24 - iter 336/427 - loss 1.24437757 - samples/sec: 186.84 - lr: 0.050000\n",
            "2021-06-03 17:02:03,433 epoch 24 - iter 378/427 - loss 1.24337552 - samples/sec: 188.77 - lr: 0.050000\n",
            "2021-06-03 17:02:11,390 epoch 24 - iter 420/427 - loss 1.24177354 - samples/sec: 172.04 - lr: 0.050000\n",
            "2021-06-03 17:02:12,626 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:02:12,627 EPOCH 24 done: loss 1.2411 - lr 0.0500000\n",
            "2021-06-03 17:02:19,821 DEV : loss 1.2629246711730957 - score 0.436\n",
            "2021-06-03 17:02:20,648 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 17:02:24,090 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:02:32,895 epoch 25 - iter 42/427 - loss 1.23687154 - samples/sec: 163.23 - lr: 0.050000\n",
            "2021-06-03 17:02:40,910 epoch 25 - iter 84/427 - loss 1.22744954 - samples/sec: 186.78 - lr: 0.050000\n",
            "2021-06-03 17:02:49,071 epoch 25 - iter 126/427 - loss 1.21478293 - samples/sec: 184.46 - lr: 0.050000\n",
            "2021-06-03 17:02:57,103 epoch 25 - iter 168/427 - loss 1.21811549 - samples/sec: 170.53 - lr: 0.050000\n",
            "2021-06-03 17:03:04,342 epoch 25 - iter 210/427 - loss 1.21529322 - samples/sec: 189.41 - lr: 0.050000\n",
            "2021-06-03 17:03:12,116 epoch 25 - iter 252/427 - loss 1.21940750 - samples/sec: 175.59 - lr: 0.050000\n",
            "2021-06-03 17:03:19,996 epoch 25 - iter 294/427 - loss 1.21859946 - samples/sec: 190.80 - lr: 0.050000\n",
            "2021-06-03 17:03:28,068 epoch 25 - iter 336/427 - loss 1.22023272 - samples/sec: 169.25 - lr: 0.050000\n",
            "2021-06-03 17:03:35,418 epoch 25 - iter 378/427 - loss 1.21751704 - samples/sec: 187.16 - lr: 0.050000\n",
            "2021-06-03 17:03:44,185 epoch 25 - iter 420/427 - loss 1.21890585 - samples/sec: 182.04 - lr: 0.050000\n",
            "2021-06-03 17:03:45,534 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:03:45,536 EPOCH 25 done: loss 1.2190 - lr 0.0500000\n",
            "2021-06-03 17:03:53,574 DEV : loss 1.2755905389785767 - score 0.4278\n",
            "2021-06-03 17:03:54,375 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:03:54,378 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:04:03,214 epoch 26 - iter 42/427 - loss 1.20026781 - samples/sec: 161.74 - lr: 0.050000\n",
            "2021-06-03 17:04:11,338 epoch 26 - iter 84/427 - loss 1.20287775 - samples/sec: 185.11 - lr: 0.050000\n",
            "2021-06-03 17:04:18,584 epoch 26 - iter 126/427 - loss 1.20150256 - samples/sec: 189.67 - lr: 0.050000\n",
            "2021-06-03 17:04:26,401 epoch 26 - iter 168/427 - loss 1.20539764 - samples/sec: 175.36 - lr: 0.050000\n",
            "2021-06-03 17:04:34,420 epoch 26 - iter 210/427 - loss 1.20958449 - samples/sec: 170.90 - lr: 0.050000\n",
            "2021-06-03 17:04:42,319 epoch 26 - iter 252/427 - loss 1.21260875 - samples/sec: 189.65 - lr: 0.050000\n",
            "2021-06-03 17:04:49,358 epoch 26 - iter 294/427 - loss 1.21375509 - samples/sec: 194.35 - lr: 0.050000\n",
            "2021-06-03 17:04:57,096 epoch 26 - iter 336/427 - loss 1.21579028 - samples/sec: 193.10 - lr: 0.050000\n",
            "2021-06-03 17:05:05,305 epoch 26 - iter 378/427 - loss 1.21582030 - samples/sec: 182.14 - lr: 0.050000\n",
            "2021-06-03 17:05:13,505 epoch 26 - iter 420/427 - loss 1.21807345 - samples/sec: 183.91 - lr: 0.050000\n",
            "2021-06-03 17:05:14,768 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:05:14,771 EPOCH 26 done: loss 1.2186 - lr 0.0500000\n",
            "2021-06-03 17:05:22,785 DEV : loss 1.2420064210891724 - score 0.446\n",
            "2021-06-03 17:05:23,575 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 17:05:26,945 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:05:35,119 epoch 27 - iter 42/427 - loss 1.20329941 - samples/sec: 176.65 - lr: 0.050000\n",
            "2021-06-03 17:05:43,237 epoch 27 - iter 84/427 - loss 1.20647979 - samples/sec: 169.23 - lr: 0.050000\n",
            "2021-06-03 17:05:51,126 epoch 27 - iter 126/427 - loss 1.21306870 - samples/sec: 189.84 - lr: 0.050000\n",
            "2021-06-03 17:05:59,266 epoch 27 - iter 168/427 - loss 1.21487523 - samples/sec: 185.45 - lr: 0.050000\n",
            "2021-06-03 17:06:07,377 epoch 27 - iter 210/427 - loss 1.21228344 - samples/sec: 184.95 - lr: 0.050000\n",
            "2021-06-03 17:06:14,694 epoch 27 - iter 252/427 - loss 1.21114088 - samples/sec: 187.78 - lr: 0.050000\n",
            "2021-06-03 17:06:22,806 epoch 27 - iter 294/427 - loss 1.21485765 - samples/sec: 169.08 - lr: 0.050000\n",
            "2021-06-03 17:06:30,756 epoch 27 - iter 336/427 - loss 1.21900041 - samples/sec: 189.36 - lr: 0.050000\n",
            "2021-06-03 17:06:38,700 epoch 27 - iter 378/427 - loss 1.21746494 - samples/sec: 172.78 - lr: 0.050000\n",
            "2021-06-03 17:06:46,000 epoch 27 - iter 420/427 - loss 1.21647567 - samples/sec: 187.84 - lr: 0.050000\n",
            "2021-06-03 17:06:47,908 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:06:47,911 EPOCH 27 done: loss 1.2153 - lr 0.0500000\n",
            "2021-06-03 17:06:55,050 DEV : loss 1.365166425704956 - score 0.3606\n",
            "2021-06-03 17:06:55,855 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:06:55,858 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:07:04,608 epoch 28 - iter 42/427 - loss 1.21482496 - samples/sec: 182.81 - lr: 0.050000\n",
            "2021-06-03 17:07:12,480 epoch 28 - iter 84/427 - loss 1.20443766 - samples/sec: 189.84 - lr: 0.050000\n",
            "2021-06-03 17:07:20,287 epoch 28 - iter 126/427 - loss 1.20895176 - samples/sec: 191.74 - lr: 0.050000\n",
            "2021-06-03 17:07:28,286 epoch 28 - iter 168/427 - loss 1.20230886 - samples/sec: 186.92 - lr: 0.050000\n",
            "2021-06-03 17:07:35,764 epoch 28 - iter 210/427 - loss 1.20158875 - samples/sec: 182.89 - lr: 0.050000\n",
            "2021-06-03 17:07:43,821 epoch 28 - iter 252/427 - loss 1.20296743 - samples/sec: 185.88 - lr: 0.050000\n",
            "2021-06-03 17:07:51,663 epoch 28 - iter 294/427 - loss 1.20515410 - samples/sec: 174.75 - lr: 0.050000\n",
            "2021-06-03 17:07:59,700 epoch 28 - iter 336/427 - loss 1.20776738 - samples/sec: 186.51 - lr: 0.050000\n",
            "2021-06-03 17:08:07,632 epoch 28 - iter 378/427 - loss 1.20770154 - samples/sec: 172.56 - lr: 0.050000\n",
            "2021-06-03 17:08:14,622 epoch 28 - iter 420/427 - loss 1.20765365 - samples/sec: 196.33 - lr: 0.050000\n",
            "2021-06-03 17:08:15,919 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:08:15,921 EPOCH 28 done: loss 1.2081 - lr 0.0500000\n",
            "2021-06-03 17:08:23,807 DEV : loss 1.2652570009231567 - score 0.4214\n",
            "2021-06-03 17:08:24,619 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:08:24,622 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:08:33,198 epoch 29 - iter 42/427 - loss 1.19671949 - samples/sec: 186.52 - lr: 0.050000\n",
            "2021-06-03 17:08:40,429 epoch 29 - iter 84/427 - loss 1.19668833 - samples/sec: 190.35 - lr: 0.050000\n",
            "2021-06-03 17:08:48,324 epoch 29 - iter 126/427 - loss 1.17526267 - samples/sec: 173.69 - lr: 0.050000\n",
            "2021-06-03 17:08:55,916 epoch 29 - iter 168/427 - loss 1.18916453 - samples/sec: 197.87 - lr: 0.050000\n",
            "2021-06-03 17:09:03,678 epoch 29 - iter 210/427 - loss 1.19229370 - samples/sec: 193.24 - lr: 0.050000\n",
            "2021-06-03 17:09:11,570 epoch 29 - iter 252/427 - loss 1.19642565 - samples/sec: 189.32 - lr: 0.050000\n",
            "2021-06-03 17:09:18,856 epoch 29 - iter 294/427 - loss 1.19953293 - samples/sec: 187.94 - lr: 0.050000\n",
            "2021-06-03 17:09:26,682 epoch 29 - iter 336/427 - loss 1.20071401 - samples/sec: 191.99 - lr: 0.050000\n",
            "2021-06-03 17:09:34,457 epoch 29 - iter 378/427 - loss 1.20291609 - samples/sec: 192.77 - lr: 0.050000\n",
            "2021-06-03 17:09:42,428 epoch 29 - iter 420/427 - loss 1.19957218 - samples/sec: 187.50 - lr: 0.050000\n",
            "2021-06-03 17:09:43,702 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:09:43,704 EPOCH 29 done: loss 1.2005 - lr 0.0500000\n",
            "2021-06-03 17:09:51,645 DEV : loss 1.28553307056427 - score 0.4514\n",
            "2021-06-03 17:09:52,424 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 17:09:55,702 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:10:03,512 epoch 30 - iter 42/427 - loss 1.20275749 - samples/sec: 184.04 - lr: 0.050000\n",
            "2021-06-03 17:10:11,357 epoch 30 - iter 84/427 - loss 1.18315031 - samples/sec: 192.79 - lr: 0.050000\n",
            "2021-06-03 17:10:19,025 epoch 30 - iter 126/427 - loss 1.19321691 - samples/sec: 195.22 - lr: 0.050000\n",
            "2021-06-03 17:10:26,713 epoch 30 - iter 168/427 - loss 1.19703302 - samples/sec: 195.42 - lr: 0.050000\n",
            "2021-06-03 17:10:34,563 epoch 30 - iter 210/427 - loss 1.20132624 - samples/sec: 190.03 - lr: 0.050000\n",
            "2021-06-03 17:10:41,649 epoch 30 - iter 252/427 - loss 1.20153141 - samples/sec: 193.43 - lr: 0.050000\n",
            "2021-06-03 17:10:49,249 epoch 30 - iter 294/427 - loss 1.20304793 - samples/sec: 197.65 - lr: 0.050000\n",
            "2021-06-03 17:10:57,064 epoch 30 - iter 336/427 - loss 1.20511100 - samples/sec: 175.06 - lr: 0.050000\n",
            "2021-06-03 17:11:04,687 epoch 30 - iter 378/427 - loss 1.20455171 - samples/sec: 196.16 - lr: 0.050000\n",
            "2021-06-03 17:11:12,725 epoch 30 - iter 420/427 - loss 1.20567148 - samples/sec: 185.97 - lr: 0.050000\n",
            "2021-06-03 17:11:14,032 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:11:14,033 EPOCH 30 done: loss 1.2053 - lr 0.0500000\n",
            "2021-06-03 17:11:21,886 DEV : loss 1.274630069732666 - score 0.4269\n",
            "2021-06-03 17:11:22,661 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:11:22,664 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:11:30,363 epoch 31 - iter 42/427 - loss 1.16160778 - samples/sec: 187.47 - lr: 0.050000\n",
            "2021-06-03 17:11:38,289 epoch 31 - iter 84/427 - loss 1.16789979 - samples/sec: 193.56 - lr: 0.050000\n",
            "2021-06-03 17:11:46,393 epoch 31 - iter 126/427 - loss 1.18689411 - samples/sec: 184.90 - lr: 0.050000\n",
            "2021-06-03 17:11:54,342 epoch 31 - iter 168/427 - loss 1.18263580 - samples/sec: 188.88 - lr: 0.050000\n",
            "2021-06-03 17:12:01,513 epoch 31 - iter 210/427 - loss 1.18517550 - samples/sec: 190.95 - lr: 0.050000\n",
            "2021-06-03 17:12:09,123 epoch 31 - iter 252/427 - loss 1.18624046 - samples/sec: 179.09 - lr: 0.050000\n",
            "2021-06-03 17:12:16,811 epoch 31 - iter 294/427 - loss 1.18900230 - samples/sec: 193.66 - lr: 0.050000\n",
            "2021-06-03 17:12:24,765 epoch 31 - iter 336/427 - loss 1.19157472 - samples/sec: 171.78 - lr: 0.050000\n",
            "2021-06-03 17:12:32,681 epoch 31 - iter 378/427 - loss 1.19149309 - samples/sec: 189.18 - lr: 0.050000\n",
            "2021-06-03 17:12:39,733 epoch 31 - iter 420/427 - loss 1.19313311 - samples/sec: 194.36 - lr: 0.050000\n",
            "2021-06-03 17:12:41,643 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:12:41,645 EPOCH 31 done: loss 1.1929 - lr 0.0500000\n",
            "2021-06-03 17:12:48,724 DEV : loss 1.2595386505126953 - score 0.4323\n",
            "2021-06-03 17:12:49,509 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:12:49,512 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:12:58,296 epoch 32 - iter 42/427 - loss 1.19056637 - samples/sec: 181.87 - lr: 0.050000\n",
            "2021-06-03 17:13:06,396 epoch 32 - iter 84/427 - loss 1.18554272 - samples/sec: 185.56 - lr: 0.050000\n",
            "2021-06-03 17:13:14,288 epoch 32 - iter 126/427 - loss 1.18904530 - samples/sec: 173.57 - lr: 0.050000\n",
            "2021-06-03 17:13:21,447 epoch 32 - iter 168/427 - loss 1.19281712 - samples/sec: 191.59 - lr: 0.050000\n",
            "2021-06-03 17:13:29,340 epoch 32 - iter 210/427 - loss 1.19595392 - samples/sec: 173.54 - lr: 0.050000\n",
            "2021-06-03 17:13:37,236 epoch 32 - iter 252/427 - loss 1.18896037 - samples/sec: 190.14 - lr: 0.050000\n",
            "2021-06-03 17:13:45,172 epoch 32 - iter 294/427 - loss 1.19285584 - samples/sec: 189.47 - lr: 0.050000\n",
            "2021-06-03 17:13:52,381 epoch 32 - iter 336/427 - loss 1.19409760 - samples/sec: 190.25 - lr: 0.050000\n",
            "2021-06-03 17:13:59,939 epoch 32 - iter 378/427 - loss 1.19526262 - samples/sec: 198.50 - lr: 0.050000\n",
            "2021-06-03 17:14:07,680 epoch 32 - iter 420/427 - loss 1.19457380 - samples/sec: 193.69 - lr: 0.050000\n",
            "2021-06-03 17:14:08,862 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:14:08,864 EPOCH 32 done: loss 1.1950 - lr 0.0500000\n",
            "2021-06-03 17:14:16,557 DEV : loss 1.2909940481185913 - score 0.4033\n",
            "2021-06-03 17:14:17,349 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:14:17,352 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:14:26,029 epoch 33 - iter 42/427 - loss 1.19144765 - samples/sec: 164.76 - lr: 0.050000\n",
            "2021-06-03 17:14:33,275 epoch 33 - iter 84/427 - loss 1.18955222 - samples/sec: 189.02 - lr: 0.050000\n",
            "2021-06-03 17:14:41,175 epoch 33 - iter 126/427 - loss 1.18279967 - samples/sec: 190.33 - lr: 0.050000\n",
            "2021-06-03 17:14:49,106 epoch 33 - iter 168/427 - loss 1.18320507 - samples/sec: 172.20 - lr: 0.050000\n",
            "2021-06-03 17:14:57,027 epoch 33 - iter 210/427 - loss 1.18790226 - samples/sec: 172.48 - lr: 0.050000\n",
            "2021-06-03 17:15:04,843 epoch 33 - iter 252/427 - loss 1.18623844 - samples/sec: 174.78 - lr: 0.050000\n",
            "2021-06-03 17:15:11,803 epoch 33 - iter 294/427 - loss 1.17780198 - samples/sec: 196.56 - lr: 0.050000\n",
            "2021-06-03 17:15:19,629 epoch 33 - iter 336/427 - loss 1.17608321 - samples/sec: 190.17 - lr: 0.050000\n",
            "2021-06-03 17:15:27,591 epoch 33 - iter 378/427 - loss 1.17898011 - samples/sec: 171.93 - lr: 0.050000\n",
            "2021-06-03 17:15:35,447 epoch 33 - iter 420/427 - loss 1.18092195 - samples/sec: 190.80 - lr: 0.050000\n",
            "2021-06-03 17:15:36,745 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:15:36,746 EPOCH 33 done: loss 1.1808 - lr 0.0500000\n",
            "2021-06-03 17:15:44,492 DEV : loss 1.245909333229065 - score 0.4478\n",
            "Epoch    33: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2021-06-03 17:15:45,281 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:15:45,283 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:15:53,236 epoch 34 - iter 42/427 - loss 1.12773992 - samples/sec: 181.50 - lr: 0.025000\n",
            "2021-06-03 17:16:00,972 epoch 34 - iter 84/427 - loss 1.15177339 - samples/sec: 177.05 - lr: 0.025000\n",
            "2021-06-03 17:16:08,722 epoch 34 - iter 126/427 - loss 1.15911952 - samples/sec: 193.23 - lr: 0.025000\n",
            "2021-06-03 17:16:16,309 epoch 34 - iter 168/427 - loss 1.15436869 - samples/sec: 180.58 - lr: 0.025000\n",
            "2021-06-03 17:16:23,449 epoch 34 - iter 210/427 - loss 1.16178450 - samples/sec: 192.09 - lr: 0.025000\n",
            "2021-06-03 17:16:31,033 epoch 34 - iter 252/427 - loss 1.15852963 - samples/sec: 197.48 - lr: 0.025000\n",
            "2021-06-03 17:16:38,852 epoch 34 - iter 294/427 - loss 1.15959452 - samples/sec: 192.74 - lr: 0.025000\n",
            "2021-06-03 17:16:46,740 epoch 34 - iter 336/427 - loss 1.15762681 - samples/sec: 189.65 - lr: 0.025000\n",
            "2021-06-03 17:16:53,841 epoch 34 - iter 378/427 - loss 1.15480343 - samples/sec: 193.58 - lr: 0.025000\n",
            "2021-06-03 17:17:01,608 epoch 34 - iter 420/427 - loss 1.15839003 - samples/sec: 193.29 - lr: 0.025000\n",
            "2021-06-03 17:17:02,855 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:17:02,857 EPOCH 34 done: loss 1.1582 - lr 0.0250000\n",
            "2021-06-03 17:17:10,401 DEV : loss 1.2757030725479126 - score 0.4178\n",
            "2021-06-03 17:17:11,156 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:17:11,158 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:17:19,600 epoch 35 - iter 42/427 - loss 1.17173643 - samples/sec: 188.39 - lr: 0.025000\n",
            "2021-06-03 17:17:27,518 epoch 35 - iter 84/427 - loss 1.16221787 - samples/sec: 172.64 - lr: 0.025000\n",
            "2021-06-03 17:17:34,564 epoch 35 - iter 126/427 - loss 1.15154141 - samples/sec: 194.38 - lr: 0.025000\n",
            "2021-06-03 17:17:42,367 epoch 35 - iter 168/427 - loss 1.16051679 - samples/sec: 190.59 - lr: 0.025000\n",
            "2021-06-03 17:17:50,049 epoch 35 - iter 210/427 - loss 1.15306117 - samples/sec: 177.80 - lr: 0.025000\n",
            "2021-06-03 17:17:57,764 epoch 35 - iter 252/427 - loss 1.14999897 - samples/sec: 176.92 - lr: 0.025000\n",
            "2021-06-03 17:18:05,286 epoch 35 - iter 294/427 - loss 1.15190944 - samples/sec: 198.57 - lr: 0.025000\n",
            "2021-06-03 17:18:12,328 epoch 35 - iter 336/427 - loss 1.15242772 - samples/sec: 194.54 - lr: 0.025000\n",
            "2021-06-03 17:18:20,031 epoch 35 - iter 378/427 - loss 1.15366357 - samples/sec: 194.04 - lr: 0.025000\n",
            "2021-06-03 17:18:27,829 epoch 35 - iter 420/427 - loss 1.15335606 - samples/sec: 175.38 - lr: 0.025000\n",
            "2021-06-03 17:18:29,069 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:18:29,072 EPOCH 35 done: loss 1.1537 - lr 0.0250000\n",
            "2021-06-03 17:18:36,757 DEV : loss 1.2584738731384277 - score 0.4432\n",
            "2021-06-03 17:18:37,543 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:18:37,546 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:18:45,854 epoch 36 - iter 42/427 - loss 1.13609416 - samples/sec: 191.88 - lr: 0.025000\n",
            "2021-06-03 17:18:52,985 epoch 36 - iter 84/427 - loss 1.13145772 - samples/sec: 192.56 - lr: 0.025000\n",
            "2021-06-03 17:19:00,622 epoch 36 - iter 126/427 - loss 1.13045041 - samples/sec: 179.41 - lr: 0.025000\n",
            "2021-06-03 17:19:08,134 epoch 36 - iter 168/427 - loss 1.13389042 - samples/sec: 182.18 - lr: 0.025000\n",
            "2021-06-03 17:19:15,081 epoch 36 - iter 210/427 - loss 1.13535455 - samples/sec: 197.88 - lr: 0.025000\n",
            "2021-06-03 17:19:22,786 epoch 36 - iter 252/427 - loss 1.14020978 - samples/sec: 194.68 - lr: 0.025000\n",
            "2021-06-03 17:19:30,420 epoch 36 - iter 294/427 - loss 1.14287479 - samples/sec: 194.73 - lr: 0.025000\n",
            "2021-06-03 17:19:38,022 epoch 36 - iter 336/427 - loss 1.14394390 - samples/sec: 196.88 - lr: 0.025000\n",
            "2021-06-03 17:19:45,193 epoch 36 - iter 378/427 - loss 1.14683433 - samples/sec: 191.68 - lr: 0.025000\n",
            "2021-06-03 17:19:52,953 epoch 36 - iter 420/427 - loss 1.14566632 - samples/sec: 193.49 - lr: 0.025000\n",
            "2021-06-03 17:19:54,210 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:19:54,211 EPOCH 36 done: loss 1.1452 - lr 0.0250000\n",
            "2021-06-03 17:20:01,883 DEV : loss 1.2684104442596436 - score 0.4269\n",
            "2021-06-03 17:20:02,657 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:20:02,660 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:20:11,063 epoch 37 - iter 42/427 - loss 1.15691200 - samples/sec: 189.59 - lr: 0.025000\n",
            "2021-06-03 17:20:18,760 epoch 37 - iter 84/427 - loss 1.14736251 - samples/sec: 177.77 - lr: 0.025000\n",
            "2021-06-03 17:20:26,457 epoch 37 - iter 126/427 - loss 1.15297416 - samples/sec: 177.70 - lr: 0.025000\n",
            "2021-06-03 17:20:33,395 epoch 37 - iter 168/427 - loss 1.14617329 - samples/sec: 197.71 - lr: 0.025000\n",
            "2021-06-03 17:20:41,109 epoch 37 - iter 210/427 - loss 1.14024302 - samples/sec: 193.50 - lr: 0.025000\n",
            "2021-06-03 17:20:48,724 epoch 37 - iter 252/427 - loss 1.14090217 - samples/sec: 197.41 - lr: 0.025000\n",
            "2021-06-03 17:20:55,648 epoch 37 - iter 294/427 - loss 1.14284646 - samples/sec: 198.33 - lr: 0.025000\n",
            "2021-06-03 17:21:03,277 epoch 37 - iter 336/427 - loss 1.14087255 - samples/sec: 196.04 - lr: 0.025000\n",
            "2021-06-03 17:21:10,955 epoch 37 - iter 378/427 - loss 1.14341028 - samples/sec: 178.25 - lr: 0.025000\n",
            "2021-06-03 17:21:18,554 epoch 37 - iter 420/427 - loss 1.14475333 - samples/sec: 179.91 - lr: 0.025000\n",
            "2021-06-03 17:21:19,818 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:21:19,819 EPOCH 37 done: loss 1.1440 - lr 0.0250000\n",
            "2021-06-03 17:21:27,355 DEV : loss 1.2852284908294678 - score 0.4069\n",
            "Epoch    37: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2021-06-03 17:21:28,116 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:21:28,120 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:21:35,843 epoch 38 - iter 42/427 - loss 1.11875140 - samples/sec: 186.81 - lr: 0.012500\n",
            "2021-06-03 17:21:43,580 epoch 38 - iter 84/427 - loss 1.10367529 - samples/sec: 195.60 - lr: 0.012500\n",
            "2021-06-03 17:21:51,273 epoch 38 - iter 126/427 - loss 1.11601632 - samples/sec: 195.37 - lr: 0.012500\n",
            "2021-06-03 17:21:58,240 epoch 38 - iter 168/427 - loss 1.11911210 - samples/sec: 197.17 - lr: 0.012500\n",
            "2021-06-03 17:22:05,988 epoch 38 - iter 210/427 - loss 1.12234505 - samples/sec: 193.58 - lr: 0.012500\n",
            "2021-06-03 17:22:13,627 epoch 38 - iter 252/427 - loss 1.12541839 - samples/sec: 179.49 - lr: 0.012500\n",
            "2021-06-03 17:22:21,397 epoch 38 - iter 294/427 - loss 1.13073744 - samples/sec: 192.47 - lr: 0.012500\n",
            "2021-06-03 17:22:28,391 epoch 38 - iter 336/427 - loss 1.13490828 - samples/sec: 196.06 - lr: 0.012500\n",
            "2021-06-03 17:22:36,096 epoch 38 - iter 378/427 - loss 1.13431818 - samples/sec: 194.48 - lr: 0.012500\n",
            "2021-06-03 17:22:43,696 epoch 38 - iter 420/427 - loss 1.13560001 - samples/sec: 179.77 - lr: 0.012500\n",
            "2021-06-03 17:22:44,846 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:22:44,848 EPOCH 38 done: loss 1.1356 - lr 0.0125000\n",
            "2021-06-03 17:22:52,506 DEV : loss 1.271376609802246 - score 0.4441\n",
            "2021-06-03 17:22:53,272 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:22:53,275 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:23:00,909 epoch 39 - iter 42/427 - loss 1.15061582 - samples/sec: 189.28 - lr: 0.012500\n",
            "2021-06-03 17:23:09,021 epoch 39 - iter 84/427 - loss 1.16131872 - samples/sec: 169.24 - lr: 0.012500\n",
            "2021-06-03 17:23:16,865 epoch 39 - iter 126/427 - loss 1.14916821 - samples/sec: 174.29 - lr: 0.012500\n",
            "2021-06-03 17:23:24,461 epoch 39 - iter 168/427 - loss 1.14194658 - samples/sec: 180.37 - lr: 0.012500\n",
            "2021-06-03 17:23:31,584 epoch 39 - iter 210/427 - loss 1.14435376 - samples/sec: 191.98 - lr: 0.012500\n",
            "2021-06-03 17:23:39,281 epoch 39 - iter 252/427 - loss 1.14453195 - samples/sec: 194.28 - lr: 0.012500\n",
            "2021-06-03 17:23:46,991 epoch 39 - iter 294/427 - loss 1.14543138 - samples/sec: 194.56 - lr: 0.012500\n",
            "2021-06-03 17:23:54,573 epoch 39 - iter 336/427 - loss 1.14126047 - samples/sec: 180.45 - lr: 0.012500\n",
            "2021-06-03 17:24:01,530 epoch 39 - iter 378/427 - loss 1.13717401 - samples/sec: 197.00 - lr: 0.012500\n",
            "2021-06-03 17:24:09,084 epoch 39 - iter 420/427 - loss 1.13815977 - samples/sec: 180.99 - lr: 0.012500\n",
            "2021-06-03 17:24:10,249 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:24:10,251 EPOCH 39 done: loss 1.1360 - lr 0.0125000\n",
            "2021-06-03 17:24:17,707 DEV : loss 1.2577221393585205 - score 0.4523\n",
            "2021-06-03 17:24:18,481 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-06-03 17:24:21,695 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:24:30,060 epoch 40 - iter 42/427 - loss 1.12987857 - samples/sec: 189.96 - lr: 0.012500\n",
            "2021-06-03 17:24:37,813 epoch 40 - iter 84/427 - loss 1.14510752 - samples/sec: 192.82 - lr: 0.012500\n",
            "2021-06-03 17:24:44,904 epoch 40 - iter 126/427 - loss 1.14686682 - samples/sec: 193.71 - lr: 0.012500\n",
            "2021-06-03 17:24:52,609 epoch 40 - iter 168/427 - loss 1.14647297 - samples/sec: 194.77 - lr: 0.012500\n",
            "2021-06-03 17:25:00,416 epoch 40 - iter 210/427 - loss 1.13910686 - samples/sec: 175.32 - lr: 0.012500\n",
            "2021-06-03 17:25:08,127 epoch 40 - iter 252/427 - loss 1.13963519 - samples/sec: 194.50 - lr: 0.012500\n",
            "2021-06-03 17:25:15,710 epoch 40 - iter 294/427 - loss 1.14064965 - samples/sec: 197.45 - lr: 0.012500\n",
            "2021-06-03 17:25:22,660 epoch 40 - iter 336/427 - loss 1.13820586 - samples/sec: 197.50 - lr: 0.012500\n",
            "2021-06-03 17:25:30,241 epoch 40 - iter 378/427 - loss 1.13359198 - samples/sec: 198.25 - lr: 0.012500\n",
            "2021-06-03 17:25:37,930 epoch 40 - iter 420/427 - loss 1.13340690 - samples/sec: 194.25 - lr: 0.012500\n",
            "2021-06-03 17:25:39,166 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:25:39,168 EPOCH 40 done: loss 1.1336 - lr 0.0125000\n",
            "2021-06-03 17:25:46,853 DEV : loss 1.2607829570770264 - score 0.4378\n",
            "2021-06-03 17:25:47,640 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:25:47,643 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:25:56,028 epoch 41 - iter 42/427 - loss 1.12059394 - samples/sec: 170.33 - lr: 0.012500\n",
            "2021-06-03 17:26:03,156 epoch 41 - iter 84/427 - loss 1.11679397 - samples/sec: 191.95 - lr: 0.012500\n",
            "2021-06-03 17:26:10,994 epoch 41 - iter 126/427 - loss 1.10920469 - samples/sec: 174.88 - lr: 0.012500\n",
            "2021-06-03 17:26:18,733 epoch 41 - iter 168/427 - loss 1.10934270 - samples/sec: 194.39 - lr: 0.012500\n",
            "2021-06-03 17:26:26,191 epoch 41 - iter 210/427 - loss 1.11290767 - samples/sec: 183.70 - lr: 0.012500\n",
            "2021-06-03 17:26:33,715 epoch 41 - iter 252/427 - loss 1.11351147 - samples/sec: 182.18 - lr: 0.012500\n",
            "2021-06-03 17:26:40,743 epoch 41 - iter 294/427 - loss 1.11647258 - samples/sec: 195.71 - lr: 0.012500\n",
            "2021-06-03 17:26:48,531 epoch 41 - iter 336/427 - loss 1.12042036 - samples/sec: 192.07 - lr: 0.012500\n",
            "2021-06-03 17:26:56,100 epoch 41 - iter 378/427 - loss 1.12213023 - samples/sec: 181.48 - lr: 0.012500\n",
            "2021-06-03 17:27:03,711 epoch 41 - iter 420/427 - loss 1.12031171 - samples/sec: 180.02 - lr: 0.012500\n",
            "2021-06-03 17:27:04,959 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:27:04,960 EPOCH 41 done: loss 1.1215 - lr 0.0125000\n",
            "2021-06-03 17:27:12,414 DEV : loss 1.2749828100204468 - score 0.4314\n",
            "2021-06-03 17:27:13,163 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:27:13,165 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:27:20,911 epoch 42 - iter 42/427 - loss 1.11778281 - samples/sec: 186.27 - lr: 0.012500\n",
            "2021-06-03 17:27:28,782 epoch 42 - iter 84/427 - loss 1.11893823 - samples/sec: 174.27 - lr: 0.012500\n",
            "2021-06-03 17:27:36,335 epoch 42 - iter 126/427 - loss 1.12708508 - samples/sec: 181.39 - lr: 0.012500\n",
            "2021-06-03 17:27:43,454 epoch 42 - iter 168/427 - loss 1.11542964 - samples/sec: 193.07 - lr: 0.012500\n",
            "2021-06-03 17:27:50,984 epoch 42 - iter 210/427 - loss 1.11270150 - samples/sec: 182.25 - lr: 0.012500\n",
            "2021-06-03 17:27:58,716 epoch 42 - iter 252/427 - loss 1.11923538 - samples/sec: 194.37 - lr: 0.012500\n",
            "2021-06-03 17:28:05,773 epoch 42 - iter 294/427 - loss 1.11950059 - samples/sec: 194.28 - lr: 0.012500\n",
            "2021-06-03 17:28:13,345 epoch 42 - iter 336/427 - loss 1.11865270 - samples/sec: 196.94 - lr: 0.012500\n",
            "2021-06-03 17:28:21,039 epoch 42 - iter 378/427 - loss 1.11968808 - samples/sec: 177.49 - lr: 0.012500\n",
            "2021-06-03 17:28:28,905 epoch 42 - iter 420/427 - loss 1.11639398 - samples/sec: 173.86 - lr: 0.012500\n",
            "2021-06-03 17:28:30,120 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:28:30,122 EPOCH 42 done: loss 1.1162 - lr 0.0125000\n",
            "2021-06-03 17:28:37,720 DEV : loss 1.2698760032653809 - score 0.4514\n",
            "2021-06-03 17:28:38,487 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:28:38,490 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:28:46,095 epoch 43 - iter 42/427 - loss 1.12040563 - samples/sec: 189.55 - lr: 0.012500\n",
            "2021-06-03 17:28:53,856 epoch 43 - iter 84/427 - loss 1.10204992 - samples/sec: 176.75 - lr: 0.012500\n",
            "2021-06-03 17:29:01,575 epoch 43 - iter 126/427 - loss 1.10824401 - samples/sec: 176.98 - lr: 0.012500\n",
            "2021-06-03 17:29:09,221 epoch 43 - iter 168/427 - loss 1.11084378 - samples/sec: 179.21 - lr: 0.012500\n",
            "2021-06-03 17:29:16,198 epoch 43 - iter 210/427 - loss 1.10879129 - samples/sec: 196.54 - lr: 0.012500\n",
            "2021-06-03 17:29:23,848 epoch 43 - iter 252/427 - loss 1.11212634 - samples/sec: 178.63 - lr: 0.012500\n",
            "2021-06-03 17:29:31,490 epoch 43 - iter 294/427 - loss 1.11297016 - samples/sec: 197.20 - lr: 0.012500\n",
            "2021-06-03 17:29:39,264 epoch 43 - iter 336/427 - loss 1.11419099 - samples/sec: 176.05 - lr: 0.012500\n",
            "2021-06-03 17:29:46,289 epoch 43 - iter 378/427 - loss 1.11690492 - samples/sec: 194.95 - lr: 0.012500\n",
            "2021-06-03 17:29:54,093 epoch 43 - iter 420/427 - loss 1.11927081 - samples/sec: 192.00 - lr: 0.012500\n",
            "2021-06-03 17:29:55,356 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:29:55,358 EPOCH 43 done: loss 1.1191 - lr 0.0125000\n",
            "2021-06-03 17:30:03,031 DEV : loss 1.2646034955978394 - score 0.4414\n",
            "Epoch    43: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2021-06-03 17:30:03,819 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:30:03,821 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:30:12,298 epoch 44 - iter 42/427 - loss 1.13246467 - samples/sec: 187.98 - lr: 0.006250\n",
            "2021-06-03 17:30:19,884 epoch 44 - iter 84/427 - loss 1.10816463 - samples/sec: 197.95 - lr: 0.006250\n",
            "2021-06-03 17:30:27,012 epoch 44 - iter 126/427 - loss 1.10317954 - samples/sec: 192.32 - lr: 0.006250\n",
            "2021-06-03 17:30:34,621 epoch 44 - iter 168/427 - loss 1.10739275 - samples/sec: 180.03 - lr: 0.006250\n",
            "2021-06-03 17:30:42,326 epoch 44 - iter 210/427 - loss 1.10685566 - samples/sec: 193.80 - lr: 0.006250\n",
            "2021-06-03 17:30:49,974 epoch 44 - iter 252/427 - loss 1.10474390 - samples/sec: 195.77 - lr: 0.006250\n",
            "2021-06-03 17:30:57,682 epoch 44 - iter 294/427 - loss 1.10521602 - samples/sec: 193.44 - lr: 0.006250\n",
            "2021-06-03 17:31:04,580 epoch 44 - iter 336/427 - loss 1.10629557 - samples/sec: 198.85 - lr: 0.006250\n",
            "2021-06-03 17:31:12,219 epoch 44 - iter 378/427 - loss 1.10487977 - samples/sec: 196.17 - lr: 0.006250\n",
            "2021-06-03 17:31:20,089 epoch 44 - iter 420/427 - loss 1.10742143 - samples/sec: 189.82 - lr: 0.006250\n",
            "2021-06-03 17:31:21,340 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:31:21,342 EPOCH 44 done: loss 1.1083 - lr 0.0062500\n",
            "2021-06-03 17:31:29,101 DEV : loss 1.2670809030532837 - score 0.4432\n",
            "2021-06-03 17:31:29,892 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:31:29,895 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:31:37,610 epoch 45 - iter 42/427 - loss 1.10142407 - samples/sec: 187.72 - lr: 0.006250\n",
            "2021-06-03 17:31:45,510 epoch 45 - iter 84/427 - loss 1.09627535 - samples/sec: 193.57 - lr: 0.006250\n",
            "2021-06-03 17:31:53,123 epoch 45 - iter 126/427 - loss 1.10150090 - samples/sec: 196.50 - lr: 0.006250\n",
            "2021-06-03 17:32:00,744 epoch 45 - iter 168/427 - loss 1.10487957 - samples/sec: 196.41 - lr: 0.006250\n",
            "2021-06-03 17:32:07,727 epoch 45 - iter 210/427 - loss 1.10224821 - samples/sec: 196.65 - lr: 0.006250\n",
            "2021-06-03 17:32:15,576 epoch 45 - iter 252/427 - loss 1.10627636 - samples/sec: 191.19 - lr: 0.006250\n",
            "2021-06-03 17:32:23,243 epoch 45 - iter 294/427 - loss 1.10519390 - samples/sec: 195.56 - lr: 0.006250\n",
            "2021-06-03 17:32:30,792 epoch 45 - iter 336/427 - loss 1.10380145 - samples/sec: 198.09 - lr: 0.006250\n",
            "2021-06-03 17:32:37,865 epoch 45 - iter 378/427 - loss 1.10793895 - samples/sec: 193.32 - lr: 0.006250\n",
            "2021-06-03 17:32:45,539 epoch 45 - iter 420/427 - loss 1.10963599 - samples/sec: 194.18 - lr: 0.006250\n",
            "2021-06-03 17:32:46,779 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:32:46,780 EPOCH 45 done: loss 1.1093 - lr 0.0062500\n",
            "2021-06-03 17:32:54,320 DEV : loss 1.2621467113494873 - score 0.4505\n",
            "2021-06-03 17:32:55,093 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:32:55,096 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:33:03,284 epoch 46 - iter 42/427 - loss 1.10715933 - samples/sec: 174.05 - lr: 0.006250\n",
            "2021-06-03 17:33:10,245 epoch 46 - iter 84/427 - loss 1.10622868 - samples/sec: 196.47 - lr: 0.006250\n",
            "2021-06-03 17:33:17,831 epoch 46 - iter 126/427 - loss 1.10671146 - samples/sec: 197.97 - lr: 0.006250\n",
            "2021-06-03 17:33:25,621 epoch 46 - iter 168/427 - loss 1.10648581 - samples/sec: 175.55 - lr: 0.006250\n",
            "2021-06-03 17:33:33,457 epoch 46 - iter 210/427 - loss 1.10410691 - samples/sec: 191.85 - lr: 0.006250\n",
            "2021-06-03 17:33:41,181 epoch 46 - iter 252/427 - loss 1.10901134 - samples/sec: 194.36 - lr: 0.006250\n",
            "2021-06-03 17:33:48,164 epoch 46 - iter 294/427 - loss 1.10820297 - samples/sec: 196.58 - lr: 0.006250\n",
            "2021-06-03 17:33:55,596 epoch 46 - iter 336/427 - loss 1.10713504 - samples/sec: 184.15 - lr: 0.006250\n",
            "2021-06-03 17:34:03,053 epoch 46 - iter 378/427 - loss 1.10755499 - samples/sec: 200.32 - lr: 0.006250\n",
            "2021-06-03 17:34:10,092 epoch 46 - iter 420/427 - loss 1.10587090 - samples/sec: 195.13 - lr: 0.006250\n",
            "2021-06-03 17:34:12,007 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:34:12,009 EPOCH 46 done: loss 1.1063 - lr 0.0062500\n",
            "2021-06-03 17:34:18,887 DEV : loss 1.2679917812347412 - score 0.4396\n",
            "2021-06-03 17:34:19,667 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:34:19,669 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:34:27,992 epoch 47 - iter 42/427 - loss 1.09234277 - samples/sec: 172.42 - lr: 0.006250\n",
            "2021-06-03 17:34:35,705 epoch 47 - iter 84/427 - loss 1.09294467 - samples/sec: 177.38 - lr: 0.006250\n",
            "2021-06-03 17:34:42,684 epoch 47 - iter 126/427 - loss 1.09436701 - samples/sec: 196.68 - lr: 0.006250\n",
            "2021-06-03 17:34:50,450 epoch 47 - iter 168/427 - loss 1.10345196 - samples/sec: 193.33 - lr: 0.006250\n",
            "2021-06-03 17:34:57,992 epoch 47 - iter 210/427 - loss 1.10407424 - samples/sec: 199.22 - lr: 0.006250\n",
            "2021-06-03 17:35:05,626 epoch 47 - iter 252/427 - loss 1.10395812 - samples/sec: 195.28 - lr: 0.006250\n",
            "2021-06-03 17:35:13,335 epoch 47 - iter 294/427 - loss 1.10078409 - samples/sec: 177.08 - lr: 0.006250\n",
            "2021-06-03 17:35:21,016 epoch 47 - iter 336/427 - loss 1.09780878 - samples/sec: 194.95 - lr: 0.006250\n",
            "2021-06-03 17:35:27,987 epoch 47 - iter 378/427 - loss 1.10405763 - samples/sec: 196.19 - lr: 0.006250\n",
            "2021-06-03 17:35:35,586 epoch 47 - iter 420/427 - loss 1.10222099 - samples/sec: 196.70 - lr: 0.006250\n",
            "2021-06-03 17:35:36,831 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:35:36,832 EPOCH 47 done: loss 1.1044 - lr 0.0062500\n",
            "2021-06-03 17:35:44,410 DEV : loss 1.273632526397705 - score 0.4332\n",
            "Epoch    47: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2021-06-03 17:35:45,166 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:35:45,169 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:35:53,649 epoch 48 - iter 42/427 - loss 1.09681175 - samples/sec: 187.91 - lr: 0.003125\n",
            "2021-06-03 17:36:01,259 epoch 48 - iter 84/427 - loss 1.09908312 - samples/sec: 180.05 - lr: 0.003125\n",
            "2021-06-03 17:36:08,843 epoch 48 - iter 126/427 - loss 1.09556434 - samples/sec: 197.07 - lr: 0.003125\n",
            "2021-06-03 17:36:15,899 epoch 48 - iter 168/427 - loss 1.10101859 - samples/sec: 193.35 - lr: 0.003125\n",
            "2021-06-03 17:36:23,537 epoch 48 - iter 210/427 - loss 1.09630253 - samples/sec: 195.77 - lr: 0.003125\n",
            "2021-06-03 17:36:31,430 epoch 48 - iter 252/427 - loss 1.09351706 - samples/sec: 188.44 - lr: 0.003125\n",
            "2021-06-03 17:36:38,965 epoch 48 - iter 294/427 - loss 1.10058817 - samples/sec: 199.09 - lr: 0.003125\n",
            "2021-06-03 17:36:46,093 epoch 48 - iter 336/427 - loss 1.10055899 - samples/sec: 191.90 - lr: 0.003125\n",
            "2021-06-03 17:36:53,720 epoch 48 - iter 378/427 - loss 1.09964256 - samples/sec: 196.63 - lr: 0.003125\n",
            "2021-06-03 17:37:01,403 epoch 48 - iter 420/427 - loss 1.09741762 - samples/sec: 194.60 - lr: 0.003125\n",
            "2021-06-03 17:37:02,586 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:37:02,588 EPOCH 48 done: loss 1.0982 - lr 0.0031250\n",
            "2021-06-03 17:37:10,052 DEV : loss 1.2706084251403809 - score 0.4387\n",
            "2021-06-03 17:37:10,814 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:37:10,816 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:37:19,138 epoch 49 - iter 42/427 - loss 1.12365551 - samples/sec: 172.22 - lr: 0.003125\n",
            "2021-06-03 17:37:26,243 epoch 49 - iter 84/427 - loss 1.09161692 - samples/sec: 192.87 - lr: 0.003125\n",
            "2021-06-03 17:37:33,928 epoch 49 - iter 126/427 - loss 1.10217328 - samples/sec: 194.08 - lr: 0.003125\n",
            "2021-06-03 17:37:41,442 epoch 49 - iter 168/427 - loss 1.10436824 - samples/sec: 199.67 - lr: 0.003125\n",
            "2021-06-03 17:37:49,097 epoch 49 - iter 210/427 - loss 1.10403019 - samples/sec: 178.61 - lr: 0.003125\n",
            "2021-06-03 17:37:56,829 epoch 49 - iter 252/427 - loss 1.10730525 - samples/sec: 176.64 - lr: 0.003125\n",
            "2021-06-03 17:38:03,663 epoch 49 - iter 294/427 - loss 1.10407667 - samples/sec: 200.00 - lr: 0.003125\n",
            "2021-06-03 17:38:11,496 epoch 49 - iter 336/427 - loss 1.10053504 - samples/sec: 190.79 - lr: 0.003125\n",
            "2021-06-03 17:38:19,093 epoch 49 - iter 378/427 - loss 1.10046847 - samples/sec: 196.58 - lr: 0.003125\n",
            "2021-06-03 17:38:26,694 epoch 49 - iter 420/427 - loss 1.09979891 - samples/sec: 196.82 - lr: 0.003125\n",
            "2021-06-03 17:38:27,905 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:38:27,907 EPOCH 49 done: loss 1.1000 - lr 0.0031250\n",
            "2021-06-03 17:38:35,563 DEV : loss 1.2692954540252686 - score 0.4505\n",
            "2021-06-03 17:38:36,335 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:38:36,337 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:38:44,937 epoch 50 - iter 42/427 - loss 1.08210201 - samples/sec: 185.08 - lr: 0.003125\n",
            "2021-06-03 17:38:52,202 epoch 50 - iter 84/427 - loss 1.10171155 - samples/sec: 188.36 - lr: 0.003125\n",
            "2021-06-03 17:38:59,742 epoch 50 - iter 126/427 - loss 1.09915655 - samples/sec: 181.23 - lr: 0.003125\n",
            "2021-06-03 17:39:07,535 epoch 50 - iter 168/427 - loss 1.10253082 - samples/sec: 192.51 - lr: 0.003125\n",
            "2021-06-03 17:39:15,313 epoch 50 - iter 210/427 - loss 1.10518442 - samples/sec: 193.46 - lr: 0.003125\n",
            "2021-06-03 17:39:22,977 epoch 50 - iter 252/427 - loss 1.10665509 - samples/sec: 195.57 - lr: 0.003125\n",
            "2021-06-03 17:39:29,880 epoch 50 - iter 294/427 - loss 1.10325523 - samples/sec: 198.40 - lr: 0.003125\n",
            "2021-06-03 17:39:37,501 epoch 50 - iter 336/427 - loss 1.10322693 - samples/sec: 197.57 - lr: 0.003125\n",
            "2021-06-03 17:39:45,135 epoch 50 - iter 378/427 - loss 1.09812524 - samples/sec: 196.42 - lr: 0.003125\n",
            "2021-06-03 17:39:52,873 epoch 50 - iter 420/427 - loss 1.10016307 - samples/sec: 193.30 - lr: 0.003125\n",
            "2021-06-03 17:39:54,060 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:39:54,061 EPOCH 50 done: loss 1.1012 - lr 0.0031250\n",
            "2021-06-03 17:40:01,821 DEV : loss 1.2639087438583374 - score 0.4523\n",
            "2021-06-03 17:40:02,579 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:40:02,581 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:40:10,288 epoch 51 - iter 42/427 - loss 1.10744015 - samples/sec: 188.02 - lr: 0.003125\n",
            "2021-06-03 17:40:18,055 epoch 51 - iter 84/427 - loss 1.10944128 - samples/sec: 196.92 - lr: 0.003125\n",
            "2021-06-03 17:40:25,885 epoch 51 - iter 126/427 - loss 1.09492515 - samples/sec: 174.76 - lr: 0.003125\n",
            "2021-06-03 17:40:32,880 epoch 51 - iter 168/427 - loss 1.09603494 - samples/sec: 196.42 - lr: 0.003125\n",
            "2021-06-03 17:40:40,505 epoch 51 - iter 210/427 - loss 1.09777520 - samples/sec: 196.76 - lr: 0.003125\n",
            "2021-06-03 17:40:48,287 epoch 51 - iter 252/427 - loss 1.09263601 - samples/sec: 175.54 - lr: 0.003125\n",
            "2021-06-03 17:40:55,908 epoch 51 - iter 294/427 - loss 1.09127595 - samples/sec: 196.27 - lr: 0.003125\n",
            "2021-06-03 17:41:02,954 epoch 51 - iter 336/427 - loss 1.09283243 - samples/sec: 194.20 - lr: 0.003125\n",
            "2021-06-03 17:41:10,858 epoch 51 - iter 378/427 - loss 1.09325440 - samples/sec: 189.24 - lr: 0.003125\n",
            "2021-06-03 17:41:18,502 epoch 51 - iter 420/427 - loss 1.09241416 - samples/sec: 196.00 - lr: 0.003125\n",
            "2021-06-03 17:41:19,713 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:41:19,715 EPOCH 51 done: loss 1.0917 - lr 0.0031250\n",
            "2021-06-03 17:41:27,281 DEV : loss 1.2731988430023193 - score 0.4505\n",
            "Epoch    51: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2021-06-03 17:41:28,031 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:41:28,033 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:41:35,600 epoch 52 - iter 42/427 - loss 1.10150174 - samples/sec: 191.03 - lr: 0.001563\n",
            "2021-06-03 17:41:43,487 epoch 52 - iter 84/427 - loss 1.08420185 - samples/sec: 191.92 - lr: 0.001563\n",
            "2021-06-03 17:41:51,182 epoch 52 - iter 126/427 - loss 1.09425135 - samples/sec: 194.88 - lr: 0.001563\n",
            "2021-06-03 17:41:58,698 epoch 52 - iter 168/427 - loss 1.09315725 - samples/sec: 199.48 - lr: 0.001563\n",
            "2021-06-03 17:42:05,582 epoch 52 - iter 210/427 - loss 1.08726365 - samples/sec: 199.32 - lr: 0.001563\n",
            "2021-06-03 17:42:13,212 epoch 52 - iter 252/427 - loss 1.08646831 - samples/sec: 195.61 - lr: 0.001563\n",
            "2021-06-03 17:42:20,721 epoch 52 - iter 294/427 - loss 1.09080144 - samples/sec: 200.08 - lr: 0.001563\n",
            "2021-06-03 17:42:28,276 epoch 52 - iter 336/427 - loss 1.09394489 - samples/sec: 199.18 - lr: 0.001563\n",
            "2021-06-03 17:42:35,860 epoch 52 - iter 378/427 - loss 1.09506896 - samples/sec: 197.12 - lr: 0.001563\n",
            "2021-06-03 17:42:42,687 epoch 52 - iter 420/427 - loss 1.09603273 - samples/sec: 201.21 - lr: 0.001563\n",
            "2021-06-03 17:42:43,937 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:42:43,939 EPOCH 52 done: loss 1.0963 - lr 0.0015625\n",
            "2021-06-03 17:42:51,287 DEV : loss 1.2669163942337036 - score 0.4496\n",
            "2021-06-03 17:42:52,050 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:42:52,052 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:43:00,320 epoch 53 - iter 42/427 - loss 1.11100167 - samples/sec: 191.57 - lr: 0.001563\n",
            "2021-06-03 17:43:07,934 epoch 53 - iter 84/427 - loss 1.10115333 - samples/sec: 196.02 - lr: 0.001563\n",
            "2021-06-03 17:43:14,851 epoch 53 - iter 126/427 - loss 1.10018882 - samples/sec: 198.33 - lr: 0.001563\n",
            "2021-06-03 17:43:22,473 epoch 53 - iter 168/427 - loss 1.10099643 - samples/sec: 196.97 - lr: 0.001563\n",
            "2021-06-03 17:43:30,199 epoch 53 - iter 210/427 - loss 1.09936105 - samples/sec: 193.88 - lr: 0.001563\n",
            "2021-06-03 17:43:37,184 epoch 53 - iter 252/427 - loss 1.09823452 - samples/sec: 196.06 - lr: 0.001563\n",
            "2021-06-03 17:43:44,703 epoch 53 - iter 294/427 - loss 1.09812665 - samples/sec: 197.74 - lr: 0.001563\n",
            "2021-06-03 17:43:52,343 epoch 53 - iter 336/427 - loss 1.09555100 - samples/sec: 195.51 - lr: 0.001563\n",
            "2021-06-03 17:43:59,890 epoch 53 - iter 378/427 - loss 1.09663108 - samples/sec: 197.50 - lr: 0.001563\n",
            "2021-06-03 17:44:07,510 epoch 53 - iter 420/427 - loss 1.09680247 - samples/sec: 196.64 - lr: 0.001563\n",
            "2021-06-03 17:44:08,678 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:44:08,680 EPOCH 53 done: loss 1.0948 - lr 0.0015625\n",
            "2021-06-03 17:44:16,164 DEV : loss 1.2768267393112183 - score 0.4441\n",
            "2021-06-03 17:44:16,917 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:44:16,921 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:44:24,451 epoch 54 - iter 42/427 - loss 1.10231583 - samples/sec: 191.63 - lr: 0.001563\n",
            "2021-06-03 17:44:32,227 epoch 54 - iter 84/427 - loss 1.08569350 - samples/sec: 194.33 - lr: 0.001563\n",
            "2021-06-03 17:44:39,919 epoch 54 - iter 126/427 - loss 1.08568551 - samples/sec: 177.86 - lr: 0.001563\n",
            "2021-06-03 17:44:47,536 epoch 54 - iter 168/427 - loss 1.08824895 - samples/sec: 197.17 - lr: 0.001563\n",
            "2021-06-03 17:44:54,617 epoch 54 - iter 210/427 - loss 1.08302402 - samples/sec: 193.44 - lr: 0.001563\n",
            "2021-06-03 17:45:02,066 epoch 54 - iter 252/427 - loss 1.08181453 - samples/sec: 201.10 - lr: 0.001563\n",
            "2021-06-03 17:45:09,585 epoch 54 - iter 294/427 - loss 1.08955607 - samples/sec: 199.03 - lr: 0.001563\n",
            "2021-06-03 17:45:16,600 epoch 54 - iter 336/427 - loss 1.09495435 - samples/sec: 195.43 - lr: 0.001563\n",
            "2021-06-03 17:45:24,050 epoch 54 - iter 378/427 - loss 1.09384700 - samples/sec: 200.71 - lr: 0.001563\n",
            "2021-06-03 17:45:31,715 epoch 54 - iter 420/427 - loss 1.09388389 - samples/sec: 195.50 - lr: 0.001563\n",
            "2021-06-03 17:45:32,910 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:45:32,912 EPOCH 54 done: loss 1.0941 - lr 0.0015625\n",
            "2021-06-03 17:45:40,562 DEV : loss 1.2744065523147583 - score 0.4414\n",
            "2021-06-03 17:45:41,349 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:45:41,352 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:45:49,856 epoch 55 - iter 42/427 - loss 1.09517489 - samples/sec: 186.47 - lr: 0.001563\n",
            "2021-06-03 17:45:56,941 epoch 55 - iter 84/427 - loss 1.08412918 - samples/sec: 193.70 - lr: 0.001563\n",
            "2021-06-03 17:46:04,717 epoch 55 - iter 126/427 - loss 1.08209779 - samples/sec: 176.03 - lr: 0.001563\n",
            "2021-06-03 17:46:12,289 epoch 55 - iter 168/427 - loss 1.08547900 - samples/sec: 180.29 - lr: 0.001563\n",
            "2021-06-03 17:46:19,703 epoch 55 - iter 210/427 - loss 1.08700085 - samples/sec: 201.29 - lr: 0.001563\n",
            "2021-06-03 17:46:26,636 epoch 55 - iter 252/427 - loss 1.08317570 - samples/sec: 197.78 - lr: 0.001563\n",
            "2021-06-03 17:46:34,152 epoch 55 - iter 294/427 - loss 1.08341849 - samples/sec: 199.49 - lr: 0.001563\n",
            "2021-06-03 17:46:41,751 epoch 55 - iter 336/427 - loss 1.08260918 - samples/sec: 196.93 - lr: 0.001563\n",
            "2021-06-03 17:46:49,275 epoch 55 - iter 378/427 - loss 1.08273202 - samples/sec: 198.18 - lr: 0.001563\n",
            "2021-06-03 17:46:56,205 epoch 55 - iter 420/427 - loss 1.08558273 - samples/sec: 197.63 - lr: 0.001563\n",
            "2021-06-03 17:46:58,024 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:46:58,025 EPOCH 55 done: loss 1.0853 - lr 0.0015625\n",
            "2021-06-03 17:47:04,811 DEV : loss 1.2694789171218872 - score 0.4514\n",
            "Epoch    55: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2021-06-03 17:47:05,575 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:47:05,577 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:47:13,711 epoch 56 - iter 42/427 - loss 1.06221696 - samples/sec: 195.08 - lr: 0.000781\n",
            "2021-06-03 17:47:21,244 epoch 56 - iter 84/427 - loss 1.07625433 - samples/sec: 198.07 - lr: 0.000781\n",
            "2021-06-03 17:47:29,026 epoch 56 - iter 126/427 - loss 1.08092804 - samples/sec: 192.40 - lr: 0.000781\n",
            "2021-06-03 17:47:35,997 epoch 56 - iter 168/427 - loss 1.08014593 - samples/sec: 196.81 - lr: 0.000781\n",
            "2021-06-03 17:47:43,604 epoch 56 - iter 210/427 - loss 1.08099781 - samples/sec: 196.35 - lr: 0.000781\n",
            "2021-06-03 17:47:51,089 epoch 56 - iter 252/427 - loss 1.09142374 - samples/sec: 198.71 - lr: 0.000781\n",
            "2021-06-03 17:47:58,636 epoch 56 - iter 294/427 - loss 1.09581578 - samples/sec: 199.00 - lr: 0.000781\n",
            "2021-06-03 17:48:05,683 epoch 56 - iter 336/427 - loss 1.09520117 - samples/sec: 194.47 - lr: 0.000781\n",
            "2021-06-03 17:48:13,277 epoch 56 - iter 378/427 - loss 1.09119203 - samples/sec: 197.30 - lr: 0.000781\n",
            "2021-06-03 17:48:21,004 epoch 56 - iter 420/427 - loss 1.09219892 - samples/sec: 193.63 - lr: 0.000781\n",
            "2021-06-03 17:48:22,237 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:48:22,239 EPOCH 56 done: loss 1.0914 - lr 0.0007813\n",
            "2021-06-03 17:48:29,718 DEV : loss 1.2730728387832642 - score 0.4505\n",
            "2021-06-03 17:48:30,485 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:48:30,487 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:48:38,157 epoch 57 - iter 42/427 - loss 1.06901313 - samples/sec: 187.94 - lr: 0.000781\n",
            "2021-06-03 17:48:46,001 epoch 57 - iter 84/427 - loss 1.09413811 - samples/sec: 193.88 - lr: 0.000781\n",
            "2021-06-03 17:48:53,620 epoch 57 - iter 126/427 - loss 1.09455652 - samples/sec: 196.19 - lr: 0.000781\n",
            "2021-06-03 17:49:01,382 epoch 57 - iter 168/427 - loss 1.08179450 - samples/sec: 176.56 - lr: 0.000781\n",
            "2021-06-03 17:49:08,413 epoch 57 - iter 210/427 - loss 1.08300017 - samples/sec: 195.40 - lr: 0.000781\n",
            "2021-06-03 17:49:15,954 epoch 57 - iter 252/427 - loss 1.08432717 - samples/sec: 198.55 - lr: 0.000781\n",
            "2021-06-03 17:49:23,459 epoch 57 - iter 294/427 - loss 1.08562952 - samples/sec: 199.47 - lr: 0.000781\n",
            "2021-06-03 17:49:30,370 epoch 57 - iter 336/427 - loss 1.08688445 - samples/sec: 198.42 - lr: 0.000781\n",
            "2021-06-03 17:49:37,969 epoch 57 - iter 378/427 - loss 1.08727963 - samples/sec: 180.13 - lr: 0.000781\n",
            "2021-06-03 17:49:45,460 epoch 57 - iter 420/427 - loss 1.08590367 - samples/sec: 182.68 - lr: 0.000781\n",
            "2021-06-03 17:49:46,688 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:49:46,690 EPOCH 57 done: loss 1.0848 - lr 0.0007813\n",
            "2021-06-03 17:49:54,875 DEV : loss 1.2747212648391724 - score 0.4378\n",
            "2021-06-03 17:49:55,633 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:49:55,636 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:50:03,948 epoch 58 - iter 42/427 - loss 1.08420468 - samples/sec: 190.41 - lr: 0.000781\n",
            "2021-06-03 17:50:10,940 epoch 58 - iter 84/427 - loss 1.07605015 - samples/sec: 195.73 - lr: 0.000781\n",
            "2021-06-03 17:50:18,606 epoch 58 - iter 126/427 - loss 1.08667700 - samples/sec: 196.12 - lr: 0.000781\n",
            "2021-06-03 17:50:26,484 epoch 58 - iter 168/427 - loss 1.08814591 - samples/sec: 173.37 - lr: 0.000781\n",
            "2021-06-03 17:50:34,491 epoch 58 - iter 210/427 - loss 1.08951153 - samples/sec: 187.08 - lr: 0.000781\n",
            "2021-06-03 17:50:41,888 epoch 58 - iter 252/427 - loss 1.08325957 - samples/sec: 184.84 - lr: 0.000781\n",
            "2021-06-03 17:50:49,519 epoch 58 - iter 294/427 - loss 1.08433867 - samples/sec: 196.07 - lr: 0.000781\n",
            "2021-06-03 17:50:56,555 epoch 58 - iter 336/427 - loss 1.08365834 - samples/sec: 194.78 - lr: 0.000781\n",
            "2021-06-03 17:51:04,100 epoch 58 - iter 378/427 - loss 1.08532677 - samples/sec: 199.21 - lr: 0.000781\n",
            "2021-06-03 17:51:11,669 epoch 58 - iter 420/427 - loss 1.08568087 - samples/sec: 180.54 - lr: 0.000781\n",
            "2021-06-03 17:51:12,957 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:51:12,959 EPOCH 58 done: loss 1.0849 - lr 0.0007813\n",
            "2021-06-03 17:51:20,609 DEV : loss 1.2715929746627808 - score 0.4514\n",
            "2021-06-03 17:51:21,362 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:51:21,365 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:51:29,846 epoch 59 - iter 42/427 - loss 1.10206045 - samples/sec: 186.71 - lr: 0.000781\n",
            "2021-06-03 17:51:36,849 epoch 59 - iter 84/427 - loss 1.09853632 - samples/sec: 195.53 - lr: 0.000781\n",
            "2021-06-03 17:51:44,539 epoch 59 - iter 126/427 - loss 1.10066153 - samples/sec: 195.24 - lr: 0.000781\n",
            "2021-06-03 17:51:52,221 epoch 59 - iter 168/427 - loss 1.09469001 - samples/sec: 178.20 - lr: 0.000781\n",
            "2021-06-03 17:51:59,795 epoch 59 - iter 210/427 - loss 1.09815974 - samples/sec: 197.77 - lr: 0.000781\n",
            "2021-06-03 17:52:06,712 epoch 59 - iter 252/427 - loss 1.09203261 - samples/sec: 198.24 - lr: 0.000781\n",
            "2021-06-03 17:52:14,262 epoch 59 - iter 294/427 - loss 1.08905820 - samples/sec: 181.06 - lr: 0.000781\n",
            "2021-06-03 17:52:21,855 epoch 59 - iter 336/427 - loss 1.08773387 - samples/sec: 179.97 - lr: 0.000781\n",
            "2021-06-03 17:52:29,290 epoch 59 - iter 378/427 - loss 1.08732243 - samples/sec: 183.69 - lr: 0.000781\n",
            "2021-06-03 17:52:36,241 epoch 59 - iter 420/427 - loss 1.08684369 - samples/sec: 196.66 - lr: 0.000781\n",
            "2021-06-03 17:52:37,508 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:52:37,511 EPOCH 59 done: loss 1.0888 - lr 0.0007813\n",
            "2021-06-03 17:52:45,086 DEV : loss 1.2705035209655762 - score 0.4478\n",
            "Epoch    59: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2021-06-03 17:52:45,867 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:52:45,869 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:52:54,380 epoch 60 - iter 42/427 - loss 1.09971974 - samples/sec: 169.11 - lr: 0.000391\n",
            "2021-06-03 17:53:01,753 epoch 60 - iter 84/427 - loss 1.10011000 - samples/sec: 186.74 - lr: 0.000391\n",
            "2021-06-03 17:53:09,437 epoch 60 - iter 126/427 - loss 1.08792719 - samples/sec: 195.43 - lr: 0.000391\n",
            "2021-06-03 17:53:17,037 epoch 60 - iter 168/427 - loss 1.08994044 - samples/sec: 197.49 - lr: 0.000391\n",
            "2021-06-03 17:53:24,659 epoch 60 - iter 210/427 - loss 1.08744071 - samples/sec: 196.29 - lr: 0.000391\n",
            "2021-06-03 17:53:31,738 epoch 60 - iter 252/427 - loss 1.09267656 - samples/sec: 193.61 - lr: 0.000391\n",
            "2021-06-03 17:53:39,558 epoch 60 - iter 294/427 - loss 1.09071012 - samples/sec: 191.48 - lr: 0.000391\n",
            "2021-06-03 17:53:47,230 epoch 60 - iter 336/427 - loss 1.08902476 - samples/sec: 195.63 - lr: 0.000391\n",
            "2021-06-03 17:53:54,904 epoch 60 - iter 378/427 - loss 1.09109279 - samples/sec: 193.71 - lr: 0.000391\n",
            "2021-06-03 17:54:02,451 epoch 60 - iter 420/427 - loss 1.09027291 - samples/sec: 198.19 - lr: 0.000391\n",
            "2021-06-03 17:54:03,706 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:54:03,707 EPOCH 60 done: loss 1.0895 - lr 0.0003906\n",
            "2021-06-03 17:54:10,525 DEV : loss 1.2738004922866821 - score 0.4487\n",
            "2021-06-03 17:54:11,322 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:54:11,325 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:54:19,711 epoch 61 - iter 42/427 - loss 1.12209173 - samples/sec: 191.94 - lr: 0.000391\n",
            "2021-06-03 17:54:27,311 epoch 61 - iter 84/427 - loss 1.10247195 - samples/sec: 196.92 - lr: 0.000391\n",
            "2021-06-03 17:54:34,896 epoch 61 - iter 126/427 - loss 1.10610983 - samples/sec: 197.11 - lr: 0.000391\n",
            "2021-06-03 17:54:41,915 epoch 61 - iter 168/427 - loss 1.09690835 - samples/sec: 195.02 - lr: 0.000391\n",
            "2021-06-03 17:54:49,358 epoch 61 - iter 210/427 - loss 1.09223046 - samples/sec: 200.92 - lr: 0.000391\n",
            "2021-06-03 17:54:57,287 epoch 61 - iter 252/427 - loss 1.09030549 - samples/sec: 172.44 - lr: 0.000391\n",
            "2021-06-03 17:55:04,855 epoch 61 - iter 294/427 - loss 1.08929933 - samples/sec: 196.86 - lr: 0.000391\n",
            "2021-06-03 17:55:12,428 epoch 61 - iter 336/427 - loss 1.08564450 - samples/sec: 197.72 - lr: 0.000391\n",
            "2021-06-03 17:55:19,361 epoch 61 - iter 378/427 - loss 1.09161683 - samples/sec: 197.52 - lr: 0.000391\n",
            "2021-06-03 17:55:26,930 epoch 61 - iter 420/427 - loss 1.09246582 - samples/sec: 181.31 - lr: 0.000391\n",
            "2021-06-03 17:55:28,170 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:55:28,172 EPOCH 61 done: loss 1.0921 - lr 0.0003906\n",
            "2021-06-03 17:55:35,717 DEV : loss 1.2731270790100098 - score 0.4478\n",
            "2021-06-03 17:55:36,483 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 17:55:36,486 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:55:44,001 epoch 62 - iter 42/427 - loss 1.11465886 - samples/sec: 191.27 - lr: 0.000391\n",
            "2021-06-03 17:55:51,762 epoch 62 - iter 84/427 - loss 1.10651499 - samples/sec: 194.90 - lr: 0.000391\n",
            "2021-06-03 17:55:59,374 epoch 62 - iter 126/427 - loss 1.10868417 - samples/sec: 196.64 - lr: 0.000391\n",
            "2021-06-03 17:56:06,868 epoch 62 - iter 168/427 - loss 1.10202953 - samples/sec: 200.04 - lr: 0.000391\n",
            "2021-06-03 17:56:13,693 epoch 62 - iter 210/427 - loss 1.09389653 - samples/sec: 200.75 - lr: 0.000391\n",
            "2021-06-03 17:56:21,363 epoch 62 - iter 252/427 - loss 1.09065102 - samples/sec: 178.40 - lr: 0.000391\n",
            "2021-06-03 17:56:29,000 epoch 62 - iter 294/427 - loss 1.09052352 - samples/sec: 196.02 - lr: 0.000391\n",
            "2021-06-03 17:56:36,794 epoch 62 - iter 336/427 - loss 1.08908182 - samples/sec: 192.21 - lr: 0.000391\n",
            "2021-06-03 17:56:44,541 epoch 62 - iter 378/427 - loss 1.08679886 - samples/sec: 176.31 - lr: 0.000391\n",
            "2021-06-03 17:56:51,426 epoch 62 - iter 420/427 - loss 1.08565805 - samples/sec: 198.68 - lr: 0.000391\n",
            "2021-06-03 17:56:53,285 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:56:53,287 EPOCH 62 done: loss 1.0848 - lr 0.0003906\n",
            "2021-06-03 17:57:00,144 DEV : loss 1.2716253995895386 - score 0.4496\n",
            "2021-06-03 17:57:00,922 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 17:57:00,924 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:57:09,230 epoch 63 - iter 42/427 - loss 1.10689514 - samples/sec: 191.73 - lr: 0.000391\n",
            "2021-06-03 17:57:17,066 epoch 63 - iter 84/427 - loss 1.09957539 - samples/sec: 191.08 - lr: 0.000391\n",
            "2021-06-03 17:57:24,684 epoch 63 - iter 126/427 - loss 1.09977917 - samples/sec: 197.55 - lr: 0.000391\n",
            "2021-06-03 17:57:31,561 epoch 63 - iter 168/427 - loss 1.09951239 - samples/sec: 199.15 - lr: 0.000391\n",
            "2021-06-03 17:57:39,092 epoch 63 - iter 210/427 - loss 1.09540571 - samples/sec: 181.39 - lr: 0.000391\n",
            "2021-06-03 17:57:46,845 epoch 63 - iter 252/427 - loss 1.09731066 - samples/sec: 176.09 - lr: 0.000391\n",
            "2021-06-03 17:57:54,515 epoch 63 - iter 294/427 - loss 1.09912740 - samples/sec: 194.97 - lr: 0.000391\n",
            "2021-06-03 17:58:01,436 epoch 63 - iter 336/427 - loss 1.09526014 - samples/sec: 198.61 - lr: 0.000391\n",
            "2021-06-03 17:58:09,114 epoch 63 - iter 378/427 - loss 1.09704153 - samples/sec: 195.07 - lr: 0.000391\n",
            "2021-06-03 17:58:16,698 epoch 63 - iter 420/427 - loss 1.09703102 - samples/sec: 180.91 - lr: 0.000391\n",
            "2021-06-03 17:58:17,922 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:58:17,923 EPOCH 63 done: loss 1.0971 - lr 0.0003906\n",
            "2021-06-03 17:58:25,445 DEV : loss 1.272233486175537 - score 0.4469\n",
            "Epoch    63: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2021-06-03 17:58:26,197 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 17:58:26,201 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:58:33,901 epoch 64 - iter 42/427 - loss 1.09079974 - samples/sec: 186.68 - lr: 0.000195\n",
            "2021-06-03 17:58:41,930 epoch 64 - iter 84/427 - loss 1.09462597 - samples/sec: 189.58 - lr: 0.000195\n",
            "2021-06-03 17:58:49,566 epoch 64 - iter 126/427 - loss 1.09005629 - samples/sec: 179.63 - lr: 0.000195\n",
            "2021-06-03 17:58:56,720 epoch 64 - iter 168/427 - loss 1.08740682 - samples/sec: 191.75 - lr: 0.000195\n",
            "2021-06-03 17:59:04,383 epoch 64 - iter 210/427 - loss 1.08224847 - samples/sec: 195.92 - lr: 0.000195\n",
            "2021-06-03 17:59:12,079 epoch 64 - iter 252/427 - loss 1.08572224 - samples/sec: 194.35 - lr: 0.000195\n",
            "2021-06-03 17:59:19,539 epoch 64 - iter 294/427 - loss 1.08817197 - samples/sec: 199.22 - lr: 0.000195\n",
            "2021-06-03 17:59:26,984 epoch 64 - iter 336/427 - loss 1.09065103 - samples/sec: 200.95 - lr: 0.000195\n",
            "2021-06-03 17:59:33,886 epoch 64 - iter 378/427 - loss 1.09420129 - samples/sec: 198.63 - lr: 0.000195\n",
            "2021-06-03 17:59:41,421 epoch 64 - iter 420/427 - loss 1.09321962 - samples/sec: 180.98 - lr: 0.000195\n",
            "2021-06-03 17:59:42,592 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:59:42,594 EPOCH 64 done: loss 1.0935 - lr 0.0001953\n",
            "2021-06-03 17:59:50,023 DEV : loss 1.2723751068115234 - score 0.4478\n",
            "2021-06-03 17:59:50,801 BAD EPOCHS (no improvement): 1\n",
            "2021-06-03 17:59:50,804 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 17:59:59,113 epoch 65 - iter 42/427 - loss 1.07434239 - samples/sec: 172.38 - lr: 0.000195\n",
            "2021-06-03 18:00:06,418 epoch 65 - iter 84/427 - loss 1.06872637 - samples/sec: 186.80 - lr: 0.000195\n",
            "2021-06-03 18:00:13,458 epoch 65 - iter 126/427 - loss 1.07863366 - samples/sec: 194.43 - lr: 0.000195\n",
            "2021-06-03 18:00:21,108 epoch 65 - iter 168/427 - loss 1.08232664 - samples/sec: 178.78 - lr: 0.000195\n",
            "2021-06-03 18:00:28,716 epoch 65 - iter 210/427 - loss 1.07796080 - samples/sec: 179.72 - lr: 0.000195\n",
            "2021-06-03 18:00:36,441 epoch 65 - iter 252/427 - loss 1.08313972 - samples/sec: 177.03 - lr: 0.000195\n",
            "2021-06-03 18:00:44,055 epoch 65 - iter 294/427 - loss 1.08699835 - samples/sec: 197.01 - lr: 0.000195\n",
            "2021-06-03 18:00:51,093 epoch 65 - iter 336/427 - loss 1.08589600 - samples/sec: 194.24 - lr: 0.000195\n",
            "2021-06-03 18:00:58,710 epoch 65 - iter 378/427 - loss 1.08850780 - samples/sec: 179.28 - lr: 0.000195\n",
            "2021-06-03 18:01:06,380 epoch 65 - iter 420/427 - loss 1.09168028 - samples/sec: 194.83 - lr: 0.000195\n",
            "2021-06-03 18:01:07,617 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:01:07,618 EPOCH 65 done: loss 1.0906 - lr 0.0001953\n",
            "2021-06-03 18:01:15,100 DEV : loss 1.2708978652954102 - score 0.4514\n",
            "2021-06-03 18:01:15,860 BAD EPOCHS (no improvement): 2\n",
            "2021-06-03 18:01:15,863 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:01:24,343 epoch 66 - iter 42/427 - loss 1.10193701 - samples/sec: 187.30 - lr: 0.000195\n",
            "2021-06-03 18:01:31,884 epoch 66 - iter 84/427 - loss 1.07251994 - samples/sec: 181.62 - lr: 0.000195\n",
            "2021-06-03 18:01:38,696 epoch 66 - iter 126/427 - loss 1.08348602 - samples/sec: 201.55 - lr: 0.000195\n",
            "2021-06-03 18:01:46,366 epoch 66 - iter 168/427 - loss 1.08535441 - samples/sec: 194.12 - lr: 0.000195\n",
            "2021-06-03 18:01:53,992 epoch 66 - iter 210/427 - loss 1.08174282 - samples/sec: 196.48 - lr: 0.000195\n",
            "2021-06-03 18:02:01,947 epoch 66 - iter 252/427 - loss 1.07693243 - samples/sec: 188.70 - lr: 0.000195\n",
            "2021-06-03 18:02:09,728 epoch 66 - iter 294/427 - loss 1.07764142 - samples/sec: 175.96 - lr: 0.000195\n",
            "2021-06-03 18:02:16,987 epoch 66 - iter 336/427 - loss 1.07717849 - samples/sec: 188.66 - lr: 0.000195\n",
            "2021-06-03 18:02:24,737 epoch 66 - iter 378/427 - loss 1.07885580 - samples/sec: 193.11 - lr: 0.000195\n",
            "2021-06-03 18:02:32,519 epoch 66 - iter 420/427 - loss 1.07501321 - samples/sec: 192.46 - lr: 0.000195\n",
            "2021-06-03 18:02:33,719 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:02:33,721 EPOCH 66 done: loss 1.0761 - lr 0.0001953\n",
            "2021-06-03 18:02:41,515 DEV : loss 1.271994709968567 - score 0.4496\n",
            "2021-06-03 18:02:42,304 BAD EPOCHS (no improvement): 3\n",
            "2021-06-03 18:02:42,306 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:02:50,832 epoch 67 - iter 42/427 - loss 1.10529527 - samples/sec: 186.24 - lr: 0.000195\n",
            "2021-06-03 18:02:57,957 epoch 67 - iter 84/427 - loss 1.10278072 - samples/sec: 192.29 - lr: 0.000195\n",
            "2021-06-03 18:03:05,596 epoch 67 - iter 126/427 - loss 1.09049916 - samples/sec: 178.91 - lr: 0.000195\n",
            "2021-06-03 18:03:13,173 epoch 67 - iter 168/427 - loss 1.08817388 - samples/sec: 197.73 - lr: 0.000195\n",
            "2021-06-03 18:03:20,760 epoch 67 - iter 210/427 - loss 1.08649096 - samples/sec: 197.71 - lr: 0.000195\n",
            "2021-06-03 18:03:28,189 epoch 67 - iter 252/427 - loss 1.08567400 - samples/sec: 201.73 - lr: 0.000195\n",
            "2021-06-03 18:03:35,086 epoch 67 - iter 294/427 - loss 1.08827046 - samples/sec: 198.96 - lr: 0.000195\n",
            "2021-06-03 18:03:42,667 epoch 67 - iter 336/427 - loss 1.09056214 - samples/sec: 197.02 - lr: 0.000195\n",
            "2021-06-03 18:03:50,432 epoch 67 - iter 378/427 - loss 1.09424459 - samples/sec: 194.40 - lr: 0.000195\n",
            "2021-06-03 18:03:57,491 epoch 67 - iter 420/427 - loss 1.09252819 - samples/sec: 194.58 - lr: 0.000195\n",
            "2021-06-03 18:03:58,710 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:03:58,712 EPOCH 67 done: loss 1.0916 - lr 0.0001953\n",
            "2021-06-03 18:04:07,335 DEV : loss 1.271223783493042 - score 0.4496\n",
            "Epoch    67: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2021-06-03 18:04:08,107 BAD EPOCHS (no improvement): 4\n",
            "2021-06-03 18:04:08,109 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:08,111 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:08,113 learning rate too small - quitting training!\n",
            "2021-06-03 18:04:08,117 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:11,224 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:11,226 Testing using best model ...\n",
            "2021-06-03 18:04:11,228 loading file best-model.pt\n",
            "2021-06-03 18:04:19,182 \t0.4511\n",
            "2021-06-03 18:04:19,184 \n",
            "Results:\n",
            "- F-score (micro) 0.4511\n",
            "- F-score (macro) 0.4209\n",
            "- Accuracy 0.4511\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3     0.3252    0.1722    0.2252       389\n",
            "           1     0.4369    0.3226    0.3711       279\n",
            "           4     0.4272    0.4255    0.4263       510\n",
            "           5     0.5570    0.5514    0.5542       399\n",
            "           2     0.4503    0.6367    0.5275       633\n",
            "\n",
            "   micro avg     0.4511    0.4511    0.4511      2210\n",
            "   macro avg     0.4393    0.4217    0.4209      2210\n",
            "weighted avg     0.4405    0.4511    0.4360      2210\n",
            " samples avg     0.4511    0.4511    0.4511      2210\n",
            "\n",
            "2021-06-03 18:04:19,187 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:19,196 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:19,199 WARNING: No LOSS found for test split in this data.\n",
            "2021-06-03 18:04:19,205 Are you sure you want to plot LOSS and not another value?\n",
            "2021-06-03 18:04:19,209 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:19,242 ----------------------------------------------------------------------------------------------------\n",
            "2021-06-03 18:04:19,244 WARNING: No F1 found for test split in this data.\n",
            "2021-06-03 18:04:19,249 Are you sure you want to plot F1 and not another value?\n",
            "2021-06-03 18:04:19,251 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss and F1 plots are saved in /content/training.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcd8MAhZsMnO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeusfZPJanZT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}